{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/VSCode/banditLiquidDem/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from exp_framework.Ensemble import Ensemble, PretrainedEnsemble, StudentExpertEnsemble\n",
    "from exp_framework.delegation import (\n",
    "    DelegationMechanism,\n",
    "    UCBDelegationMechanism,\n",
    "    ProbaSlopeDelegationMechanism,\n",
    "    RestrictedMaxGurusDelegationMechanism,\n",
    "    StudentExpertDelegationMechanism,\n",
    ")\n",
    "from exp_framework.learning import Net\n",
    "from exp_framework.experiment import (\n",
    "    Experiment,\n",
    "    calculate_avg_std_test_accs,\n",
    "    calculate_avg_std_train_accs,\n",
    ")\n",
    "from avalanche.training.supervised import Naive\n",
    "from matplotlib import pyplot as plt\n",
    "from exp_framework.data_utils import Data\n",
    "from avalanche.benchmarks.classic import RotatedMNIST, SplitMNIST\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.plugins import CWRStarPlugin, ReplayPlugin, EWCPlugin, TrainGeneratorAfterExpPlugin, LwFPlugin, SynapticIntelligencePlugin\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import accuracy_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning the mapping $\\mathcal{X} \\rightarrow \\mathcal{G}$ (i.e. $\\mathcal{X} \\rightarrow \\mathcal{Y}\\times\\mathcal{C}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "window_size = 50\n",
    "num_trials = 2\n",
    "n_voters = 10\n",
    "\n",
    "\n",
    "# # Set up the Class Incremental framework\n",
    "# data = Data(\n",
    "#     data_set_name=\"mnist\",\n",
    "#     # train_digit_groups=[range(5), range(5, 10)],\n",
    "#     # train_digit_groups=[[0, 1, 2], [3, 4, 5,], [6, 7, 8, 9]],\n",
    "#     train_digit_groups=[[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]],\n",
    "#     # test_digit_groups=[[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]],\n",
    "#     # test_digit_groups=[range(5), range(5, 10)],\n",
    "#     test_digit_groups=[range(10)],\n",
    "#     batch_size=batch_size,\n",
    "# )\n",
    "\n",
    "data = SplitMNIST(n_experiences=5, fixed_class_order=list(range(10)))\n",
    "# if data == \"MNIST\":\n",
    "#     benchmark = SplitMNIST(n_experiences=5, fixed_class_order=list(range(10)), seed=self.seed)\n",
    "# elif data == \"RotatedMNIST\":\n",
    "#     benchmark = RotatedMNIST(n_experiences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Active Voter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Delegation Mechanisms and Ensembles\n",
    "\n",
    "For simplicity, only explore full ensemble and variants of ProbaSlopeDelegationMechanism since they can be created programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Delegation Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Delegation Mechanisms - single guru\n",
    "\n",
    "NOOP_del_mech = DelegationMechanism(batch_size=batch_size, window_size=window_size)\n",
    "\n",
    "probability_functions = [\"random_better\", \"probabilistic_better\", \"probabilistic_weighted\"]\n",
    "score_functions = [\n",
    "                   \"accuracy_score\",\n",
    "                   \"balanced_accuracy_score\",\n",
    "                   \"f1_score\",\n",
    "                   \"precision_score\",\n",
    "                   \"recall_score\",\n",
    "                   \"top_k_accuracy_score\",\n",
    "                   \"roc_auc_score\",\n",
    "                   \"log_loss_score\",\n",
    "                   \"max_diversity\",\n",
    "                   ]\n",
    "probability_functions = [\"max_diversity\"]\n",
    "score_functions = [\n",
    "                   \"accuracy_score\"\n",
    "                   ]\n",
    "max_active_gurus = 1\n",
    "\n",
    "del_mechs = {\n",
    "    \"full-ensemble\": NOOP_del_mech\n",
    "}\n",
    "for prob_func, score_func in product(probability_functions, score_functions):\n",
    "    dm = ProbaSlopeDelegationMechanism(\n",
    "        batch_size=batch_size,\n",
    "        window_size=window_size,\n",
    "        max_active=max_active_gurus,\n",
    "        probability_function=prob_func,\n",
    "        score_method=score_func\n",
    "        )\n",
    "    del_mechs[f\"{prob_func}-{score_func}\"] = dm\n",
    "\n",
    "\n",
    "ensembles_dict = {\n",
    "    dm_name: Ensemble(\n",
    "        training_epochs=1,\n",
    "        n_voters=n_voters,\n",
    "        delegation_mechanism=dm,\n",
    "        name=dm_name,\n",
    "        input_dim=28 * 28,\n",
    "        output_dim=10,\n",
    "    )\n",
    "    for dm_name, dm in del_mechs.items()\n",
    "}\n",
    "\n",
    "# restricted_max_gurus_mech = RestrictedMaxGurusDelegationMechanism(\n",
    "#     batch_size=batch_size,\n",
    "#     num_voters=n_voters,\n",
    "#     max_active_voters=max_active_gurus,\n",
    "#     window_size=window_size,\n",
    "#     t_between_delegation=3,\n",
    "# )\n",
    "# UCB_del_mech = UCBDelegationMechanism(\n",
    "#     batch_size=batch_size,\n",
    "#     window_size=window_size,\n",
    "#     ucb_window_size=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Avalanche Strategies to Compare Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/VSCode/banditLiquidDem/.conda/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:68: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_dim=28 * 28, output_dim=10)\n",
    "# model = SimpleMLP(num_classes=10)\n",
    "optimize = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "plugins_to_evaluate = {\n",
    "    \"LwF\": LwFPlugin(),\n",
    "    \"EWC\": EWCPlugin(ewc_lambda=0.001),\n",
    "    \"SynapticIntelligence\": SynapticIntelligencePlugin(si_lambda=0.5)\n",
    "}\n",
    "\n",
    "strategies_to_evaluate = {}\n",
    "for name, pte in plugins_to_evaluate.items():\n",
    "    evp = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True),\n",
    "        )\n",
    "    cl_strategy = Naive(\n",
    "        model = model,\n",
    "        optimizer=optimize,\n",
    "        criterion=CrossEntropyLoss(),\n",
    "        train_mb_size=batch_size, train_epochs=1, eval_mb_size=batch_size,\n",
    "        plugins=[pte, evp],\n",
    "        evaluator=evp\n",
    "    )\n",
    "    strategies_to_evaluate[name] = (cl_strategy, evp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of batch accs:  198\n",
      "Length of batch accs:  198\n",
      "Length of batch accs:  198\n",
      "Length of batch accs:  388\n",
      "Length of batch accs:  388\n",
      "Length of batch accs:  388\n",
      "Length of batch accs:  564\n",
      "Length of batch accs:  564\n",
      "Length of batch accs:  564\n",
      "Length of batch accs:  756\n",
      "Length of batch accs:  756\n",
      "Length of batch accs:  756\n",
      "Length of batch accs:  942\n",
      "Length of batch accs:  942\n",
      "Length of batch accs:  942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:23<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of evaluation are: \n",
      "{'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9583333333333334}\n",
      "\n",
      "\n",
      "defaultdict(<function EvaluationPlugin.__init__.<locals>.<lambda> at 0x16c3bbeb0>, {'Top1_Acc_MB/train_phase/train_stream/Task000': ([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32, 33, 33, 34, 34, 35, 35, 36, 36, 37, 37, 38, 38, 39, 39, 40, 40, 41, 41, 42, 42, 43, 43, 44, 44, 45, 45, 46, 46, 47, 47, 48, 48, 49, 49, 50, 50, 51, 51, 52, 52, 53, 53, 54, 54, 55, 55, 56, 56, 57, 57, 58, 58, 59, 59, 60, 60, 61, 61, 62, 62, 63, 63, 64, 64, 65, 65, 66, 66, 67, 67, 68, 68, 69, 69, 70, 70, 71, 71, 72, 72, 73, 73, 74, 74, 75, 75, 76, 76, 77, 77, 78, 78, 79, 79, 80, 80, 81, 81, 82, 82, 83, 83, 84, 84, 85, 85, 86, 86, 87, 87, 88, 88, 89, 89, 90, 90, 91, 91, 92, 92, 93, 93, 94, 94, 95, 95, 96, 96, 97, 97, 98, 98, 99, 99, 100, 100, 101, 101, 102, 102, 103, 103, 104, 104, 105, 105, 106, 106, 107, 107, 108, 108, 109, 109, 110, 110, 111, 111, 112, 112, 113, 113, 114, 114, 115, 115, 116, 116, 117, 117, 118, 118, 119, 119, 120, 120, 121, 121, 122, 122, 123, 123, 124, 124, 125, 125, 126, 126, 127, 127, 128, 128, 129, 129, 130, 130, 131, 131, 132, 132, 133, 133, 134, 134, 135, 135, 136, 136, 137, 137, 138, 138, 139, 139, 140, 140, 141, 141, 142, 142, 143, 143, 144, 144, 145, 145, 146, 146, 147, 147, 148, 148, 149, 149, 150, 150, 151, 151, 152, 152, 153, 153, 154, 154, 155, 155, 156, 156, 157, 157, 158, 158, 159, 159, 160, 160, 161, 161, 162, 162, 163, 163, 164, 164, 165, 165, 166, 166, 167, 167, 168, 168, 169, 169, 170, 170, 171, 171, 172, 172, 173, 173, 174, 174, 175, 175, 176, 176, 177, 177, 178, 178, 179, 179, 180, 180, 181, 181, 182, 182, 183, 183, 184, 184, 185, 185, 186, 186, 187, 187, 188, 188, 189, 189, 190, 190, 191, 191, 192, 192, 193, 193, 194, 194, 195, 195, 196, 196, 197, 197, 198, 198, 199, 199, 200, 200, 201, 201, 202, 202, 203, 203, 204, 204, 205, 205, 206, 206, 207, 207, 208, 208, 209, 209, 210, 210, 211, 211, 212, 212, 213, 213, 214, 214, 215, 215, 216, 216, 217, 217, 218, 218, 219, 219, 220, 220, 221, 221, 222, 222, 223, 223, 224, 224, 225, 225, 226, 226, 227, 227, 228, 228, 229, 229, 230, 230, 231, 231, 232, 232, 233, 233, 234, 234, 235, 235, 236, 236, 237, 237, 238, 238, 239, 239, 240, 240, 241, 241, 242, 242, 243, 243, 244, 244, 245, 245, 246, 246, 247, 247, 248, 248, 249, 249, 250, 250, 251, 251, 252, 252, 253, 253, 254, 254, 255, 255, 256, 256, 257, 257, 258, 258, 259, 259, 260, 260, 261, 261, 262, 262, 263, 263, 264, 264, 265, 265, 266, 266, 267, 267, 268, 268, 269, 269, 270, 270, 271, 271, 272, 272, 273, 273, 274, 274, 275, 275, 276, 276, 277, 277, 278, 278, 279, 279, 280, 280, 281, 281, 282, 282, 283, 283, 284, 284, 285, 285, 286, 286, 287, 287, 288, 288, 289, 289, 290, 290, 291, 291, 292, 292, 293, 293, 294, 294, 295, 295, 296, 296, 297, 297, 298, 298, 299, 299, 300, 300, 301, 301, 302, 302, 303, 303, 304, 304, 305, 305, 306, 306, 307, 307, 308, 308, 309, 309, 310, 310, 311, 311, 312, 312, 313, 313, 314, 314, 315, 315, 316, 316, 317, 317, 318, 318, 319, 319, 320, 320, 321, 321, 322, 322, 323, 323, 324, 324, 325, 325, 326, 326, 327, 327, 328, 328, 329, 329, 330, 330, 331, 331, 332, 332, 333, 333, 334, 334, 335, 335, 336, 336, 337, 337, 338, 338, 339, 339, 340, 340, 341, 341, 342, 342, 343, 343, 344, 344, 345, 345, 346, 346, 347, 347, 348, 348, 349, 349, 350, 350, 351, 351, 352, 352, 353, 353, 354, 354, 355, 355, 356, 356, 357, 357, 358, 358, 359, 359, 360, 360, 361, 361, 362, 362, 363, 363, 364, 364, 365, 365, 366, 366, 367, 367, 368, 368, 369, 369, 370, 370, 371, 371, 372, 372, 373, 373, 374, 374, 375, 375, 376, 376, 377, 377, 378, 378, 379, 379, 380, 380, 381, 381, 382, 382, 383, 383, 384, 384, 385, 385, 386, 386, 387, 387, 388, 388, 389, 389, 390, 390, 391, 391, 392, 392, 393, 393, 394, 394, 395, 395, 396, 396, 397, 397, 398, 398, 399, 399, 400, 400, 401, 401, 402, 402, 403, 403, 404, 404, 405, 405, 406, 406, 407, 407, 408, 408, 409, 409, 410, 410, 411, 411, 412, 412, 413, 413, 414, 414, 415, 415, 416, 416, 417, 417, 418, 418, 419, 419, 420, 420, 421, 421, 422, 422, 423, 423, 424, 424, 425, 425, 426, 426, 427, 427, 428, 428, 429, 429, 430, 430, 431, 431, 432, 432, 433, 433, 434, 434, 435, 435, 436, 436, 437, 437, 438, 438, 439, 439, 440, 440, 441, 441, 442, 442, 443, 443, 444, 444, 445, 445, 446, 446, 447, 447, 448, 448, 449, 449, 450, 450, 451, 451, 452, 452, 453, 453, 454, 454, 455, 455, 456, 456, 457, 457, 458, 458, 459, 459, 460, 460, 461, 461, 462, 462, 463, 463, 464, 464, 465, 465, 466, 466, 467, 467, 468, 468, 469, 469, 470, 470], [0.0, 0.0, 0.8515625, 0.8515625, 0.96875, 0.96875, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 0.9921875, 0.9921875, 0.984375, 0.984375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 0.984375, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 0.984375, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0078125, 0.0625, 0.0625, 0.09375, 0.09375, 0.296875, 0.296875, 0.4140625, 0.4140625, 0.4765625, 0.4765625, 0.609375, 0.609375, 0.6796875, 0.6796875, 0.7421875, 0.7421875, 0.7265625, 0.7265625, 0.8671875, 0.8671875, 0.8515625, 0.8515625, 0.859375, 0.859375, 0.890625, 0.890625, 0.8984375, 0.8984375, 0.890625, 0.890625, 0.8359375, 0.8359375, 0.890625, 0.890625, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.734375, 0.734375, 0.921875, 0.921875, 0.8359375, 0.8359375, 0.859375, 0.859375, 0.8828125, 0.8828125, 0.8671875, 0.8671875, 0.859375, 0.859375, 0.875, 0.875, 0.8671875, 0.8671875, 0.8671875, 0.8671875, 0.8515625, 0.8515625, 0.9140625, 0.9140625, 0.90625, 0.90625, 0.9296875, 0.9296875, 0.90625, 0.90625, 0.90625, 0.90625, 0.875, 0.875, 0.9453125, 0.9453125, 0.921875, 0.921875, 0.890625, 0.890625, 0.9140625, 0.9140625, 0.9375, 0.9375, 0.9453125, 0.9453125, 0.953125, 0.953125, 0.9453125, 0.9453125, 0.9375, 0.9375, 0.90625, 0.90625, 0.953125, 0.953125, 0.9453125, 0.9453125, 0.953125, 0.953125, 0.9375, 0.9375, 0.953125, 0.953125, 0.9609375, 0.9609375, 0.96875, 0.96875, 0.953125, 0.953125, 0.953125, 0.953125, 0.9765625, 0.9765625, 0.9453125, 0.9453125, 0.96875, 0.96875, 0.9375, 0.9375, 0.9609375, 0.9609375, 0.9765625, 0.9765625, 0.9609375, 0.9609375, 0.953125, 0.953125, 0.9765625, 0.9765625, 0.96875, 0.96875, 0.96875, 0.96875, 0.9453125, 0.9453125, 0.96875, 0.96875, 0.984375, 0.984375, 0.9609375, 0.9609375, 1.0, 1.0, 0.953125, 0.953125, 0.96875, 0.96875, 0.953125, 0.953125, 0.96875, 0.96875, 0.984375, 0.984375, 0.9765625, 0.9765625, 0.953125, 0.953125, 0.9765625, 0.9765625, 0.984375, 0.984375, 0.9609375, 0.9609375, 0.96875, 0.96875, 0.96875, 0.96875, 0.9453125, 0.9453125, 0.9473684210526315, 0.9473684210526315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.015625, 0.0703125, 0.0703125, 0.171875, 0.171875, 0.328125, 0.328125, 0.4921875, 0.4921875, 0.5859375, 0.5859375, 0.6484375, 0.6484375, 0.6875, 0.6875, 0.6796875, 0.6796875, 0.765625, 0.765625, 0.703125, 0.703125, 0.71875, 0.71875, 0.796875, 0.796875, 0.7265625, 0.7265625, 0.6484375, 0.6484375, 0.71875, 0.71875, 0.7109375, 0.7109375, 0.7890625, 0.7890625, 0.8671875, 0.8671875, 0.953125, 0.953125, 0.90625, 0.90625, 0.9453125, 0.9453125, 0.9609375, 0.9609375, 0.9375, 0.9375, 0.921875, 0.921875, 0.9453125, 0.9453125, 0.8984375, 0.8984375, 0.9140625, 0.9140625, 0.953125, 0.953125, 0.953125, 0.953125, 0.96875, 0.96875, 0.9609375, 0.9609375, 0.9375, 0.9375, 0.9765625, 0.9765625, 0.953125, 0.953125, 0.9375, 0.9375, 0.96875, 0.96875, 0.953125, 0.953125, 0.9765625, 0.9765625, 0.9609375, 0.9609375, 0.9765625, 0.9765625, 0.9609375, 0.9609375, 0.9765625, 0.9765625, 0.984375, 0.984375, 0.9921875, 0.9921875, 0.953125, 0.953125, 0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.9453125, 0.9453125, 0.96875, 0.96875, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.984375, 0.984375, 0.96875, 0.96875, 0.984375, 0.984375, 0.984375, 0.984375, 0.9921875, 0.9921875, 0.9765625, 0.9765625, 0.9921875, 0.9921875, 0.9765625, 0.9765625, 0.984375, 0.984375, 0.9921259842519685, 0.9921259842519685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0078125, 0.046875, 0.046875, 0.171875, 0.171875, 0.3671875, 0.3671875, 0.359375, 0.359375, 0.4453125, 0.4453125, 0.4140625, 0.4140625, 0.4921875, 0.4921875, 0.4765625, 0.4765625, 0.5078125, 0.5078125, 0.484375, 0.484375, 0.453125, 0.453125, 0.5234375, 0.5234375, 0.453125, 0.453125, 0.5390625, 0.5390625, 0.5078125, 0.5078125, 0.546875, 0.546875, 0.6484375, 0.6484375, 0.59375, 0.59375, 0.6953125, 0.6953125, 0.828125, 0.828125, 0.8203125, 0.8203125, 0.875, 0.875, 0.9375, 0.9375, 0.9140625, 0.9140625, 0.9453125, 0.9453125, 0.921875, 0.921875, 0.96875, 0.96875, 0.96875, 0.96875, 0.9765625, 0.9765625, 0.984375, 0.984375, 0.984375, 0.984375, 1.0, 1.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9765625, 0.9765625, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 0.96875, 0.984375, 0.984375, 0.984375, 0.984375, 1.0, 1.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.984375, 0.984375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.984375, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 0.9765625, 0.9765625, 0.984375, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0078125, 0.03125, 0.03125, 0.0703125, 0.0703125, 0.0625, 0.0625, 0.1015625, 0.1015625, 0.1484375, 0.1484375, 0.125, 0.125, 0.15625, 0.15625, 0.1953125, 0.1953125, 0.1875, 0.1875, 0.265625, 0.265625, 0.2578125, 0.2578125, 0.265625, 0.265625, 0.3125, 0.3125, 0.3359375, 0.3359375, 0.375, 0.375, 0.4296875, 0.4296875, 0.4765625, 0.4765625, 0.515625, 0.515625, 0.6796875, 0.6796875, 0.6875, 0.6875, 0.75, 0.75, 0.8828125, 0.8828125, 0.8515625, 0.8515625, 0.921875, 0.921875, 0.9453125, 0.9453125, 0.9296875, 0.9296875, 0.953125, 0.953125, 0.9609375, 0.9609375, 0.984375, 0.984375, 0.953125, 0.953125, 0.9296875, 0.9296875, 0.9453125, 0.9453125, 0.953125, 0.953125, 0.953125, 0.953125, 0.9375, 0.9375, 0.953125, 0.953125, 0.953125, 0.953125, 0.9375, 0.9375, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.953125, 0.953125, 0.9453125, 0.9453125, 0.9609375, 0.9609375, 0.9765625, 0.9765625, 0.9453125, 0.9453125, 0.96875, 0.96875, 0.9765625, 0.9765625, 0.953125, 0.953125, 0.9765625, 0.9765625, 0.984375, 0.984375, 0.96875, 0.96875, 0.9609375, 0.9609375, 0.953125, 0.953125, 0.953125, 0.953125, 0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.9609375, 0.953125, 0.953125, 0.9375, 0.9375, 0.984375, 0.984375, 0.9583333333333334, 0.9583333333333334])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train ensembles - single guru\u001b[39;00m\n\u001b[1;32m      3\u001b[0m one_active_exp \u001b[38;5;241m=\u001b[39m Experiment(n_trials\u001b[38;5;241m=\u001b[39mnum_trials, ensembles\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(ensembles_dict\u001b[38;5;241m.\u001b[39mvalues()), benchmark\u001b[38;5;241m=\u001b[39mdata, strategies_to_evaluate\u001b[38;5;241m=\u001b[39mstrategies_to_evaluate)\n\u001b[0;32m----> 4\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mone_active_exp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VSCode/banditLiquidDem/exp_framework/experiment.py:55\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trials)):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Set seed for reproducibility\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     seed_everything(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m+\u001b[39m t)\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_metric_values\n",
      "File \u001b[0;32m~/VSCode/banditLiquidDem/exp_framework/experiment.py:178\u001b[0m, in \u001b[0;36mExperiment.single_trial\u001b[0;34m(self, trial_num)\u001b[0m\n\u001b[1;32m    176\u001b[0m batch_acc \u001b[38;5;241m=\u001b[39m eval_plugin\u001b[38;5;241m.\u001b[39mget_all_metrics()\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_acc)\n\u001b[0;32m--> 178\u001b[0m \u001b[43mexit\u001b[49m()\n\u001b[1;32m    179\u001b[0m batch_t, batch_acc \u001b[38;5;241m=\u001b[39m batch_acc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop1_Acc_MB/test_phase/test_stream/Task000\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, ba \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_acc):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# Train ensembles - single guru\n",
    "\n",
    "one_active_exp = Experiment(n_trials=num_trials, ensembles=list(ensembles_dict.values()), benchmark=data, strategies_to_evaluate=strategies_to_evaluate)\n",
    "_ = one_active_exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics = one_active_exp.get_aggregate_batch_metrics()\n",
    "dfs = []\n",
    "for ens, metric_dict in batch_metrics.items():\n",
    "    df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "    df[\"ensemble_name\"] = ens\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "col_order = [len(df.columns)-1] + list(range(len(df.columns)-1))\n",
    "df = df[df.columns[col_order]]\n",
    "print(df)\n",
    "file_prefix = f\"class_incremental_single_guru-trials={num_trials}-batch_size={batch_size}_window_size={window_size}\"\n",
    "path = \"results\"\n",
    "\n",
    "df.to_csv(f\"{path}/{file_prefix}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results - single guru\n",
    "\n",
    "print(f\"Results for mechanisms with max_active_gurus = {max_active_gurus}:\")\n",
    "\n",
    "# Collect and print train accuracies - aggregate and by batch\n",
    "train_results_dict = dict()\n",
    "for ens_name, ensemble in ensembles_dict.items():\n",
    "    train_acc, train_acc_std = calculate_avg_std_train_accs(\n",
    "        one_active_exp, ens_name, num_trials\n",
    "    )\n",
    "    train_results_dict[ens_name] = (train_acc, train_acc_std)\n",
    "\n",
    "for ens_name, (train_acc, train_acc_std) in train_results_dict.items():\n",
    "    print(f\"Mean train acc for {ens_name}: {round(np.mean(train_acc), 3)}+-{round(np.mean(train_acc_std), 3)}\")\n",
    "# for ens_name, (train_acc, train_acc_std) in train_results_dict.items():\n",
    "#     print(f\"All train accs for {ens_name}: {train_acc}\")\n",
    "    \n",
    "print(\"--------------\")\n",
    "\n",
    "# Collect and print test accuracies\n",
    "results_dict = dict()\n",
    "for ens_name, ensemble in ensembles_dict.items():\n",
    "    test_acc, test_acc_std = calculate_avg_std_test_accs(\n",
    "        one_active_exp, ens_name, num_trials\n",
    "    )\n",
    "    results_dict[ens_name] = (test_acc, test_acc_std)\n",
    "\n",
    "for ens_name, (test_acc, test_acc_std) in results_dict.items():\n",
    "    print(f\"Mean test acc for {ens_name}: {round(np.mean(test_acc), 3)}+-{round(np.mean(test_acc_std), 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many Active Voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Delegation Mechanisms - single guru\n",
    "\n",
    "NOOP_del_mech = DelegationMechanism(batch_size=batch_size, window_size=window_size)\n",
    "\n",
    "probability_functions = [\"random_better\", \"probabilistic_better\", \"probabilistic_weighted\"]\n",
    "score_functions = [\n",
    "                   \"accuracy_score\",\n",
    "                   \"balanced_accuracy_score\",\n",
    "                   \"f1_score\",\n",
    "                   \"precision_score\",\n",
    "                   \"recall_score\",\n",
    "                   \"top_k_accuracy_score\",\n",
    "                   \"roc_auc_score\",\n",
    "                   \"log_loss_score\",\n",
    "                   ]\n",
    "max_active_gurus = 3\n",
    "\n",
    "del_mechs = {\n",
    "    \"full-ensemble\": NOOP_del_mech\n",
    "}\n",
    "for prob_func, score_func in product(probability_functions, score_functions):\n",
    "    dm = ProbaSlopeDelegationMechanism(\n",
    "        batch_size=batch_size,\n",
    "        window_size=window_size,\n",
    "        max_active=max_active_gurus,\n",
    "        probability_function=prob_func,\n",
    "        score_method=score_func\n",
    "        )\n",
    "    del_mechs[f\"{prob_func}-{score_func}\"] = dm\n",
    "\n",
    "\n",
    "many_active_ensembles_dict = {\n",
    "    dm_name: Ensemble(\n",
    "        training_epochs=1,\n",
    "        n_voters=n_voters,\n",
    "        delegation_mechanism=dm,\n",
    "        name=dm_name,\n",
    "        input_dim=28 * 28,\n",
    "        output_dim=10,\n",
    "    )\n",
    "    for dm_name, dm in del_mechs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment - Many gurus\n",
    "\n",
    "many_active_exp = Experiment(n_trials=num_trials, ensembles=list(many_active_ensembles_dict.values()), data=data, seed=4090)\n",
    "_ = many_active_exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Results for mechanisms with max_active_gurus = {max_active_gurus}:\")\n",
    "\n",
    "# Collect and print train accuracies - aggregate and by batch\n",
    "train_results_dict = dict()\n",
    "for ens_name, ensemble in many_active_ensembles_dict.items():\n",
    "    train_acc, train_acc_std = calculate_avg_std_train_accs(\n",
    "        many_active_exp, ens_name, num_trials\n",
    "    )\n",
    "    train_results_dict[ens_name] = (train_acc, train_acc_std)\n",
    "\n",
    "for ens_name, (train_acc, train_acc_std) in train_results_dict.items():\n",
    "    print(f\"Mean train acc for {ens_name}: {round(np.mean(train_acc), 3)}+-{round(np.mean(train_acc_std), 3)}\")\n",
    "# for ens_name, (train_acc, train_acc_std) in train_results_dict.items():\n",
    "#     print(f\"All train accs for {ens_name}: {train_acc}\")\n",
    "    \n",
    "print(\"--------------\")\n",
    "\n",
    "# Collect and print test accuracies\n",
    "results_dict = dict()\n",
    "for ens_name, ensemble in many_active_ensembles_dict.items():\n",
    "    test_acc, test_acc_std = calculate_avg_std_test_accs(\n",
    "        many_active_exp, ens_name, num_trials\n",
    "    )\n",
    "    results_dict[ens_name] = (test_acc, test_acc_std)\n",
    "\n",
    "for ens_name, (test_acc, test_acc_std) in results_dict.items():\n",
    "    print(f\"Mean test acc for {ens_name}: {round(np.mean(test_acc), 3)}+-{round(np.mean(test_acc_std), 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Comparison with Avalanche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_framework.learning import Net\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training.supervised import Naive, CWRStar, Replay, GDumb, Cumulative, LwF, GEM, AGEM, EWC  # and many more!\n",
    "from avalanche.benchmarks.classic import RotatedMNIST, SplitMNIST\n",
    "from avalanche.training.plugins import ReplayPlugin\n",
    "import pprint\n",
    "\n",
    "model = Net(input_dim=28 * 28, output_dim=10)\n",
    "optimize = Adam(model.parameters(), lr=0.001)\n",
    "replay = ReplayPlugin(mem_size=100)\n",
    "\n",
    "cl_strategy = Naive(\n",
    "    model, optimizer=optimize, criterion=CrossEntropyLoss(),\n",
    "    train_mb_size=128, train_epochs=1, eval_mb_size=128,\n",
    "    # plugins=[replay]\n",
    ")\n",
    "# optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# model = SimpleMLP(num_classes=10)\n",
    "# criterion = CrossEntropyLoss()\n",
    "# cl_strategy = Naive(\n",
    "#     model, SGD(model.parameters(), lr=0.001, momentum=0.9), criterion,\n",
    "#     train_mb_size=100, train_epochs=4, eval_mb_size=100\n",
    "# )\n",
    "\n",
    "\n",
    "# scenario\n",
    "# benchmark = RotatedMNIST(n_experiences=5, seed=1)\n",
    "benchmark = SplitMNIST(n_experiences=5, fixed_class_order=list(range(10)), seed=1)\n",
    "\n",
    "# TRAINING LOOP\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "for experience in benchmark.train_stream:\n",
    "    print(\"Start of experience: \", experience.current_experience)\n",
    "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
    "\n",
    "    cl_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the whole test set')\n",
    "    results.append(cl_strategy.eval(benchmark.test_stream))\n",
    "\n",
    "for r in results:\n",
    "    pprint.pprint(r)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.classic import RotatedMNIST\n",
    "\n",
    "# scenario\n",
    "benchmark = RotatedMNIST(n_experiences=5, seed=1)\n",
    "\n",
    "# TRAINING LOOP\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "for experience in benchmark.train_stream:\n",
    "    print(\"Start of experience: \", experience.current_experience)\n",
    "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
    "\n",
    "    cl_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the whole test set')\n",
    "    results.append(cl_strategy.eval(benchmark.test_stream))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Results\n",
    "\n",
    "(leftover copied code from other file, not adapted for the above code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = \"Georgia\"\n",
    "\n",
    "# set colors for each bar. Use pastel\n",
    "colors = sns.color_palette(\"pastel\")\n",
    "# assign colors for each bar\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Test Accuracies\")\n",
    "ax.set_ylabel(\"Test Accuracy\")\n",
    "ax.set_xlabel(\"Delegation Mechanism\")\n",
    "# ax.set_xticks([0, 1, 2])\n",
    "# ax.set_xticklabels(\n",
    "#     [\"No Delegation\", \"Proba Slope\", \"Restricted Max Guru\"], rotation=45, ha=\"right\"\n",
    "# )\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"No Delegation\", \"Proba Slope\"], rotation=45, ha=\"right\")\n",
    "# Data for bar plot\n",
    "means = [\n",
    "    np.mean(full_avg_test_accs),\n",
    "    np.mean(proba_slope_avg_test_accs),\n",
    "    # np.mean(restricted_max_guru_avg_test_accs),\n",
    "]\n",
    "stds = [\n",
    "    np.std(full_avg_test_accs),\n",
    "    np.std(proba_slope_avg_test_accs),\n",
    "    # np.std(restricted_max_guru_avg_test_accs),\n",
    "]\n",
    "\n",
    "# Create each bar individually to set different colors\n",
    "for i in range(len(ensembles)):\n",
    "    ax.bar(i, means[i], color=colors[i], yerr=stds[i], capsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_slope_avg_train_accs, proba_slope_std_train_accs = calculate_avg_std_train_accs(\n",
    "    exp, \"proba_slope_delegations\", num_trials\n",
    ")\n",
    "full_avg_train_accs, full_std_train_accs = calculate_avg_std_train_accs(\n",
    "    exp, \"full_ensemble\", num_trials\n",
    ")\n",
    "\n",
    "# (\n",
    "#     restricted_max_guru_avg_train_accs,\n",
    "#     restricted_max_guru_std_train_accs,\n",
    "# ) = calculate_avg_std_train_accs(exp, \"restricted_max_guru_delegations\", num_trials)\n",
    "\n",
    "print(\n",
    "    \"Mean train accs for proba_slope delegation ensemble: \",\n",
    "    np.mean(proba_slope_avg_train_accs),\n",
    ")\n",
    "print(\"Mean train accs for full ensemble: \", np.mean(full_avg_train_accs))\n",
    "\n",
    "# print(\n",
    "#     \"Mean train accs for restricted_max_guru delegation ensemble: \",\n",
    "#     np.mean(restricted_max_guru_avg_train_accs),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits = exp.train_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"pastel\", context=\"paper\")\n",
    "\n",
    "# Set the font to Georgia\n",
    "mpl.rcParams[\"font.family\"] = \"Georgia\"\n",
    "mpl.rcParams[\"font.size\"] = 12\n",
    "mpl.rcParams[\"axes.labelsize\"] = 14\n",
    "mpl.rcParams[\"axes.titlesize\"] = 16\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "colors = sns.color_palette(\"pastel\")\n",
    "proba_slope_color = colors[1]\n",
    "full_color = colors[0]\n",
    "restricted_max_guru_color = colors[2]\n",
    "\n",
    "ax.plot(\n",
    "    proba_slope_avg_train_accs,\n",
    "    label=\"ProbaSlope Delegation Ensemble\",\n",
    "    color=proba_slope_color,\n",
    "    linewidth=2,\n",
    ")\n",
    "ax.fill_between(\n",
    "    range(len(proba_slope_avg_train_accs)),\n",
    "    np.array(proba_slope_avg_train_accs) - np.array(proba_slope_std_train_accs),\n",
    "    np.array(proba_slope_avg_train_accs) + np.array(proba_slope_std_train_accs),\n",
    "    color=proba_slope_color,\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "ax.plot(full_avg_train_accs, label=\"Full Ensemble\", color=full_color, linewidth=2)\n",
    "ax.fill_between(\n",
    "    range(len(full_avg_train_accs)),\n",
    "    np.array(full_avg_train_accs) - np.array(full_std_train_accs),\n",
    "    np.array(full_avg_train_accs) + np.array(full_std_train_accs),\n",
    "    color=full_color,\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "# ax.plot(\n",
    "#     restricted_max_guru_avg_train_accs,\n",
    "#     label=\"Restricted Max Guru Delegation Ensemble\",\n",
    "#     color=restricted_max_guru_color,\n",
    "#     linewidth=2,\n",
    "# )\n",
    "# ax.fill_between(\n",
    "#     range(len(restricted_max_guru_avg_train_accs)),\n",
    "#     np.array(restricted_max_guru_avg_train_accs)\n",
    "#     - np.array(restricted_max_guru_std_train_accs),\n",
    "#     np.array(restricted_max_guru_avg_train_accs)\n",
    "#     + np.array(restricted_max_guru_std_train_accs),\n",
    "#     color=colors[2],\n",
    "#     alpha=0.3,\n",
    "# )\n",
    "\n",
    "\n",
    "# plot vertical lines at test splits\n",
    "for split in train_splits[:-1]:\n",
    "    ax.axvline(x=split, color=\"k\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Setting labels, title, and legend\n",
    "ax.set_xlabel(\"Batch Number\")\n",
    "ax.set_ylabel(\"Train Accuracy\")\n",
    "ax.set_title(\n",
    "    \"ProbaSlope Delegation Ensemble vs Full Ensemble vs Restricted Max Guru Delegation Ensemble\"\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "# set y lim to lower\n",
    "ax.set_ylim(top=1.3)\n",
    "# set y ticks to 0-1\n",
    "ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_voters = exp.ensembles[1].voters\n",
    "print(ensembles[1].name)\n",
    "batch_accs = []\n",
    "for v in ps_voters:\n",
    "    batch_accs.append(v.batch_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len(data.train_data_loader.dataset) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_active_streaks(voter_id, trial_num):\n",
    "    \"\"\"\n",
    "    Find active streaks for a specified voter.\n",
    "\n",
    "    :param voter_id: ID of the voter for which to find active streaks.\n",
    "    :param batch_metric_values: Dictionary containing the batch metric values.\n",
    "    :param metric_key: Key to access the relevant metric in batch_metric_values.\n",
    "    :return: List of active streaks for the specified voter.\n",
    "    \"\"\"\n",
    "    active_batches = []\n",
    "    active_streak = [None, None]\n",
    "    voter_active = False\n",
    "\n",
    "    for i, av in enumerate(\n",
    "        exp.batch_metric_values[\"proba_slope_delegations\"][trial_num][\n",
    "            \"active_voters-train\"\n",
    "        ]\n",
    "    ):\n",
    "        # print(av)\n",
    "        if voter_id in av:\n",
    "            if not voter_active:\n",
    "                # Start a new streak\n",
    "                active_streak[0] = i\n",
    "                voter_active = True\n",
    "                # print(\"streak started\")\n",
    "            active_streak[1] = i\n",
    "        else:\n",
    "            if voter_active:\n",
    "                # End the current streak\n",
    "                active_batches.append(active_streak.copy())\n",
    "                active_streak = [None, None]\n",
    "                voter_active = False\n",
    "                # print(\"streak done\")\n",
    "\n",
    "    # Handle case where the streak continues till the end of the list\n",
    "    if voter_active:\n",
    "        active_batches.append(active_streak.copy())\n",
    "\n",
    "    return active_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at activity on last trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for voter_id in range(n_voters):\n",
    "    active_streaks = find_active_streaks(voter_id, num_trials - 1)\n",
    "    # print(f\"Active Streaks for Voter {voter_id}: {active_streaks}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))  # Create a new figure for each voter\n",
    "    plt.plot(batch_accs[voter_id])\n",
    "    plt.axvline(x=len_train, color=\"k\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # Shade the active batches for this voter\n",
    "    for streak in active_streaks:\n",
    "        if streak[0] is not None and streak[1] is not None:\n",
    "            plt.axvspan(streak[0], streak[1], alpha=0.3, color=\"red\")\n",
    "\n",
    "    # Plot a green vertical line at all train splits\n",
    "    for split in train_splits[:-1]:\n",
    "        plt.axvline(x=split, color=\"g\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "    plt.title(f\"Voter {voter_id} Activity\")\n",
    "    plt.xlabel(\"Batches\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()  # Display the plot for each voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
