{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from exp_framework.Ensemble import Ensemble, PretrainedEnsemble, StudentExpertEnsemble\n",
    "from exp_framework.delegation import (\n",
    "    DelegationMechanism,\n",
    "    UCBDelegationMechanism,\n",
    "    ProbaSlopeDelegationMechanism,\n",
    "    RestrictedMaxGurusDelegationMechanism,\n",
    "    StudentExpertDelegationMechanism,\n",
    ")\n",
    "from exp_framework.learning import Net\n",
    "from exp_framework.experiment import (\n",
    "    Experiment,\n",
    "    calculate_avg_std_test_accs,\n",
    "    calculate_avg_std_train_accs,\n",
    "    calculate_avg_std_test_accs_per_trial,\n",
    ")\n",
    "from avalanche.training.supervised import Naive\n",
    "from matplotlib import pyplot as plt\n",
    "from exp_framework.data_utils import Data\n",
    "from avalanche.benchmarks.classic import RotatedMNIST, SplitMNIST\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.plugins import (\n",
    "    CWRStarPlugin,\n",
    "    ReplayPlugin,\n",
    "    EWCPlugin,\n",
    "    TrainGeneratorAfterExpPlugin,\n",
    "    LwFPlugin,\n",
    "    SynapticIntelligencePlugin,\n",
    ")\n",
    "from exp_framework.MinibatchEvalAccuracy import MinibatchEvalAccuracy\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import accuracy_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning the mapping $\\mathcal{X} \\rightarrow \\mathcal{G}$ (i.e. $\\mathcal{X} \\rightarrow \\mathcal{Y}\\times\\mathcal{C}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up global experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "window_size = 400\n",
    "num_trials = 10\n",
    "n_voters = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Delegation Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Delegation Mechanisms and Ensembles\n",
    "\n",
    "For simplicity, only explore full ensemble and variants of ProbaSlopeDelegationMechanism since they can be created programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensembles_dict(lo_num_gurus=[1, 2, 3, 4]):\n",
    "    NOOP_del_mech = DelegationMechanism(batch_size=batch_size, window_size=window_size)\n",
    "    NOOP_del_mech2 = DelegationMechanism(batch_size=batch_size, window_size=window_size)\n",
    "\n",
    "    probability_functions = [\n",
    "        \"random_better\",\n",
    "        \"probabilistic_better\",\n",
    "        \"probabilistic_weighted\",\n",
    "        \"max_diversity\",\n",
    "    ]\n",
    "    score_functions = [\n",
    "        \"accuracy_score\",\n",
    "        \"balanced_accuracy_score\",\n",
    "        \"f1_score\",\n",
    "        # \"precision_score\",\n",
    "        # \"recall_score\",\n",
    "        # \"top_k_accuracy_score\",\n",
    "        # \"roc_auc_score\",\n",
    "        # \"log_loss_score\",\n",
    "        # \"max_diversity\",\n",
    "    ]\n",
    "    # probability_functions = [\"max_diversity\"]\n",
    "    # score_functions = [\"accuracy_score\"]\n",
    "\n",
    "    del_mechs = {\"full-ensemble\": NOOP_del_mech}\n",
    "    for prob_func, score_func in product(probability_functions, score_functions):\n",
    "        for num_gurus in lo_num_gurus:\n",
    "            dm = ProbaSlopeDelegationMechanism(\n",
    "                batch_size=batch_size,\n",
    "                window_size=window_size,\n",
    "                max_active=num_gurus,\n",
    "                probability_function=prob_func,\n",
    "                score_method=score_func,\n",
    "            )\n",
    "            del_mechs[f\"{prob_func}-{score_func}-num_gurus-{num_gurus}\"] = dm\n",
    "\n",
    "    for num_train_gurus in lo_num_gurus:\n",
    "        for num_test_gurus in lo_num_gurus:\n",
    "            dm = StudentExpertDelegationMechanism(\n",
    "                batch_size=batch_size,\n",
    "                window_size=window_size,\n",
    "                max_active_train=num_train_gurus,\n",
    "                max_active_test=num_test_gurus,\n",
    "            )\n",
    "            del_mechs[\n",
    "                f\"StudentExpert-num_train_gurus-{num_train_gurus}-num_test_gurus-{num_test_gurus}\"\n",
    "            ] = dm\n",
    "\n",
    "    ensembles_dict = {\n",
    "        dm_name: Ensemble(\n",
    "            training_epochs=1,\n",
    "            n_voters=n_voters,\n",
    "            delegation_mechanism=dm,\n",
    "            name=dm_name,\n",
    "            input_dim=28 * 28,\n",
    "            output_dim=10,\n",
    "        )\n",
    "        for dm_name, dm in del_mechs.items()\n",
    "    }\n",
    "    ensembles_dict[\"single_Net\"] = Ensemble(\n",
    "        training_epochs=1,\n",
    "        n_voters=1,\n",
    "        delegation_mechanism=NOOP_del_mech2,\n",
    "        name=\"single_Net\",\n",
    "        input_dim=28 * 28,\n",
    "        output_dim=10,\n",
    "    )\n",
    "    return ensembles_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Avalanche Strategies to Compare Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_strategies_to_evaluate():\n",
    "    plugins_to_evaluate = {\n",
    "        \"LwF\": LwFPlugin(),\n",
    "        \"EWC\": EWCPlugin(ewc_lambda=0.001),\n",
    "        \"SynapticIntelligence\": SynapticIntelligencePlugin(si_lambda=0.5),\n",
    "        # \"Replay\": ReplayPlugin(mem_size=100),\n",
    "    }\n",
    "\n",
    "    strategies_to_evaluate = {}\n",
    "    for name, pte in plugins_to_evaluate.items():\n",
    "        model = Net(input_dim=28 * 28, output_dim=10, width=512)\n",
    "        optimize = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        mb_eval = MinibatchEvalAccuracy()\n",
    "        evp = EvaluationPlugin(\n",
    "            accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            mb_eval,\n",
    "        )\n",
    "        cl_strategy = Naive(\n",
    "            model=model,\n",
    "            optimizer=optimize,\n",
    "            criterion=CrossEntropyLoss(),\n",
    "            train_mb_size=batch_size,\n",
    "            train_epochs=1,\n",
    "            eval_mb_size=batch_size,\n",
    "            # plugins=[pte, evp],\n",
    "            plugins=[pte, evp, mb_eval],\n",
    "        )\n",
    "        strategies_to_evaluate[name] = (cl_strategy, evp)\n",
    "\n",
    "    return strategies_to_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Active Voter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Ensemble - single active voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 29.09it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2547\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9251\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.58it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2497\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9264\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:17<00:00, 26.51it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2532\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9247\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.32it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9809\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9100\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.20it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2284\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9315\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 27.74it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2283\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9321\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 27.88it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7079\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9369\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:17<00:00, 27.14it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2079\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9370\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 27.81it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2138\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9359\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:17<00:00, 27.55it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5010\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9522\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:18<00:00, 25.67it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1879\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9439\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:17<00:00, 26.84it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1830\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9451\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 27.98it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7045\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9394\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:18<00:00, 25.21it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2267\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9340\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 27.70it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2215\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9366\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19ceb03a0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d6dd8a0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c3b2860>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x10d101960>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19ceb03a0>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.3082476265822785, 0.21499208860759494, 0.2806566455696203, 0.34375, 0.9573773734177216], 'random_better-accuracy_score-num_gurus-1': [0.9248417721518988, 0.35769382911392406, 0.34394778481012656, 0.8597705696202531, 0.42138053797468356], 'random_better-accuracy_score-num_gurus-2': [0.8581882911392406, 0.4006131329113924, 0.7818433544303798, 0.8565071202531646, 0.5773338607594937], 'random_better-accuracy_score-num_gurus-3': [0.8421677215189873, 0.2455498417721519, 0.41366693037974683, 0.9216772151898734, 0.8089398734177216], 'random_better-accuracy_score-num_gurus-4': [0.6875988924050633, 0.2242879746835443, 0.3182357594936709, 0.8443433544303798, 0.9401700949367089], 'random_better-balanced_accuracy_score-num_gurus-1': [0.9306764240506329, 0.2764042721518987, 0.41000791139240506, 0.8513647151898734, 0.3178401898734177], 'random_better-balanced_accuracy_score-num_gurus-2': [0.9162381329113924, 0.42138053797468356, 0.2791732594936709, 0.9078322784810127, 0.5158227848101266], 'random_better-balanced_accuracy_score-num_gurus-3': [0.8059731012658228, 0.37153876582278483, 0.3371242088607595, 0.9046677215189873, 0.8473101265822784], 'random_better-balanced_accuracy_score-num_gurus-4': [0.666435917721519, 0.24060522151898733, 0.3950751582278481, 0.8045886075949367, 0.9419501582278481], 'random_better-f1_score-num_gurus-1': [0.9290941455696202, 0.4261273734177215, 0.2962816455696203, 0.8421677215189873, 0.3142800632911392], 'random_better-f1_score-num_gurus-2': [0.915743670886076, 0.35888053797468356, 0.3092365506329114, 0.923556170886076, 0.5657634493670886], 'random_better-f1_score-num_gurus-3': [0.7755142405063291, 0.4651898734177215, 0.29222705696202533, 0.8879549050632911, 0.8944818037974683], 'random_better-f1_score-num_gurus-4': [0.7423852848101266, 0.22913370253164558, 0.37767009493670883, 0.8609572784810127, 0.9256329113924051], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9386867088607594, 0.18008306962025317, 0.21706882911392406, 0.8675830696202531, 0.26394382911392406], 'probabilistic_better-accuracy_score-num_gurus-2': [0.9179193037974683, 0.28827136075949367, 0.4137658227848101, 0.9194026898734177, 0.5257120253164557], 'probabilistic_better-accuracy_score-num_gurus-3': [0.8409810126582279, 0.2052017405063291, 0.507120253164557, 0.9136669303797469, 0.8095332278481012], 'probabilistic_better-accuracy_score-num_gurus-4': [0.682060917721519, 0.22695806962025317, 0.39556962025316456, 0.8316851265822784, 0.9377966772151899], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9359177215189873, 0.1428995253164557, 0.2491099683544304, 0.8575949367088608, 0.27501977848101267], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.9255340189873418, 0.2969738924050633, 0.41485363924050633, 0.911689082278481, 0.515625], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.8215981012658228, 0.21479430379746836, 0.5122626582278481, 0.8973496835443038, 0.8393987341772152], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.6443829113924051, 0.24030854430379747, 0.4834849683544304, 0.7652294303797469, 0.948378164556962], 'probabilistic_better-f1_score-num_gurus-1': [0.9376977848101266, 0.1395371835443038, 0.29875395569620256, 0.8589794303797469, 0.2776898734177215], 'probabilistic_better-f1_score-num_gurus-2': [0.9221716772151899, 0.18502768987341772, 0.4933742088607595, 0.9060522151898734, 0.5181962025316456], 'probabilistic_better-f1_score-num_gurus-3': [0.8347507911392406, 0.2244857594936709, 0.5424248417721519, 0.9089200949367089, 0.8133900316455697], 'probabilistic_better-f1_score-num_gurus-4': [0.689181170886076, 0.22596914556962025, 0.36886867088607594, 0.8381131329113924, 0.9440268987341772], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9382911392405063, 0.13469145569620253, 0.2671083860759494, 0.8549248417721519, 0.2818433544303797], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9274129746835443, 0.27175632911392406, 0.37035205696202533, 0.9148536392405063, 0.478935917721519], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.8268393987341772, 0.22685917721518986, 0.5300632911392406, 0.8952729430379747, 0.8104232594936709], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.6607001582278481, 0.28322784810126583, 0.40783227848101267, 0.8056764240506329, 0.9477848101265823], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9380933544303798, 0.1607001582278481, 0.1883900316455696, 0.8644185126582279, 0.2520767405063291], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9264240506329114, 0.27689873417721517, 0.40892009493670883, 0.9125791139240507, 0.5256131329113924], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.818631329113924, 0.21380537974683544, 0.5718947784810127, 0.8974485759493671, 0.8099287974683544], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.6677215189873418, 0.19699367088607594, 0.5110759493670886, 0.7947982594936709, 0.9382911392405063], 'probabilistic_weighted-f1_score-num_gurus-1': [0.9355221518987342, 0.13479034810126583, 0.2588014240506329, 0.853243670886076, 0.2643393987341772], 'probabilistic_weighted-f1_score-num_gurus-2': [0.9102056962025317, 0.19788370253164558, 0.5892998417721519, 0.9007120253164557, 0.47043117088607594], 'probabilistic_weighted-f1_score-num_gurus-3': [0.8182357594936709, 0.3142800632911392, 0.4248417721518987, 0.9036787974683544, 0.8433544303797469], 'probabilistic_weighted-f1_score-num_gurus-4': [0.6106606012658228, 0.22626582278481014, 0.39230617088607594, 0.7730419303797469, 0.9477848101265823], 'max_diversity-accuracy_score-num_gurus-1': [0.8798457278481012, 0.5279865506329114, 0.3344541139240506, 0.7901503164556962, 0.5423259493670886], 'max_diversity-accuracy_score-num_gurus-2': [0.8241693037974683, 0.5093947784810127, 0.478935917721519, 0.8303006329113924, 0.8356408227848101], 'max_diversity-accuracy_score-num_gurus-3': [0.8452333860759493, 0.24713212025316456, 0.5238330696202531, 0.903876582278481, 0.801621835443038], 'max_diversity-accuracy_score-num_gurus-4': [0.6023536392405063, 0.2588014240506329, 0.3112143987341772, 0.7792721518987342, 0.9472903481012658], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.9023931962025317, 0.4465981012658228, 0.3682753164556962, 0.8515625, 0.4886273734177215], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.8565071202531646, 0.4686511075949367, 0.4771558544303797, 0.8215981012658228, 0.8115110759493671], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.7518789556962026, 0.3785601265822785, 0.4221716772151899, 0.8482990506329114, 0.919501582278481], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.6865110759493671, 0.23516613924050633, 0.372626582278481, 0.8207080696202531, 0.9359177215189873], 'max_diversity-f1_score-num_gurus-1': [0.8814280063291139, 0.45708069620253167, 0.6556566455696202, 0.7953916139240507, 0.47260680379746833], 'max_diversity-f1_score-num_gurus-2': [0.796182753164557, 0.5935522151898734, 0.5357001582278481, 0.7902492088607594, 0.8178401898734177], 'max_diversity-f1_score-num_gurus-3': [0.8465189873417721, 0.25267009493670883, 0.41574367088607594, 0.935126582278481, 0.78125], 'max_diversity-f1_score-num_gurus-4': [0.6037381329113924, 0.22280458860759494, 0.3738132911392405, 0.7544501582278481, 0.9456091772151899], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.9309731012658228, 0.9004153481012658, 0.4293908227848101, 0.9414556962025317, 0.9407634493670886], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.9356210443037974, 0.9099090189873418, 0.3881526898734177, 0.9408623417721519, 0.9387856012658228], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.9342365506329114, 0.9087223101265823, 0.31507120253164556, 0.9319620253164557, 0.9227650316455697], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.9341376582278481, 0.20806962025316456, 0.8566060126582279, 0.9074367088607594, 0.9009098101265823], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9298852848101266, 0.2830300632911392, 0.9097112341772152, 0.9432357594936709, 0.9355221518987342], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.9321598101265823, 0.2619659810126582, 0.9115901898734177, 0.9466969936708861, 0.9418512658227848], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.9371044303797469, 0.2935126582278481, 0.9121835443037974, 0.9385878164556962, 0.9403678797468354], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9324564873417721, 0.9160403481012658, 0.4107990506329114, 0.9336431962025317, 0.9432357594936709], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.8571993670886076, 0.2842167721518987, 0.9037776898734177, 0.9486748417721519, 0.9431368670886076], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8569026898734177, 0.8966574367088608, 0.9024920886075949, 0.9541139240506329, 0.9451147151898734], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.8629351265822784, 0.8958662974683544, 0.8544303797468354, 0.9529272151898734, 0.9466969936708861], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.8705498417721519, 0.3116099683544304, 0.9098101265822784, 0.9523338607594937, 0.9445213607594937], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.8297072784810127, 0.30399525316455694, 0.8808346518987342, 0.940565664556962, 0.939873417721519], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.8228837025316456, 0.2903481012658228, 0.8594738924050633, 0.9399723101265823, 0.9447191455696202], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.8650118670886076, 0.3158623417721519, 0.7694818037974683, 0.9526305379746836, 0.946993670886076], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.8536392405063291, 0.26364715189873417, 0.7889636075949367, 0.9434335443037974, 0.9455102848101266], 'single_Net': [0.2733386075949367, 0.19897151898734178, 0.25731803797468356, 0.3360363924050633, 0.9503560126582279]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.44it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1707\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5553\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.29it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.0051\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2629\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.42it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.6253\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4040\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.42it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9652\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6461\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 31.88it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2771\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9708\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.2087\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5678\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.21it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.8191\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3326\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.59it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.7258\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2286\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.01it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.4921\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3260\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.19it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.9248\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3357\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.03it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1182\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9636\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.0160\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4373\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.36it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.6452\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3599\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.10it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.5511\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2369\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 32.58it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.8925\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2897\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.06it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.5956\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3896\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 33.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [1:13:23<11:00:33, 4403.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1040\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9666\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.9577\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4485\n",
      "Starting trial  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.86it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2549\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9255\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.01it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2544\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9240\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 27.81it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2519\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9245\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.26it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9767\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9105\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.20it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2321\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9318\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:17<00:00, 27.05it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2372\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9293\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.95it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6793\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9403\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 27.62it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2156\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9356\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.29it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2165\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9361\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.42it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4941\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9528\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.36it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1827\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9438\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.15it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1844\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9444\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.01it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7035\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9378\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 29.02it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2198\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9354\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.05it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2279\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9348\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d6dc910>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1a0fae4a0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1e3174550>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1e3174430>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1a0fae4a0>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.3256526898734177, 0.2064873417721519, 0.3112143987341772, 0.36342958860759494, 0.9567840189873418], 'random_better-accuracy_score-num_gurus-1': [0.8982397151898734, 0.5289754746835443, 0.46499208860759494, 0.8445411392405063, 0.518690664556962], 'random_better-accuracy_score-num_gurus-2': [0.8956685126582279, 0.2578125, 0.7512856012658228, 0.835245253164557, 0.629746835443038], 'random_better-accuracy_score-num_gurus-3': [0.785996835443038, 0.3683742088607595, 0.40625, 0.8928006329113924, 0.8536392405063291], 'random_better-accuracy_score-num_gurus-4': [0.5299643987341772, 0.23575949367088608, 0.4019976265822785, 0.6866099683544303, 0.9521360759493671], 'random_better-balanced_accuracy_score-num_gurus-1': [0.9049643987341772, 0.47310126582278483, 0.6285601265822784, 0.8255537974683544, 0.4014042721518987], 'random_better-balanced_accuracy_score-num_gurus-2': [0.9089200949367089, 0.3774723101265823, 0.484375, 0.9197982594936709, 0.5578520569620253], 'random_better-balanced_accuracy_score-num_gurus-3': [0.6955102848101266, 0.25504351265822783, 0.5956289556962026, 0.771064082278481, 0.9228639240506329], 'random_better-balanced_accuracy_score-num_gurus-4': [0.6365704113924051, 0.2155854430379747, 0.3966574367088608, 0.7970727848101266, 0.9447191455696202], 'random_better-f1_score-num_gurus-1': [0.9335443037974683, 0.2644382911392405, 0.25494462025316456, 0.8604628164556962, 0.3052808544303797], 'random_better-f1_score-num_gurus-2': [0.8992286392405063, 0.2803599683544304, 0.48951740506329117, 0.8282238924050633, 0.7059928797468354], 'random_better-f1_score-num_gurus-3': [0.8078520569620253, 0.29282041139240506, 0.5344145569620253, 0.8930973101265823, 0.8455300632911392], 'random_better-f1_score-num_gurus-4': [0.5426226265822784, 0.22705696202531644, 0.3460245253164557, 0.7568235759493671, 0.9464003164556962], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9374011075949367, 0.13310917721518986, 0.2981606012658228, 0.8320806962025317, 0.2524723101265823], 'probabilistic_better-accuracy_score-num_gurus-2': [0.9193037974683544, 0.18502768987341772, 0.6271756329113924, 0.893690664556962, 0.4709256329113924], 'probabilistic_better-accuracy_score-num_gurus-3': [0.8000395569620253, 0.22478243670886075, 0.6021558544303798, 0.8814280063291139, 0.8757911392405063], 'probabilistic_better-accuracy_score-num_gurus-4': [0.6258900316455697, 0.21054193037974683, 0.4946598101265823, 0.7356606012658228, 0.946993670886076], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9352254746835443, 0.13350474683544303, 0.29489715189873417, 0.8310917721518988, 0.25158227848101267], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.9234572784810127, 0.17563291139240506, 0.603935917721519, 0.885185917721519, 0.46706882911392406], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.798556170886076, 0.24960443037974683, 0.599881329113924, 0.8837025316455697, 0.8528481012658228], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.6446795886075949, 0.22023338607594936, 0.6407238924050633, 0.7042128164556962, 0.9346321202531646], 'probabilistic_better-f1_score-num_gurus-1': [0.9370055379746836, 0.13152689873417722, 0.28866693037974683, 0.8364319620253164, 0.25435126582278483], 'probabilistic_better-f1_score-num_gurus-2': [0.9131724683544303, 0.17751186708860758, 0.6481408227848101, 0.8830102848101266, 0.4853639240506329], 'probabilistic_better-f1_score-num_gurus-3': [0.8021162974683544, 0.22527689873417722, 0.6066060126582279, 0.8806368670886076, 0.8494857594936709], 'probabilistic_better-f1_score-num_gurus-4': [0.6717761075949367, 0.21588212025316456, 0.4319620253164557, 0.8049841772151899, 0.9420490506329114], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9333465189873418, 0.12678006329113925, 0.2797666139240506, 0.8284216772151899, 0.2563291139240506], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9196993670886076, 0.16999604430379747, 0.6037381329113924, 0.8697587025316456, 0.4840783227848101], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.8111155063291139, 0.1886867088607595, 0.5782238924050633, 0.8901305379746836, 0.8358386075949367], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.6356803797468354, 0.2100474683544304, 0.4284018987341772, 0.775118670886076, 0.9449169303797469], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9346321202531646, 0.14200949367088608, 0.35799050632911394, 0.828125, 0.27739319620253167], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9220727848101266, 0.17227056962025317, 0.6191653481012658, 0.884493670886076, 0.46944224683544306], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.8206091772151899, 0.2311115506329114, 0.5660601265822784, 0.900118670886076, 0.8458267405063291], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.6352848101265823, 0.2310126582278481, 0.5403481012658228, 0.7411985759493671, 0.9451147151898734], 'probabilistic_weighted-f1_score-num_gurus-1': [0.9343354430379747, 0.13350474683544303, 0.33781645569620256, 0.8278283227848101, 0.27848101265822783], 'probabilistic_weighted-f1_score-num_gurus-2': [0.9052610759493671, 0.18473101265822786, 0.627373417721519, 0.8730221518987342, 0.49980221518987344], 'probabilistic_weighted-f1_score-num_gurus-3': [0.8054786392405063, 0.20816851265822786, 0.5506329113924051, 0.8928006329113924, 0.8415743670886076], 'probabilistic_weighted-f1_score-num_gurus-4': [0.6536787974683544, 0.20302610759493672, 0.4293908227848101, 0.7818433544303798, 0.9475870253164557], 'max_diversity-accuracy_score-num_gurus-1': [0.9096123417721519, 0.36758306962025317, 0.4985166139240506, 0.8157634493670886, 0.31764240506329117], 'max_diversity-accuracy_score-num_gurus-2': [0.9148536392405063, 0.45450949367088606, 0.44907041139240506, 0.8932950949367089, 0.6638647151898734], 'max_diversity-accuracy_score-num_gurus-3': [0.6369659810126582, 0.30626977848101267, 0.4276107594936709, 0.7348694620253164, 0.943631329113924], 'max_diversity-accuracy_score-num_gurus-4': [0.5012856012658228, 0.18562104430379747, 0.3677808544303797, 0.6743473101265823, 0.9518393987341772], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.904568829113924, 0.46825553797468356, 0.5599287974683544, 0.8346518987341772, 0.346815664556962], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.888943829113924, 0.48397943037974683, 0.49020965189873417, 0.8812302215189873, 0.5905854430379747], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.6355814873417721, 0.333564082278481, 0.44155458860759494, 0.717068829113924, 0.9386867088607594], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.6918512658227848, 0.2312104430379747, 0.3660996835443038, 0.8517602848101266, 0.9407634493670886], 'max_diversity-f1_score-num_gurus-1': [0.8932950949367089, 0.403184335443038, 0.6113528481012658, 0.8305973101265823, 0.37569224683544306], 'max_diversity-f1_score-num_gurus-2': [0.9210838607594937, 0.3497824367088608, 0.41791930379746833, 0.9113924050632911, 0.6248022151898734], 'max_diversity-f1_score-num_gurus-3': [0.5699169303797469, 0.35472705696202533, 0.48150712025316456, 0.631131329113924, 0.9428401898734177], 'max_diversity-f1_score-num_gurus-4': [0.5783227848101266, 0.21924446202531644, 0.39220727848101267, 0.7368473101265823, 0.9512460443037974], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.9322587025316456, 0.25, 0.9432357594936709, 0.9170292721518988, 0.940565664556962], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.9323575949367089, 0.24080300632911392, 0.9059533227848101, 0.9335443037974683, 0.9369066455696202], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.9357199367088608, 0.25514240506329117, 0.9253362341772152, 0.9241495253164557, 0.9291930379746836], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.9415545886075949, 0.19560917721518986, 0.885185917721519, 0.8947784810126582, 0.8880537974683544], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9216772151898734, 0.2700751582278481, 0.9241495253164557, 0.9369066455696202, 0.9421479430379747], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.9329509493670886, 0.26641613924050633, 0.9285007911392406, 0.9384889240506329, 0.9459058544303798], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.9361155063291139, 0.2749208860759494, 0.9349287974683544, 0.9474881329113924, 0.9425435126582279], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9256329113924051, 0.25, 0.9470925632911392, 0.9162381329113924, 0.9425435126582279], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.8489912974683544, 0.29173259493670883, 0.9318631329113924, 0.9414556962025317, 0.9400712025316456], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8647151898734177, 0.3202136075949367, 0.9026898734177216, 0.9467958860759493, 0.942939082278481], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.8377175632911392, 0.2950949367088608, 0.9103045886075949, 0.9374011075949367, 0.9464003164556962], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.8482990506329114, 0.2878757911392405, 0.9065466772151899, 0.9413568037974683, 0.9477848101265823], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.8091376582278481, 0.27927215189873417, 0.853243670886076, 0.9259295886075949, 0.9447191455696202], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.8095332278481012, 0.2825356012658228, 0.888943829113924, 0.8957674050632911, 0.9440268987341772], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.8237737341772152, 0.2711629746835443, 0.8253560126582279, 0.9292919303797469, 0.9474881329113924], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.7822389240506329, 0.24386867088607594, 0.8833069620253164, 0.8111155063291139, 0.9467958860759493], 'single_Net': [0.302314082278481, 0.1808742088607595, 0.30607199367088606, 0.30547863924050633, 0.9504549050632911]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.76it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1840\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5434\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.62it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.9886\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2581\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.73it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.5796\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4035\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.77it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9982\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6325\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.45it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2775\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9685\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.2056\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5612\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.92it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.8302\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3817\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.50it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.7411\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2275\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.43it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.7101\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3022\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.92it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.7176\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4094\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.59it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0995\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9688\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.0197\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4579\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.81it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.0742\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3338\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.07it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 4.0381\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1916\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.19it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.5583\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3082\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.31it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.7397\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3809\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [2:19:45<9:14:04, 4155.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1114\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9656\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.1043\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4360\n",
      "Starting trial  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.72it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2493\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9269\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.96it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2588\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9244\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.36it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2523\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9235\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.89it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9711\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9107\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.46it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2307\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9306\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.92it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2356\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9301\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6887\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9362\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.27it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2143\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9370\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.42it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2101\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9377\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.54it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4907\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9521\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.20it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1850\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9451\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.43it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1818\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9454\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.56it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7206\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9379\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.40it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2247\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9349\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.95it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2273\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9341\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d3781f0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d62fa00>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c21f6d0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d62fa00>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d3781f0>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.3115110759493671, 0.21380537974683544, 0.2689873417721519, 0.35344145569620256, 0.9580696202531646], 'random_better-accuracy_score-num_gurus-1': [0.9223694620253164, 0.35136471518987344, 0.28649129746835444, 0.8503757911392406, 0.3244659810126582], 'random_better-accuracy_score-num_gurus-2': [0.9184137658227848, 0.3602650316455696, 0.3029074367088608, 0.9054588607594937, 0.47933148734177217], 'random_better-accuracy_score-num_gurus-3': [0.790743670886076, 0.28293117088607594, 0.4541139240506329, 0.8891416139240507, 0.8631329113924051], 'random_better-accuracy_score-num_gurus-4': [0.6762262658227848, 0.22962816455696203, 0.3146756329113924, 0.8358386075949367, 0.9424446202531646], 'random_better-balanced_accuracy_score-num_gurus-1': [0.920193829113924, 0.2711629746835443, 0.4681566455696203, 0.8712420886075949, 0.32496044303797467], 'random_better-balanced_accuracy_score-num_gurus-2': [0.9277096518987342, 0.26048259493670883, 0.2950949367088608, 0.9154469936708861, 0.48051819620253167], 'random_better-balanced_accuracy_score-num_gurus-3': [0.7996439873417721, 0.3581882911392405, 0.45450949367088606, 0.8879549050632911, 0.8545292721518988], 'random_better-balanced_accuracy_score-num_gurus-4': [0.7375395569620253, 0.22290348101265822, 0.3191257911392405, 0.8973496835443038, 0.9236550632911392], 'random_better-f1_score-num_gurus-1': [0.9030854430379747, 0.37302215189873417, 0.32436708860759494, 0.8222903481012658, 0.29875395569620256], 'random_better-f1_score-num_gurus-2': [0.8813291139240507, 0.4209849683544304, 0.4674643987341772, 0.8504746835443038, 0.7759098101265823], 'random_better-f1_score-num_gurus-3': [0.7270569620253164, 0.5538963607594937, 0.26127373417721517, 0.8492879746835443, 0.8722310126582279], 'random_better-f1_score-num_gurus-4': [0.7174643987341772, 0.2309137658227848, 0.2991495253164557, 0.870253164556962, 0.9308742088607594], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9370055379746836, 0.1830498417721519, 0.23378164556962025, 0.8605617088607594, 0.27076740506329117], 'probabilistic_better-accuracy_score-num_gurus-2': [0.9198971518987342, 0.40585443037974683, 0.3102254746835443, 0.9056566455696202, 0.5121637658227848], 'probabilistic_better-accuracy_score-num_gurus-3': [0.8248615506329114, 0.2199367088607595, 0.5291732594936709, 0.9023931962025317, 0.8452333860759493], 'probabilistic_better-accuracy_score-num_gurus-4': [0.7025316455696202, 0.247626582278481, 0.33395965189873417, 0.861748417721519, 0.9371044303797469], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9285996835443038, 0.15100870253164558, 0.3079509493670886, 0.8448378164556962, 0.28510680379746833], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.9170292721518988, 0.4364121835443038, 0.294501582278481, 0.9121835443037974, 0.5427215189873418], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.7906447784810127, 0.2920292721518987, 0.4044699367088608, 0.8968552215189873, 0.8405854430379747], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.7098496835443038, 0.21776107594936708, 0.3149723101265823, 0.8713409810126582, 0.9311708860759493], 'probabilistic_better-f1_score-num_gurus-1': [0.9364121835443038, 0.17612737341772153, 0.24060522151898733, 0.8602650316455697, 0.25830696202531644], 'probabilistic_better-f1_score-num_gurus-2': [0.9284018987341772, 0.26166930379746833, 0.4217761075949367, 0.9118868670886076, 0.5088014240506329], 'probabilistic_better-f1_score-num_gurus-3': [0.7310126582278481, 0.47676028481012656, 0.3608583860759494, 0.8236748417721519, 0.890625], 'probabilistic_better-f1_score-num_gurus-4': [0.6654469936708861, 0.23022151898734178, 0.3395965189873418, 0.8235759493670886, 0.9443235759493671], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9338409810126582, 0.17335838607594936, 0.25039556962025317, 0.8581882911392406, 0.25504351265822783], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9240506329113924, 0.23744066455696203, 0.41426028481012656, 0.9078322784810127, 0.5027689873417721], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.8111155063291139, 0.29489715189873417, 0.4260284810126582, 0.9025909810126582, 0.866495253164557], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.6661392405063291, 0.2334849683544304, 0.3845925632911392, 0.805379746835443, 0.9425435126582279], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9343354430379747, 0.17128164556962025, 0.23427610759493672, 0.8578916139240507, 0.25741693037974683], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9244462025316456, 0.2611748417721519, 0.45777294303797467, 0.913370253164557, 0.4856606012658228], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.8072587025316456, 0.31062104430379744, 0.4209849683544304, 0.9020965189873418, 0.872626582278481], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.6373615506329114, 0.24030854430379747, 0.42770965189873417, 0.7743275316455697, 0.9441257911392406], 'probabilistic_weighted-f1_score-num_gurus-1': [0.9364121835443038, 0.18571993670886075, 0.2731408227848101, 0.8595727848101266, 0.268690664556962], 'probabilistic_weighted-f1_score-num_gurus-2': [0.9185126582278481, 0.41663370253164556, 0.31408227848101267, 0.9088212025316456, 0.49950553797468356], 'probabilistic_weighted-f1_score-num_gurus-3': [0.7392207278481012, 0.48417721518987344, 0.3389042721518987, 0.8554193037974683, 0.8614517405063291], 'probabilistic_weighted-f1_score-num_gurus-4': [0.6966969936708861, 0.22468354430379747, 0.43918117088607594, 0.8287183544303798, 0.939181170886076], 'max_diversity-accuracy_score-num_gurus-1': [0.8950751582278481, 0.5059335443037974, 0.6149129746835443, 0.8113132911392406, 0.40249208860759494], 'max_diversity-accuracy_score-num_gurus-2': [0.8696598101265823, 0.4297863924050633, 0.7311115506329114, 0.8509691455696202, 0.5370846518987342], 'max_diversity-accuracy_score-num_gurus-3': [0.6400316455696202, 0.5863330696202531, 0.26582278481012656, 0.7461431962025317, 0.9181170886075949], 'max_diversity-accuracy_score-num_gurus-4': [0.5824762658227848, 0.20599287974683544, 0.33000395569620256, 0.7317049050632911, 0.9471914556962026], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.9156447784810127, 0.44926819620253167, 0.5089992088607594, 0.8417721518987342, 0.3232792721518987], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.8362341772151899, 0.503065664556962, 0.3245648734177215, 0.8177412974683544, 0.8348496835443038], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.7477254746835443, 0.5137460443037974, 0.2731408227848101, 0.8676819620253164, 0.8735166139240507], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.7314082278481012, 0.24970332278481014, 0.30518196202531644, 0.8854825949367089, 0.9331487341772152], 'max_diversity-f1_score-num_gurus-1': [0.8990308544303798, 0.4844738924050633, 0.46281645569620256, 0.8447389240506329, 0.4416534810126582], 'max_diversity-f1_score-num_gurus-2': [0.8938884493670886, 0.331190664556962, 0.45233386075949367, 0.8845925632911392, 0.7770965189873418], 'max_diversity-f1_score-num_gurus-3': [0.6920490506329114, 0.3604628164556962, 0.3803401898734177, 0.7972705696202531, 0.9326542721518988], 'max_diversity-f1_score-num_gurus-4': [0.628065664556962, 0.21696993670886075, 0.3280261075949367, 0.7786787974683544, 0.9457080696202531], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.9285996835443038, 0.8975474683544303, 0.4044699367088608, 0.9395767405063291, 0.9319620253164557], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.9305775316455697, 0.9023931962025317, 0.45747626582278483, 0.9408623417721519, 0.936807753164557], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.9304786392405063, 0.8603639240506329, 0.4372033227848101, 0.9231606012658228, 0.9365110759493671], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.9339398734177216, 0.8138844936708861, 0.4892207278481013, 0.905557753164557, 0.8895371835443038], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9173259493670886, 0.8847903481012658, 0.8660996835443038, 0.9445213607594937, 0.9380933544303798], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.9263251582278481, 0.8917128164556962, 0.3950751582278481, 0.9477848101265823, 0.9421479430379747], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.9316653481012658, 0.828817246835443, 0.889932753164557, 0.9472903481012658, 0.9426424050632911], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9255340189873418, 0.8988330696202531, 0.44610363924050633, 0.9243473101265823, 0.9458069620253164], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.8694620253164557, 0.9023931962025317, 0.4295886075949367, 0.9459058544303798, 0.9421479430379747], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8643196202531646, 0.892306170886076, 0.8950751582278481, 0.9523338607594937, 0.9427412974683544], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.864814082278481, 0.8517602848101266, 0.8573971518987342, 0.9493670886075949, 0.9438291139240507], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.8670886075949367, 0.7728441455696202, 0.7537579113924051, 0.9438291139240507, 0.9468947784810127], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.8391020569620253, 0.2956882911392405, 0.716376582278481, 0.9283030063291139, 0.9454113924050633], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.8469145569620253, 0.2974683544303797, 0.8545292721518988, 0.9427412974683544, 0.9435324367088608], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.8506724683544303, 0.2915348101265823, 0.7995450949367089, 0.9417523734177216, 0.9459058544303798], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.8393987341772152, 0.2641416139240506, 0.8788568037974683, 0.9052610759493671, 0.9455102848101266], 'single_Net': [0.31843354430379744, 0.18255537974683544, 0.26730617088607594, 0.3661985759493671, 0.9503560126582279]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.95it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.0776\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5875\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.17it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.8663\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2895\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.44it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.4892\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4447\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.51it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9086\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6742\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.60it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2905\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9690\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.1265\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5930\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.94it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.4036\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3500\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.84it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.6064\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2402\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.75it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.2258\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3263\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.83it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.3737\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3933\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.55it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1048\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9678\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.7429\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4555\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.01it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.8887\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3588\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.41it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.5712\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2287\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.91it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.4325\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3131\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.91it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.8311\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3864\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [3:11:07<7:07:35, 3665.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1059\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9675\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.9659\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4509\n",
      "Starting trial  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.84it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2552\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9246\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.02it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2545\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9258\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.63it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2572\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9235\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.25it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9502\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9110\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.36it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2287\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9307\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.97it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2362\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9300\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.09it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6989\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9370\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.43it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2154\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9361\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.86it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2145\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9363\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.26it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5105\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9512\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.71it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1855\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9447\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.01it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1855\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9446\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.14it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6952\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9399\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.87it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2265\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9356\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.76it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2255\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9346\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d37a530>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d37bfd0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d4d4100>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d4d4340>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d4d4100>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.31981803797468356, 0.22043117088607594, 0.26285601265822783, 0.3590783227848101, 0.9594541139240507], 'random_better-accuracy_score-num_gurus-1': [0.8955696202531646, 0.4339398734177215, 0.5615110759493671, 0.8253560126582279, 0.3827136075949367], 'random_better-accuracy_score-num_gurus-2': [0.9068433544303798, 0.408623417721519, 0.48032041139240506, 0.9142602848101266, 0.5603243670886076], 'random_better-accuracy_score-num_gurus-3': [0.8008306962025317, 0.4774525316455696, 0.36649525316455694, 0.8911194620253164, 0.8621439873417721], 'random_better-accuracy_score-num_gurus-4': [0.5799050632911392, 0.1863132911392405, 0.4778481012658228, 0.6865110759493671, 0.9490704113924051], 'random_better-balanced_accuracy_score-num_gurus-1': [0.9060522151898734, 0.4134691455696203, 0.34206882911392406, 0.8501780063291139, 0.3440466772151899], 'random_better-balanced_accuracy_score-num_gurus-2': [0.9021954113924051, 0.3954707278481013, 0.5300632911392406, 0.8963607594936709, 0.5638844936708861], 'random_better-balanced_accuracy_score-num_gurus-3': [0.7430775316455697, 0.5267998417721519, 0.3287183544303797, 0.8520569620253164, 0.8998219936708861], 'random_better-balanced_accuracy_score-num_gurus-4': [0.6285601265822784, 0.23734177215189872, 0.3900316455696203, 0.7770965189873418, 0.9491693037974683], 'random_better-f1_score-num_gurus-1': [0.9072389240506329, 0.4050632911392405, 0.48388053797468356, 0.8637262658227848, 0.36985759493670883], 'random_better-f1_score-num_gurus-2': [0.8308939873417721, 0.30310522151898733, 0.5037579113924051, 0.8246637658227848, 0.8104232594936709], 'random_better-f1_score-num_gurus-3': [0.8197191455696202, 0.3362341772151899, 0.44462025316455694, 0.9061511075949367, 0.8375197784810127], 'random_better-f1_score-num_gurus-4': [0.7294303797468354, 0.23032041139240506, 0.37964794303797467, 0.8490901898734177, 0.9333465189873418], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9345332278481012, 0.14685522151898733, 0.2791732594936709, 0.8392009493670886, 0.2865901898734177], 'probabilistic_better-accuracy_score-num_gurus-2': [0.9264240506329114, 0.26364715189873417, 0.41604034810126583, 0.9075356012658228, 0.48506724683544306], 'probabilistic_better-accuracy_score-num_gurus-3': [0.8277294303797469, 0.19907041139240506, 0.567939082278481, 0.8958662974683544, 0.8529469936708861], 'probabilistic_better-accuracy_score-num_gurus-4': [0.6945213607594937, 0.17711629746835442, 0.6017602848101266, 0.7672072784810127, 0.9312697784810127], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9338409810126582, 0.13696598101265822, 0.31981803797468356, 0.8340585443037974, 0.28560126582278483], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.9256329113924051, 0.26295490506329117, 0.4681566455696203, 0.9041732594936709, 0.4964398734177215], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.8294106012658228, 0.1919501582278481, 0.5416337025316456, 0.9080300632911392, 0.8389042721518988], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.671875, 0.22844145569620253, 0.5279865506329114, 0.788370253164557, 0.9389833860759493], 'probabilistic_better-f1_score-num_gurus-1': [0.9329509493670886, 0.14477848101265822, 0.2978639240506329, 0.8340585443037974, 0.27175632911392406], 'probabilistic_better-f1_score-num_gurus-2': [0.9299841772151899, 0.17563291139240506, 0.49683544303797467, 0.8997231012658228, 0.46162974683544306], 'probabilistic_better-f1_score-num_gurus-3': [0.840684335443038, 0.19709256329113925, 0.5560719936708861, 0.9050632911392406, 0.8249604430379747], 'probabilistic_better-f1_score-num_gurus-4': [0.6510087025316456, 0.21835443037974683, 0.4017009493670886, 0.8026107594936709, 0.946004746835443], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9341376582278481, 0.17919303797468356, 0.2579113924050633, 0.8604628164556962, 0.26958069620253167], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9173259493670886, 0.16584256329113925, 0.5730814873417721, 0.8940862341772152, 0.4775514240506329], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.8297072784810127, 0.2008504746835443, 0.5070213607594937, 0.9034810126582279, 0.8410799050632911], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.6989715189873418, 0.20005933544303797, 0.5762460443037974, 0.7500988924050633, 0.9304786392405063], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9366099683544303, 0.14715189873417722, 0.28500791139240506, 0.8423655063291139, 0.2803599683544304], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9207871835443038, 0.17325949367088608, 0.5958267405063291, 0.8965585443037974, 0.4615308544303797], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.8439477848101266, 0.192939082278481, 0.5290743670886076, 0.9112935126582279, 0.8268393987341772], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.6972903481012658, 0.2232990506329114, 0.4395767405063291, 0.8243670886075949, 0.9435324367088608], 'probabilistic_weighted-f1_score-num_gurus-1': [0.935818829113924, 0.19017009493670886, 0.22873813291139242, 0.8515625, 0.26364715189873417], 'probabilistic_weighted-f1_score-num_gurus-2': [0.9285007911392406, 0.24821993670886075, 0.40189873417721517, 0.9048655063291139, 0.4546083860759494], 'probabilistic_weighted-f1_score-num_gurus-3': [0.8215981012658228, 0.21459651898734178, 0.5245253164556962, 0.897745253164557, 0.8426621835443038], 'probabilistic_weighted-f1_score-num_gurus-4': [0.6667325949367089, 0.18245648734177214, 0.4732990506329114, 0.7732397151898734, 0.9439280063291139], 'max_diversity-accuracy_score-num_gurus-1': [0.8970530063291139, 0.6563488924050633, 0.672567246835443, 0.8301028481012658, 0.3552215189873418], 'max_diversity-accuracy_score-num_gurus-2': [0.8419699367088608, 0.5025712025316456, 0.41455696202531644, 0.8697587025316456, 0.7780854430379747], 'max_diversity-accuracy_score-num_gurus-3': [0.649129746835443, 0.32318037974683544, 0.4387856012658228, 0.7433742088607594, 0.9406645569620253], 'max_diversity-accuracy_score-num_gurus-4': [0.6398338607594937, 0.21360759493670886, 0.3807357594936709, 0.7920292721518988, 0.9459058544303798], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.9071400316455697, 0.39764636075949367, 0.4230617088607595, 0.8473101265822784, 0.5097903481012658], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.835245253164557, 0.42325949367088606, 0.48160601265822783, 0.8431566455696202, 0.7721518987341772], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.6518987341772152, 0.3686708860759494, 0.3978441455696203, 0.7380340189873418, 0.9271162974683544], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.6984770569620253, 0.23486946202531644, 0.32308148734177217, 0.8663963607594937, 0.9414556962025317], 'max_diversity-f1_score-num_gurus-1': [0.9152492088607594, 0.4855617088607595, 0.4665743670886076, 0.8594738924050633, 0.32861946202531644], 'max_diversity-f1_score-num_gurus-2': [0.9084256329113924, 0.3813291139240506, 0.3701542721518987, 0.8786590189873418, 0.5867286392405063], 'max_diversity-f1_score-num_gurus-3': [0.8123022151898734, 0.36975870253164556, 0.37638449367088606, 0.8992286392405063, 0.8669897151898734], 'max_diversity-f1_score-num_gurus-4': [0.7150909810126582, 0.22943037974683544, 0.3310917721518987, 0.8732199367088608, 0.9406645569620253], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.9268196202531646, 0.8362341772151899, 0.4922863924050633, 0.9443235759493671, 0.9369066455696202], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.9318631329113924, 0.2579113924050633, 0.9143591772151899, 0.9198971518987342, 0.9407634493670886], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.9333465189873418, 0.8921083860759493, 0.35225474683544306, 0.9328520569620253, 0.9236550632911392], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.9328520569620253, 0.8415743670886076, 0.3428599683544304, 0.9090189873417721, 0.8917128164556962], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9268196202531646, 0.2208267405063291, 0.9325553797468354, 0.9310719936708861, 0.9395767405063291], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.9212816455696202, 0.2598892405063291, 0.9309731012658228, 0.9330498417721519, 0.9461036392405063], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.9311708860759493, 0.2688884493670886, 0.9339398734177216, 0.9371044303797469, 0.9441257911392406], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9259295886075949, 0.2845134493670886, 0.9214794303797469, 0.9162381329113924, 0.944620253164557], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.8503757911392406, 0.31685126582278483, 0.9131724683544303, 0.9387856012658228, 0.9440268987341772], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8561115506329114, 0.3224881329113924, 0.9338409810126582, 0.936807753164557, 0.9444224683544303], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.8412776898734177, 0.28639240506329117, 0.9141613924050633, 0.9389833860759493, 0.9487737341772152], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.8645174050632911, 0.2542523734177215, 0.8955696202531646, 0.9353243670886076, 0.9470925632911392], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.8543314873417721, 0.3154667721518987, 0.8514636075949367, 0.9424446202531646, 0.9439280063291139], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.8423655063291139, 0.2903481012658228, 0.8308939873417721, 0.9417523734177216, 0.9435324367088608], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.8616495253164557, 0.2563291139240506, 0.8630340189873418, 0.9165348101265823, 0.9474881329113924], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.8464200949367089, 0.3224881329113924, 0.760878164556962, 0.9250395569620253, 0.9504549050632911], 'single_Net': [0.3076542721518987, 0.2299248417721519, 0.27857990506329117, 0.33643196202531644, 0.9522349683544303]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.03it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1356\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5521\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.77it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.9482\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3200\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.62it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.5752\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4240\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.84it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9879\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6454\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.78it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2784\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9695\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.1850\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5822\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.89it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.0260\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3444\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.25it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.8504\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1997\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.51it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.4530\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3085\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.96it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.8123\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3745\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.81it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0971\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9703\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.0478\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4395\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.82it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.3813\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3604\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.81it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.2003\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3476\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.80it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.3864\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3091\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.86it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.3078\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4266\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [4:07:56<5:56:26, 3564.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1189\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9618\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.6789\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4811\n",
      "Starting trial  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.09it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2526\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9249\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.96it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2598\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9229\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.16it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2540\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9244\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.34it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9625\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9104\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.69it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2362\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9301\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2332\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9309\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.34it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6902\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9362\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.67it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2086\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9376\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.84it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2196\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9335\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.32it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4831\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9516\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1896\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9435\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.46it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1879\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9438\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.12it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7002\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9385\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.03it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2228\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9361\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.87it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2312\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9340\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1d44db6d0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x10d100fd0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1e3175d20>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1e31762f0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1e3175d20>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.35354034810126583, 0.20698180379746836, 0.2848101265822785, 0.3571993670886076, 0.9582674050632911], 'random_better-accuracy_score-num_gurus-1': [0.9029865506329114, 0.43947784810126583, 0.41238132911392406, 0.8663963607594937, 0.3657041139240506], 'random_better-accuracy_score-num_gurus-2': [0.8874604430379747, 0.2691851265822785, 0.5152294303797469, 0.9040743670886076, 0.7069818037974683], 'random_better-accuracy_score-num_gurus-3': [0.8303006329113924, 0.203125, 0.5802017405063291, 0.8963607594936709, 0.823378164556962], 'random_better-accuracy_score-num_gurus-4': [0.6490308544303798, 0.23605617088607594, 0.4899129746835443, 0.7459454113924051, 0.9472903481012658], 'random_better-balanced_accuracy_score-num_gurus-1': [0.9237539556962026, 0.26157041139240506, 0.3759889240506329, 0.852254746835443, 0.4549050632911392], 'random_better-balanced_accuracy_score-num_gurus-2': [0.9090189873417721, 0.21904667721518986, 0.4920886075949367, 0.9274129746835443, 0.5053401898734177], 'random_better-balanced_accuracy_score-num_gurus-3': [0.8214003164556962, 0.3076542721518987, 0.4189082278481013, 0.9064477848101266, 0.8416732594936709], 'random_better-balanced_accuracy_score-num_gurus-4': [0.6252966772151899, 0.213310917721519, 0.4227650316455696, 0.7672072784810127, 0.9494659810126582], 'random_better-f1_score-num_gurus-1': [0.8989319620253164, 0.4017009493670886, 0.39200949367088606, 0.8099287974683544, 0.379746835443038], 'random_better-f1_score-num_gurus-2': [0.9202927215189873, 0.25583465189873417, 0.5027689873417721, 0.9057555379746836, 0.5133504746835443], 'random_better-f1_score-num_gurus-3': [0.8100276898734177, 0.3302017405063291, 0.41475474683544306, 0.9043710443037974, 0.8543314873417721], 'random_better-f1_score-num_gurus-4': [0.6831487341772152, 0.19570806962025317, 0.4014042721518987, 0.832871835443038, 0.9449169303797469], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9378955696202531, 0.13291139240506328, 0.2800632911392405, 0.8350474683544303, 0.27323971518987344], 'probabilistic_better-accuracy_score-num_gurus-2': [0.9200949367088608, 0.16396360759493672, 0.5862341772151899, 0.889932753164557, 0.489121835443038], 'probabilistic_better-accuracy_score-num_gurus-3': [0.8125, 0.21380537974683544, 0.564873417721519, 0.9021954113924051, 0.8308939873417721], 'probabilistic_better-accuracy_score-num_gurus-4': [0.5810917721518988, 0.2412974683544304, 0.38548259493670883, 0.7388251582278481, 0.9508504746835443], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9345332278481012, 0.1361748417721519, 0.26127373417721517, 0.8380142405063291, 0.263251582278481], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.918809335443038, 0.16218354430379747, 0.6197587025316456, 0.8861748417721519, 0.48575949367088606], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.8064675632911392, 0.18018196202531644, 0.5151305379746836, 0.9061511075949367, 0.8512658227848101], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.6464596518987342, 0.1909612341772152, 0.524129746835443, 0.7409018987341772, 0.9456091772151899], 'probabilistic_better-f1_score-num_gurus-1': [0.9365110759493671, 0.14280063291139242, 0.296875, 0.8421677215189873, 0.2578125], 'probabilistic_better-f1_score-num_gurus-2': [0.917128164556962, 0.16801819620253164, 0.6177808544303798, 0.8928995253164557, 0.4912974683544304], 'probabilistic_better-f1_score-num_gurus-3': [0.7908425632911392, 0.18354430379746836, 0.5959256329113924, 0.8686708860759493, 0.8513647151898734], 'probabilistic_better-f1_score-num_gurus-4': [0.634493670886076, 0.1919501582278481, 0.6174841772151899, 0.7232001582278481, 0.9423457278481012], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9420490506329114, 0.13459256329113925, 0.2712618670886076, 0.8453322784810127, 0.2517800632911392], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9155458860759493, 0.17355617088607594, 0.5915743670886076, 0.8872626582278481, 0.49406645569620256], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.8029074367088608, 0.1808742088607595, 0.5769382911392406, 0.8763844936708861, 0.8370253164556962], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.6760284810126582, 0.189873417721519, 0.5117681962025317, 0.784315664556962, 0.9440268987341772], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9400712025316456, 0.17019382911392406, 0.23061708860759494, 0.8427610759493671, 0.24060522151898733], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9214794303797469, 0.21222310126582278, 0.6139240506329114, 0.9041732594936709, 0.4810126582278481], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.8528481012658228, 0.21459651898734178, 0.5262064873417721, 0.9227650316455697, 0.783623417721519], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.6137262658227848, 0.17128164556962025, 0.5387658227848101, 0.7231012658227848, 0.9447191455696202], 'probabilistic_weighted-f1_score-num_gurus-1': [0.9370055379746836, 0.13449367088607594, 0.27937104430379744, 0.8334651898734177, 0.26216376582278483], 'probabilistic_weighted-f1_score-num_gurus-2': [0.9254351265822784, 0.2421875, 0.4068433544303797, 0.9087223101265823, 0.47844145569620256], 'probabilistic_weighted-f1_score-num_gurus-3': [0.8019185126582279, 0.18502768987341772, 0.5224485759493671, 0.8792523734177216, 0.840684335443038], 'probabilistic_weighted-f1_score-num_gurus-4': [0.646756329113924, 0.20816851265822786, 0.5607199367088608, 0.7552412974683544, 0.9464992088607594], 'max_diversity-accuracy_score-num_gurus-1': [0.8983386075949367, 0.47498022151898733, 0.5208662974683544, 0.8111155063291139, 0.3191257911392405], 'max_diversity-accuracy_score-num_gurus-2': [0.888943829113924, 0.5069224683544303, 0.471815664556962, 0.9065466772151899, 0.6009691455696202], 'max_diversity-accuracy_score-num_gurus-3': [0.6867088607594937, 0.3822191455696203, 0.4119857594936709, 0.7806566455696202, 0.9317642405063291], 'max_diversity-accuracy_score-num_gurus-4': [0.6222310126582279, 0.20411392405063292, 0.37539556962025317, 0.7684928797468354, 0.9444224683544303], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.8926028481012658, 0.34691455696202533, 0.42681962025316456, 0.8027096518987342, 0.4365110759493671], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.693631329113924, 0.4155458860759494, 0.40011867088607594, 0.6849287974683544, 0.9145569620253164], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.7949960443037974, 0.35591376582278483, 0.36975870253164556, 0.8904272151898734, 0.8536392405063291], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.5659612341772152, 0.2399129746835443, 0.36451740506329117, 0.7260680379746836, 0.9474881329113924], 'max_diversity-f1_score-num_gurus-1': [0.9056566455696202, 0.5267009493670886, 0.29529272151898733, 0.8744066455696202, 0.40625], 'max_diversity-f1_score-num_gurus-2': [0.8790545886075949, 0.4939675632911392, 0.4783425632911392, 0.8502768987341772, 0.7427808544303798], 'max_diversity-f1_score-num_gurus-3': [0.5735759493670886, 0.5535996835443038, 0.3142800632911392, 0.6716772151898734, 0.9366099683544303], 'max_diversity-f1_score-num_gurus-4': [0.7275514240506329, 0.2077729430379747, 0.4061511075949367, 0.8440466772151899, 0.9342365506329114], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.9330498417721519, 0.27264636075949367, 0.935126582278481, 0.9440268987341772, 0.9406645569620253], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.9335443037974683, 0.2254746835443038, 0.90625, 0.9318631329113924, 0.9396756329113924], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.934434335443038, 0.2222112341772152, 0.9269185126582279, 0.9130735759493671, 0.9340387658227848], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.9385878164556962, 0.20450949367088608, 0.8772745253164557, 0.8974485759493671, 0.8809335443037974], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9336431962025317, 0.2767009493670886, 0.9258306962025317, 0.9383900316455697, 0.936807753164557], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.9350276898734177, 0.28619462025316456, 0.926621835443038, 0.9342365506329114, 0.9411590189873418], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.9371044303797469, 0.90625, 0.8951740506329114, 0.946004746835443, 0.9453125], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9259295886075949, 0.23061708860759494, 0.9241495253164557, 0.9193037974683544, 0.9361155063291139], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.845431170886076, 0.28411787974683544, 0.9160403481012658, 0.9372033227848101, 0.9449169303797469], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8189280063291139, 0.3104232594936709, 0.9179193037974683, 0.9345332278481012, 0.943631329113924], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.8361352848101266, 0.2602848101265823, 0.9321598101265823, 0.9392800632911392, 0.9433346518987342], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.8336629746835443, 0.30785205696202533, 0.9119857594936709, 0.9302808544303798, 0.9452136075949367], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.8306962025316456, 0.32970727848101267, 0.8846914556962026, 0.9355221518987342, 0.9435324367088608], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.8368275316455697, 0.2845134493670886, 0.873318829113924, 0.9348299050632911, 0.943631329113924], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.8502768987341772, 0.26582278481012656, 0.8807357594936709, 0.9396756329113924, 0.9477848101265823], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.819620253164557, 0.2776898734177215, 0.8650118670886076, 0.9091178797468354, 0.9452136075949367], 'single_Net': [0.3110166139240506, 0.16455696202531644, 0.25464794303797467, 0.3259493670886076, 0.9503560126582279]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.11it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1298\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5657\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.83it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.9472\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2612\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.00it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.5197\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4322\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.26it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9221\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6729\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.83it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2780\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9711\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.1593\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5806\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.25it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.4050\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3441\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.87it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.6731\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2174\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.04it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.0905\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3163\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.13it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.4333\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4043\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.83it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1228\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9614\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.7449\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4487\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.03it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.4791\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3720\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.41it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.6758\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2358\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.91it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.1108\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3212\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.08it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.5531\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4038\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [4:58:39<4:41:21, 3376.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0922\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9717\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.7822\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4609\n",
      "Starting trial  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.65it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2602\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9228\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.39it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2544\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9247\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.30it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2573\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9234\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.79it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9499\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9133\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.37it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2325\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9312\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.97it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2375\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9301\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.27it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7125\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9367\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.93it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2135\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9365\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.21it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2154\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9348\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.39it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5330\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9495\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.32it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1887\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9441\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.42it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1898\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9443\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.13it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7013\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9385\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 29.21it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2191\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9371\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.15it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2255\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9362\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1c187f490>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d4d6950>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1d44d8160>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d4d5990>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1d44d8160>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.307753164556962, 0.22231012658227847, 0.27541534810126583, 0.3452333860759494, 0.9558939873417721], 'random_better-accuracy_score-num_gurus-1': [0.9061511075949367, 0.4318631329113924, 0.401503164556962, 0.8307950949367089, 0.4540150316455696], 'random_better-accuracy_score-num_gurus-2': [0.9203916139240507, 0.49080300632911394, 0.30992879746835444, 0.9231606012658228, 0.5465783227848101], 'random_better-accuracy_score-num_gurus-3': [0.7977650316455697, 0.22250791139240506, 0.552314082278481, 0.8561115506329114, 0.8632318037974683], 'random_better-accuracy_score-num_gurus-4': [0.632120253164557, 0.20045490506329114, 0.29094145569620256, 0.8293117088607594, 0.9458069620253164], 'random_better-balanced_accuracy_score-num_gurus-1': [0.9017009493670886, 0.40041534810126583, 0.41683148734177217, 0.8486946202531646, 0.4365110759493671], 'random_better-balanced_accuracy_score-num_gurus-2': [0.913370253164557, 0.37875791139240506, 0.47735363924050633, 0.8853837025316456, 0.5691257911392406], 'random_better-balanced_accuracy_score-num_gurus-3': [0.8038963607594937, 0.35779272151898733, 0.43047863924050633, 0.8983386075949367, 0.8475079113924051], 'random_better-balanced_accuracy_score-num_gurus-4': [0.6450751582278481, 0.20965189873417722, 0.4943631329113924, 0.7470332278481012, 0.9452136075949367], 'random_better-f1_score-num_gurus-1': [0.9138647151898734, 0.3993275316455696, 0.3785601265822785, 0.8668908227848101, 0.5207674050632911], 'random_better-f1_score-num_gurus-2': [0.885185917721519, 0.3647151898734177, 0.34187104430379744, 0.8864715189873418, 0.7429786392405063], 'random_better-f1_score-num_gurus-3': [0.7032238924050633, 0.40822784810126583, 0.38864715189873417, 0.8071598101265823, 0.9190071202531646], 'random_better-f1_score-num_gurus-4': [0.6777096518987342, 0.2517800632911392, 0.2955893987341772, 0.8557159810126582, 0.9371044303797469], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9353243670886076, 0.14547072784810128, 0.2989517405063291, 0.8548259493670886, 0.2756131329113924], 'probabilistic_better-accuracy_score-num_gurus-2': [0.914754746835443, 0.18562104430379747, 0.5782238924050633, 0.8989319620253164, 0.47517800632911394], 'probabilistic_better-accuracy_score-num_gurus-3': [0.7822389240506329, 0.21617879746835442, 0.5342167721518988, 0.868868670886076, 0.8619462025316456], 'probabilistic_better-accuracy_score-num_gurus-4': [0.6173852848101266, 0.21034414556962025, 0.38004351265822783, 0.7700751582278481, 0.9491693037974683], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9379944620253164, 0.1527887658227848, 0.3191257911392405, 0.8431566455696202, 0.27531645569620256], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.9145569620253164, 0.1919501582278481, 0.5857397151898734, 0.8965585443037974, 0.5100870253164557], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.7984572784810127, 0.18482990506329114, 0.5038568037974683, 0.8859770569620253, 0.8337618670886076], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.5931566455696202, 0.2118275316455696, 0.35670490506329117, 0.7555379746835443, 0.9459058544303798], 'probabilistic_better-f1_score-num_gurus-1': [0.9361155063291139, 0.18730221518987342, 0.2653283227848101, 0.8572982594936709, 0.2565268987341772], 'probabilistic_better-f1_score-num_gurus-2': [0.9254351265822784, 0.29222705696202533, 0.41782041139240506, 0.9027887658227848, 0.5069224683544303], 'probabilistic_better-f1_score-num_gurus-3': [0.8126977848101266, 0.2154865506329114, 0.5303599683544303, 0.8955696202531646, 0.8134889240506329], 'probabilistic_better-f1_score-num_gurus-4': [0.6544699367088608, 0.1964003164556962, 0.3630340189873418, 0.8043908227848101, 0.9432357594936709], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9366099683544303, 0.17474287974683544, 0.21143196202531644, 0.8625395569620253, 0.244560917721519], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9121835443037974, 0.19471914556962025, 0.6136273734177216, 0.8921083860759493, 0.48575949367088606], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.7901503164556962, 0.22280458860759494, 0.5348101265822784, 0.8735166139240507, 0.8436511075949367], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.6700949367088608, 0.24189082278481014, 0.4162381329113924, 0.7990506329113924, 0.9408623417721519], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9369066455696202, 0.14804193037974683, 0.2735363924050633, 0.8623417721518988, 0.2556368670886076], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9161392405063291, 0.18146756329113925, 0.6058148734177216, 0.8834058544303798, 0.5110759493670886], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.814873417721519, 0.20391613924050633, 0.5144382911392406, 0.890625, 0.8353441455696202], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.6577333860759493, 0.24416534810126583, 0.44511471518987344, 0.7826344936708861, 0.9443235759493671], 'probabilistic_weighted-f1_score-num_gurus-1': [0.9355221518987342, 0.15545886075949367, 0.29064477848101267, 0.864121835443038, 0.26997626582278483], 'probabilistic_weighted-f1_score-num_gurus-2': [0.911689082278481, 0.18156645569620253, 0.6702927215189873, 0.8878560126582279, 0.4982199367088608], 'probabilistic_weighted-f1_score-num_gurus-3': [0.7956882911392406, 0.20569620253164558, 0.5225474683544303, 0.8759889240506329, 0.8409810126582279], 'probabilistic_weighted-f1_score-num_gurus-4': [0.6302412974683544, 0.21875, 0.3650118670886076, 0.7774920886075949, 0.9464992088607594], 'max_diversity-accuracy_score-num_gurus-1': [0.8909216772151899, 0.5012856012658228, 0.4417523734177215, 0.8283227848101266, 0.49198971518987344], 'max_diversity-accuracy_score-num_gurus-2': [0.9025909810126582, 0.2889636075949367, 0.42948971518987344, 0.8633306962025317, 0.6967958860759493], 'max_diversity-accuracy_score-num_gurus-3': [0.7309137658227848, 0.33643196202531644, 0.37183544303797467, 0.8228837025316456, 0.9207871835443038], 'max_diversity-accuracy_score-num_gurus-4': [0.6014636075949367, 0.2141020569620253, 0.3082476265822785, 0.7847112341772152, 0.947685917721519], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.8832080696202531, 0.47498022151898733, 0.3828125, 0.8251582278481012, 0.3251582278481013], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.9148536392405063, 0.44511471518987344, 0.4212816455696203, 0.9026898734177216, 0.5582476265822784], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.7977650316455697, 0.260878164556962, 0.5580498417721519, 0.8689675632911392, 0.8507713607594937], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.7006526898734177, 0.24287974683544303, 0.3334651898734177, 0.8669897151898734, 0.936807753164557], 'max_diversity-f1_score-num_gurus-1': [0.9333465189873418, 0.28629351265822783, 0.4705300632911392, 0.8633306962025317, 0.323378164556962], 'max_diversity-f1_score-num_gurus-2': [0.9113924050632911, 0.36075949367088606, 0.37539556962025317, 0.9136669303797469, 0.5501384493670886], 'max_diversity-f1_score-num_gurus-3': [0.8218947784810127, 0.24070411392405064, 0.5677412974683544, 0.8735166139240507, 0.8092365506329114], 'max_diversity-f1_score-num_gurus-4': [0.651503164556962, 0.21894778481012658, 0.3282238924050633, 0.8504746835443038, 0.9420490506329114], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.9293908227848101, 0.24149525316455697, 0.8971518987341772, 0.9288963607594937, 0.9420490506329114], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.9357199367088608, 0.22409018987341772, 0.918809335443038, 0.8996242088607594, 0.9271162974683544], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.9392800632911392, 0.30448971518987344, 0.39042721518987344, 0.9065466772151899, 0.9294897151898734], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.936807753164557, 0.20876186708860758, 0.875, 0.8782634493670886, 0.8754944620253164], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9272151898734177, 0.26424050632911394, 0.9146558544303798, 0.9310719936708861, 0.9430379746835443], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.9271162974683544, 0.9018987341772152, 0.9004153481012658, 0.9430379746835443, 0.9464003164556962], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.9331487341772152, 0.8514636075949367, 0.8817246835443038, 0.924248417721519, 0.9425435126582279], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9129746835443038, 0.2865901898734177, 0.9084256329113924, 0.9113924050632911, 0.940565664556962], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.8205102848101266, 0.2962816455696203, 0.8943829113924051, 0.9324564873417721, 0.9386867088607594], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8228837025316456, 0.3103243670886076, 0.8920094936708861, 0.9310719936708861, 0.9428401898734177], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.8591772151898734, 0.2878757911392405, 0.9070411392405063, 0.9457080696202531, 0.9451147151898734], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.8456289556962026, 0.2806566455696203, 0.9026898734177216, 0.9312697784810127, 0.9427412974683544], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.7913370253164557, 0.41455696202531644, 0.8730221518987342, 0.9017009493670886, 0.9416534810126582], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.8159612341772152, 0.2728441455696203, 0.8716376582278481, 0.926621835443038, 0.9463014240506329], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.8045886075949367, 0.3322784810126582, 0.7932159810126582, 0.9219738924050633, 0.9457080696202531], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.8125988924050633, 0.2955893987341772, 0.7466376582278481, 0.9207871835443038, 0.9478837025316456], 'single_Net': [0.2634493670886076, 0.2052017405063291, 0.22043117088607594, 0.30607199367088606, 0.9470925632911392]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.84it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1248\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5701\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.69it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.8982\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3441\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.79it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.5547\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4254\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.71it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9705\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6500\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.52it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2884\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9711\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.1673\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5921\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.76it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.9936\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3863\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.62it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.4328\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2569\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.77it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.3086\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3293\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.85it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.8153\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4206\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.60it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0964\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9690\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.9294\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4724\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.71it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.5378\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3450\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.61it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.7322\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2079\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.56it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.0041\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3374\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.82it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.7040\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3818\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [5:47:33<3:35:03, 3225.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1042\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9660\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.8165\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4476\n",
      "Starting trial  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.91it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2565\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9243\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.74it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2563\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9239\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.23it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2563\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9239\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.19it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9546\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9129\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.33it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2341\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9309\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.09it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2412\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9288\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.34it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6705\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9359\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.76it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2174\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9344\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.03it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2141\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9353\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.39it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5081\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9518\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.93it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1868\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9441\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.33it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1866\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9431\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.34it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7006\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9390\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 29.28it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2310\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9325\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.02it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2416\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9316\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1c2d834f0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1c2d83790>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1d44d8df0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1c2d83790>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1c2d834f0>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.30874208860759494, 0.2077729430379747, 0.28520569620253167, 0.34236550632911394, 0.955498417721519], 'random_better-accuracy_score-num_gurus-1': [0.9100079113924051, 0.42929193037974683, 0.3341574367088608, 0.8357397151898734, 0.30755537974683544], 'random_better-accuracy_score-num_gurus-2': [0.9115901898734177, 0.3017207278481013, 0.5123615506329114, 0.9139636075949367, 0.5252175632911392], 'random_better-accuracy_score-num_gurus-3': [0.8434533227848101, 0.19808148734177214, 0.5240308544303798, 0.914754746835443, 0.7956882911392406], 'random_better-accuracy_score-num_gurus-4': [0.7051028481012658, 0.21073971518987342, 0.3942840189873418, 0.8381131329113924, 0.9326542721518988], 'random_better-balanced_accuracy_score-num_gurus-1': [0.9042721518987342, 0.3582871835443038, 0.36857199367088606, 0.8431566455696202, 0.40644778481012656], 'random_better-balanced_accuracy_score-num_gurus-2': [0.9023931962025317, 0.6122428797468354, 0.33405854430379744, 0.9127768987341772, 0.5429193037974683], 'random_better-balanced_accuracy_score-num_gurus-3': [0.7503955696202531, 0.5146360759493671, 0.33732199367088606, 0.8542325949367089, 0.8856803797468354], 'random_better-balanced_accuracy_score-num_gurus-4': [0.7075751582278481, 0.2208267405063291, 0.4963409810126582, 0.8096321202531646, 0.9337420886075949], 'random_better-f1_score-num_gurus-1': [0.9059533227848101, 0.34988132911392406, 0.39764636075949367, 0.8291139240506329, 0.38548259493670883], 'random_better-f1_score-num_gurus-2': [0.8204113924050633, 0.5363924050632911, 0.36095727848101267, 0.8543314873417721, 0.8216969936708861], 'random_better-f1_score-num_gurus-3': [0.7877768987341772, 0.39102056962025317, 0.4177215189873418, 0.8711431962025317, 0.8478045886075949], 'random_better-f1_score-num_gurus-4': [0.7303204113924051, 0.21607990506329114, 0.3603639240506329, 0.8657041139240507, 0.9253362341772152], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9362143987341772, 0.1594145569620253, 0.22952927215189872, 0.849881329113924, 0.25761471518987344], 'probabilistic_better-accuracy_score-num_gurus-2': [0.9238528481012658, 0.17770965189873417, 0.577432753164557, 0.8884493670886076, 0.417128164556962], 'probabilistic_better-accuracy_score-num_gurus-3': [0.8125, 0.21024525316455697, 0.591376582278481, 0.8235759493670886, 0.7908425632911392], 'probabilistic_better-accuracy_score-num_gurus-4': [0.7290348101265823, 0.213310917721519, 0.44244462025316456, 0.838310917721519, 0.9321598101265823], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9364121835443038, 0.1727650316455696, 0.22952927215189872, 0.8429588607594937, 0.2633504746835443], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.9261273734177216, 0.17256724683544303, 0.5402492088607594, 0.9000197784810127, 0.4588607594936709], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.8323773734177216, 0.21024525316455697, 0.471123417721519, 0.9183148734177216, 0.829806170886076], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.6755340189873418, 0.23931962025316456, 0.43581882911392406, 0.8147745253164557, 0.9352254746835443], 'probabilistic_better-f1_score-num_gurus-1': [0.938192246835443, 0.13844936708860758, 0.267998417721519, 0.8429588607594937, 0.26483386075949367], 'probabilistic_better-f1_score-num_gurus-2': [0.9254351265822784, 0.16554588607594936, 0.5385680379746836, 0.8940862341772152, 0.4417523734177215], 'probabilistic_better-f1_score-num_gurus-3': [0.8467167721518988, 0.20233386075949367, 0.5587420886075949, 0.9128757911392406, 0.814873417721519], 'probabilistic_better-f1_score-num_gurus-4': [0.7008504746835443, 0.22577136075949367, 0.3638251582278481, 0.8567049050632911, 0.9346321202531646], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9387856012658228, 0.1765229430379747, 0.23625395569620253, 0.8611550632911392, 0.26394382911392406], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9226661392405063, 0.1776107594936709, 0.5736748417721519, 0.900810917721519, 0.4615308544303797], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.846123417721519, 0.21518987341772153, 0.5313488924050633, 0.9092167721518988, 0.7958860759493671], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.7192444620253164, 0.23852848101265822, 0.41089794303797467, 0.8579905063291139, 0.9312697784810127], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9394778481012658, 0.174248417721519, 0.22933148734177214, 0.8651107594936709, 0.2614715189873418], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9293908227848101, 0.18097310126582278, 0.5820806962025317, 0.8981408227848101, 0.4475870253164557], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.813192246835443, 0.19135680379746836, 0.5992879746835443, 0.8591772151898734, 0.8272349683544303], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.7300237341772152, 0.2533623417721519, 0.35868275316455694, 0.8919106012658228, 0.9192049050632911], 'probabilistic_weighted-f1_score-num_gurus-1': [0.939181170886076, 0.16267800632911392, 0.2208267405063291, 0.8528481012658228, 0.25524129746835444], 'probabilistic_weighted-f1_score-num_gurus-2': [0.9210838607594937, 0.1828520569620253, 0.6115506329113924, 0.8905261075949367, 0.4584651898734177], 'probabilistic_weighted-f1_score-num_gurus-3': [0.8380142405063291, 0.2221123417721519, 0.5066257911392406, 0.9100079113924051, 0.8119066455696202], 'probabilistic_weighted-f1_score-num_gurus-4': [0.7263647151898734, 0.2569224683544304, 0.4228639240506329, 0.8512658227848101, 0.9369066455696202], 'max_diversity-accuracy_score-num_gurus-1': [0.9052610759493671, 0.5216574367088608, 0.6090783227848101, 0.8152689873417721, 0.34028876582278483], 'max_diversity-accuracy_score-num_gurus-2': [0.8612539556962026, 0.45599287974683544, 0.4808148734177215, 0.8215981012658228, 0.7605814873417721], 'max_diversity-accuracy_score-num_gurus-3': [0.7287381329113924, 0.24901107594936708, 0.53125, 0.7915348101265823, 0.9165348101265823], 'max_diversity-accuracy_score-num_gurus-4': [0.7198378164556962, 0.234375, 0.3596716772151899, 0.8843947784810127, 0.9354232594936709], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.8911194620253164, 0.5327333860759493, 0.5635878164556962, 0.8170490506329114, 0.5244264240506329], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.8526503164556962, 0.3990308544303797, 0.4339398734177215, 0.791435917721519, 0.8018196202531646], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.7053006329113924, 0.3310917721518987, 0.43591772151898733, 0.8000395569620253, 0.9183148734177216], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.7115308544303798, 0.23605617088607594, 0.3837025316455696, 0.8625395569620253, 0.9363132911392406], 'max_diversity-f1_score-num_gurus-1': [0.8970530063291139, 0.4588607594936709, 0.38864715189873417, 0.8431566455696202, 0.5964200949367089], 'max_diversity-f1_score-num_gurus-2': [0.8469145569620253, 0.5391613924050633, 0.2981606012658228, 0.8661985759493671, 0.8173457278481012], 'max_diversity-f1_score-num_gurus-3': [0.6740506329113924, 0.39329509493670883, 0.43473101265822783, 0.7532634493670886, 0.924248417721519], 'max_diversity-f1_score-num_gurus-4': [0.6916534810126582, 0.21390427215189872, 0.4059533227848101, 0.8356408227848101, 0.9365110759493671], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.9295886075949367, 0.5009889240506329, 0.6082871835443038, 0.9510482594936709, 0.9343354430379747], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.9302808544303798, 0.22596914556962025, 0.9367088607594937, 0.9321598101265823, 0.932753164556962], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.9317642405063291, 0.20292721518987342, 0.9094145569620253, 0.9124802215189873, 0.9215783227848101], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.9373022151898734, 0.18344541139240506, 0.8814280063291139, 0.8987341772151899, 0.9020965189873418], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9341376582278481, 0.9181170886075949, 0.40357990506329117, 0.9456091772151899, 0.9347310126582279], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.928006329113924, 0.23714398734177214, 0.9315664556962026, 0.9539161392405063, 0.9380933544303798], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.930379746835443, 0.8934928797468354, 0.9066455696202531, 0.9471914556962026, 0.9377966772151899], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9205893987341772, 0.24228639240506328, 0.9386867088607594, 0.9272151898734177, 0.9380933544303798], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.849881329113924, 0.3161590189873418, 0.9222705696202531, 0.9438291139240507, 0.9373022151898734], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8671875, 0.25524129746835444, 0.9377966772151899, 0.9488726265822784, 0.9382911392405063], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.8787579113924051, 0.8465189873417721, 0.9087223101265823, 0.9545094936708861, 0.9407634493670886], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.8770767405063291, 0.26166930379746833, 0.9224683544303798, 0.9505537974683544, 0.9425435126582279], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.8512658227848101, 0.2592958860759494, 0.8662974683544303, 0.9493670886075949, 0.9387856012658228], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.8537381329113924, 0.2881724683544304, 0.7932159810126582, 0.9525316455696202, 0.9401700949367089], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.868868670886076, 0.2581091772151899, 0.8223892405063291, 0.9518393987341772, 0.9425435126582279], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.8607594936708861, 0.27600870253164556, 0.6372626582278481, 0.9494659810126582, 0.9448180379746836], 'single_Net': [0.25712025316455694, 0.16445806962025317, 0.2801621835443038, 0.2799643987341772, 0.9457080696202531]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.74it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1864\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5325\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.44it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.0239\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2511\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.88it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.4716\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4421\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.05it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9604\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6285\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.78it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2774\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9715\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.1839\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5651\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.00it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.7983\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3367\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.63it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.6750\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2401\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.92it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.1888\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3160\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.90it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.5013\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4114\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.35it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1073\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9652\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.8542\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4539\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.73it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.6590\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3493\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.64it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.8610\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2212\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.53it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.2207\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3204\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.60it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.6759\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3748\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [6:40:40<2:40:39, 3213.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1058\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9678\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.9045\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4467\n",
      "Starting trial  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.68it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2510\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9258\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.90it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2536\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9250\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.26it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2465\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9265\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.94it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9613\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9105\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.50it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2252\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9327\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.90it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2246\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9326\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.44it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6791\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9378\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.64it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2116\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9365\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.11it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2076\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9369\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.41it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4950\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9530\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.07it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1891\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9439\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.24it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1806\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9452\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.17it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7234\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9393\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.87it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2448\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9288\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.98it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2242\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9335\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d72d270>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1d44d8340>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1c187cc10>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1c187ccd0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d72f430>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.31062104430379744, 0.22369462025316456, 0.28718354430379744, 0.34780458860759494, 0.9621242088607594], 'random_better-accuracy_score-num_gurus-1': [0.9240506329113924, 0.32861946202531644, 0.32298259493670883, 0.8681764240506329, 0.43918117088607594], 'random_better-accuracy_score-num_gurus-2': [0.8559137658227848, 0.6483386075949367, 0.3347507911392405, 0.8720332278481012, 0.670193829113924], 'random_better-accuracy_score-num_gurus-3': [0.8168512658227848, 0.2614715189873418, 0.46607990506329117, 0.8841969936708861, 0.8623417721518988], 'random_better-accuracy_score-num_gurus-4': [0.741495253164557, 0.20411392405063292, 0.3689675632911392, 0.8848892405063291, 0.9279074367088608], 'random_better-balanced_accuracy_score-num_gurus-1': [0.9083267405063291, 0.5170094936708861, 0.4708267405063291, 0.826443829113924, 0.3395965189873418], 'random_better-balanced_accuracy_score-num_gurus-2': [0.8014240506329114, 0.5724881329113924, 0.35413370253164556, 0.833564082278481, 0.8465189873417721], 'random_better-balanced_accuracy_score-num_gurus-3': [0.7549446202531646, 0.39102056962025317, 0.41604034810126583, 0.8644185126582279, 0.9065466772151899], 'random_better-balanced_accuracy_score-num_gurus-4': [0.7283425632911392, 0.23378164556962025, 0.34375, 0.8856803797468354, 0.9366099683544303], 'random_better-f1_score-num_gurus-1': [0.9197982594936709, 0.372626582278481, 0.41149129746835444, 0.8592761075949367, 0.35749604430379744], 'random_better-f1_score-num_gurus-2': [0.8901305379746836, 0.3813291139240506, 0.5103837025316456, 0.9206882911392406, 0.6666337025316456], 'random_better-f1_score-num_gurus-3': [0.826443829113924, 0.24396756329113925, 0.5593354430379747, 0.9026898734177216, 0.84375], 'random_better-f1_score-num_gurus-4': [0.7071795886075949, 0.23585838607594936, 0.39586629746835444, 0.8329707278481012, 0.9443235759493671], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9393789556962026, 0.17058939873417722, 0.21855221518987342, 0.8567049050632911, 0.2680973101265823], 'probabilistic_better-accuracy_score-num_gurus-2': [0.9177215189873418, 0.1765229430379747, 0.5666534810126582, 0.8995253164556962, 0.506131329113924], 'probabilistic_better-accuracy_score-num_gurus-3': [0.8482001582278481, 0.2254746835443038, 0.5661590189873418, 0.9059533227848101, 0.8232792721518988], 'probabilistic_better-accuracy_score-num_gurus-4': [0.6737539556962026, 0.20361946202531644, 0.5313488924050633, 0.7743275316455697, 0.9386867088607594], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9394778481012658, 0.1651503164556962, 0.22616693037974683, 0.8458267405063291, 0.24871439873417722], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.9292919303797469, 0.1885878164556962, 0.4879351265822785, 0.8978441455696202, 0.5332278481012658], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.7996439873417721, 0.34958465189873417, 0.49594541139240506, 0.8894382911392406, 0.8727254746835443], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.6679193037974683, 0.22062895569620253, 0.4901107594936709, 0.7943037974683544, 0.9467958860759493], 'probabilistic_better-f1_score-num_gurus-1': [0.934434335443038, 0.13014240506329114, 0.29291930379746833, 0.8232792721518988, 0.270371835443038], 'probabilistic_better-f1_score-num_gurus-2': [0.9146558544303798, 0.16020569620253164, 0.6204509493670886, 0.8741099683544303, 0.5233386075949367], 'probabilistic_better-f1_score-num_gurus-3': [0.7916337025316456, 0.3270371835443038, 0.4808148734177215, 0.8972507911392406, 0.8750988924050633], 'probabilistic_better-f1_score-num_gurus-4': [0.6837420886075949, 0.20510284810126583, 0.46588212025316456, 0.8114121835443038, 0.9410601265822784], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9379944620253164, 0.17217167721518986, 0.25702136075949367, 0.8378164556962026, 0.27689873417721517], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9263251582278481, 0.2822389240506329, 0.4799248417721519, 0.9066455696202531, 0.5404469936708861], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.8036985759493671, 0.3112143987341772, 0.46281645569620256, 0.9014042721518988, 0.853935917721519], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.7018393987341772, 0.20470727848101267, 0.4392800632911392, 0.8239715189873418, 0.9402689873417721], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9330498417721519, 0.12687895569620253, 0.29183148734177217, 0.8286194620253164, 0.2704707278481013], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9245450949367089, 0.26948180379746833, 0.46736550632911394, 0.8915150316455697, 0.5464794303797469], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.7589003164556962, 0.2042128164556962, 0.6230221518987342, 0.8432555379746836, 0.8578916139240507], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.6926424050632911, 0.24594541139240506, 0.4537183544303797, 0.8134889240506329, 0.9437302215189873], 'probabilistic_weighted-f1_score-num_gurus-1': [0.9384889240506329, 0.1583267405063291, 0.20876186708860758, 0.8506724683544303, 0.23427610759493672], 'probabilistic_weighted-f1_score-num_gurus-2': [0.9304786392405063, 0.25346123417721517, 0.43473101265822783, 0.9074367088607594, 0.46716772151898733], 'probabilistic_weighted-f1_score-num_gurus-3': [0.8308939873417721, 0.33850870253164556, 0.395371835443038, 0.917128164556962, 0.8287183544303798], 'probabilistic_weighted-f1_score-num_gurus-4': [0.7164754746835443, 0.252373417721519, 0.46073971518987344, 0.8551226265822784, 0.9340387658227848], 'max_diversity-accuracy_score-num_gurus-1': [0.9122824367088608, 0.495253164556962, 0.3294106012658228, 0.8649129746835443, 0.3650118670886076], 'max_diversity-accuracy_score-num_gurus-2': [0.8042919303797469, 0.6835443037974683, 0.5717958860759493, 0.7609770569620253, 0.7667128164556962], 'max_diversity-accuracy_score-num_gurus-3': [0.7259691455696202, 0.30389636075949367, 0.534315664556962, 0.798556170886076, 0.9128757911392406], 'max_diversity-accuracy_score-num_gurus-4': [0.7247824367088608, 0.2286392405063291, 0.43245648734177217, 0.8495846518987342, 0.9372033227848101], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.8878560126582279, 0.5390625, 0.35176028481012656, 0.8258504746835443, 0.5154272151898734], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.8947784810126582, 0.4252373417721519, 0.4552017405063291, 0.8945806962025317, 0.685818829113924], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.4686511075949367, 0.5266020569620253, 0.3194224683544304, 0.5654667721518988, 0.9397745253164557], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.6831487341772152, 0.2276503164556962, 0.3707476265822785, 0.84375, 0.9406645569620253], 'max_diversity-f1_score-num_gurus-1': [0.9025909810126582, 0.5518196202531646, 0.5301621835443038, 0.8253560126582279, 0.3400909810126582], 'max_diversity-f1_score-num_gurus-2': [0.9070411392405063, 0.44936708860759494, 0.3928006329113924, 0.909315664556962, 0.5854430379746836], 'max_diversity-f1_score-num_gurus-3': [0.6542721518987342, 0.42019382911392406, 0.48269382911392406, 0.7291337025316456, 0.9389833860759493], 'max_diversity-f1_score-num_gurus-4': [0.621934335443038, 0.265625, 0.3604628164556962, 0.7936115506329114, 0.9479825949367089], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.9290941455696202, 0.20045490506329114, 0.9393789556962026, 0.9470925632911392, 0.9421479430379747], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.9312697784810127, 0.9025909810126582, 0.4243473101265823, 0.939873417721519, 0.9416534810126582], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.9363132911392406, 0.875, 0.4807159810126582, 0.9236550632911392, 0.9407634493670886], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.9370055379746836, 0.787381329113924, 0.5088014240506329, 0.9083267405063291, 0.9025909810126582], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9333465189873418, 0.9098101265822784, 0.9272151898734177, 0.9504549050632911, 0.9413568037974683], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.9337420886075949, 0.9135680379746836, 0.4594541139240506, 0.9432357594936709, 0.9450158227848101], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.9292919303797469, 0.883504746835443, 0.8710443037974683, 0.9370055379746836, 0.9501582278481012], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9319620253164557, 0.9076344936708861, 0.42167721518987344, 0.9272151898734177, 0.9478837025316456], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.858682753164557, 0.30033623417721517, 0.9155458860759493, 0.9467958860759493, 0.946993670886076], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8666930379746836, 0.2789754746835443, 0.9332476265822784, 0.942939082278481, 0.9482792721518988], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.8651107594936709, 0.8848892405063291, 0.8954707278481012, 0.9485759493670886, 0.9486748417721519], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.8475079113924051, 0.2734375, 0.9059533227848101, 0.9325553797468354, 0.9491693037974683], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.849189082278481, 0.2734375, 0.7378362341772152, 0.9433346518987342, 0.9479825949367089], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.842068829113924, 0.3326740506329114, 0.8414754746835443, 0.9337420886075949, 0.9498615506329114], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.841376582278481, 0.3337618670886076, 0.818631329113924, 0.9411590189873418, 0.9523338607594937], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.8506724683544303, 0.28500791139240506, 0.7542523734177216, 0.9408623417721519, 0.9490704113924051], 'single_Net': [0.31655458860759494, 0.17810522151898733, 0.30448971518987344, 0.3412776898734177, 0.9515427215189873]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:04<00:00, 18.84it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.0852\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5772\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.61it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.0573\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2679\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.25it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.6373\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3873\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.63it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9387\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6739\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.63it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2782\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9696\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.1993\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5752\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.60it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.4450\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3717\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.13it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.9090\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1983\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.34it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.0428\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3087\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.78it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.4908\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4036\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.58it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1019\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9698\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.7979\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4504\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.59it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.6539\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3141\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.43it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.7272\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2162\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.43it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.9172\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3457\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.47it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.6285\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3618\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [7:33:57<1:46:56, 3208.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0943\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9713\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.8042\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4418\n",
      "Starting trial  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.66it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2522\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9252\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.90it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2588\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9242\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.54it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2484\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9253\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.26it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9847\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9074\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.52it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2303\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9302\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2301\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9314\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.22it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6799\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.79it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2080\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9391\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.96it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2063\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9386\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.99it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5113\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9513\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.44it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1875\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9433\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.32it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1841\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9457\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.25it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7198\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9384\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.50it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2279\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9362\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.07it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2291\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9340\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1e3175810>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1e3176bf0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19ceb3160>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19ceb2800>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1e3175d50>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.33643196202531644, 0.20292721518987342, 0.3294106012658228, 0.36669303797468356, 0.9591574367088608], 'random_better-accuracy_score-num_gurus-1': [0.892998417721519, 0.45332278481012656, 0.4296875, 0.8445411392405063, 0.40674446202531644], 'random_better-accuracy_score-num_gurus-2': [0.9196004746835443, 0.35314477848101267, 0.46944224683544306, 0.9153481012658228, 0.5015822784810127], 'random_better-accuracy_score-num_gurus-3': [0.7695806962025317, 0.36323180379746833, 0.4229628164556962, 0.8762856012658228, 0.8995253164556962], 'random_better-accuracy_score-num_gurus-4': [0.6356803797468354, 0.19491693037974683, 0.43799446202531644, 0.7674050632911392, 0.9403678797468354], 'random_better-balanced_accuracy_score-num_gurus-1': [0.8606606012658228, 0.47339794303797467, 0.6207476265822784, 0.7399129746835443, 0.39912974683544306], 'random_better-balanced_accuracy_score-num_gurus-2': [0.8964596518987342, 0.5476661392405063, 0.3282238924050633, 0.8815268987341772, 0.5888053797468354], 'random_better-balanced_accuracy_score-num_gurus-3': [0.6539754746835443, 0.3794501582278481, 0.40664556962025317, 0.7236946202531646, 0.9367088607594937], 'random_better-balanced_accuracy_score-num_gurus-4': [0.7040150316455697, 0.22903481012658228, 0.3505735759493671, 0.8619462025316456, 0.9337420886075949], 'random_better-f1_score-num_gurus-1': [0.8813291139240507, 0.41683148734177217, 0.3905261075949367, 0.8187302215189873, 0.45895965189873417], 'random_better-f1_score-num_gurus-2': [0.9168314873417721, 0.4065466772151899, 0.4365110759493671, 0.9102056962025317, 0.5277887658227848], 'random_better-f1_score-num_gurus-3': [0.7308148734177216, 0.1986748417721519, 0.5897943037974683, 0.7855023734177216, 0.9032832278481012], 'random_better-f1_score-num_gurus-4': [0.7185522151898734, 0.22349683544303797, 0.41544699367088606, 0.8425632911392406, 0.9353243670886076], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9409612341772152, 0.14942642405063292, 0.21687104430379747, 0.8566060126582279, 0.255439082278481], 'probabilistic_better-accuracy_score-num_gurus-2': [0.9254351265822784, 0.2477254746835443, 0.43908227848101267, 0.9088212025316456, 0.473496835443038], 'probabilistic_better-accuracy_score-num_gurus-3': [0.8213014240506329, 0.2086629746835443, 0.5293710443037974, 0.9021954113924051, 0.8098299050632911], 'probabilistic_better-accuracy_score-num_gurus-4': [0.7277492088607594, 0.2600870253164557, 0.4075356012658228, 0.8881526898734177, 0.9212816455696202], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9401700949367089, 0.16821598101265822, 0.2265625, 0.8575949367088608, 0.2613726265822785], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.9162381329113924, 0.1729628164556962, 0.5868275316455697, 0.8909216772151899, 0.49376977848101267], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.8338607594936709, 0.19284018987341772, 0.5406447784810127, 0.9126780063291139, 0.8162579113924051], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.7143987341772152, 0.20609177215189872, 0.4858583860759494, 0.8165545886075949, 0.9311708860759493], 'probabilistic_better-f1_score-num_gurus-1': [0.9388844936708861, 0.17316060126582278, 0.23496835443037975, 0.8568037974683544, 0.27155854430379744], 'probabilistic_better-f1_score-num_gurus-2': [0.918809335443038, 0.1675237341772152, 0.5549841772151899, 0.8860759493670886, 0.4852650316455696], 'probabilistic_better-f1_score-num_gurus-3': [0.8237737341772152, 0.21380537974683544, 0.5549841772151899, 0.9043710443037974, 0.8240704113924051], 'probabilistic_better-f1_score-num_gurus-4': [0.6862143987341772, 0.22062895569620253, 0.4798259493670886, 0.7920292721518988, 0.9414556962025317], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9392800632911392, 0.1607990506329114, 0.22794699367088608, 0.8583860759493671, 0.26424050632911394], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9232594936708861, 0.1830498417721519, 0.5836629746835443, 0.8937895569620253, 0.4620253164556962], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.8018196202531646, 0.33099287974683544, 0.4681566455696203, 0.889932753164557, 0.8283227848101266], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.7159810126582279, 0.2274525316455696, 0.390625, 0.8480023734177216, 0.9387856012658228], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9388844936708861, 0.17108386075949367, 0.22933148734177214, 0.8588805379746836, 0.25919699367088606], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9125791139240507, 0.20253164556962025, 0.5678401898734177, 0.8839992088607594, 0.48269382911392406], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.8200158227848101, 0.34572784810126583, 0.48170490506329117, 0.9049643987341772, 0.8427610759493671], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.7080696202531646, 0.22399129746835442, 0.42019382911392406, 0.8358386075949367, 0.9374011075949367], 'probabilistic_weighted-f1_score-num_gurus-1': [0.9390822784810127, 0.13805379746835442, 0.26127373417721517, 0.8474090189873418, 0.28500791139240506], 'probabilistic_weighted-f1_score-num_gurus-2': [0.9226661392405063, 0.27600870253164556, 0.44600474683544306, 0.9140625, 0.4802215189873418], 'probabilistic_weighted-f1_score-num_gurus-3': [0.8258504746835443, 0.20806962025316456, 0.4876384493670886, 0.9238528481012658, 0.8046875], 'probabilistic_weighted-f1_score-num_gurus-4': [0.7169699367088608, 0.2118275316455696, 0.4482792721518987, 0.8190268987341772, 0.9292919303797469], 'max_diversity-accuracy_score-num_gurus-1': [0.8594738924050633, 0.5164161392405063, 0.41752373417721517, 0.7582080696202531, 0.5323378164556962], 'max_diversity-accuracy_score-num_gurus-2': [0.6488330696202531, 0.3424643987341772, 0.4380933544303797, 0.6554588607594937, 0.915743670886076], 'max_diversity-accuracy_score-num_gurus-3': [0.7250791139240507, 0.35502373417721517, 0.40427215189873417, 0.8194224683544303, 0.915743670886076], 'max_diversity-accuracy_score-num_gurus-4': [0.6482397151898734, 0.22260680379746836, 0.4026898734177215, 0.7696795886075949, 0.9426424050632911], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.9213805379746836, 0.2857990506329114, 0.6417128164556962, 0.8636273734177216, 0.36649525316455694], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.8414754746835443, 0.3921083860759494, 0.4566851265822785, 0.8160601265822784, 0.8301028481012658], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.8370253164556962, 0.26513053797468356, 0.5514240506329114, 0.9052610759493671, 0.8310917721518988], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.6956091772151899, 0.2297270569620253, 0.41149129746835444, 0.8163568037974683, 0.939181170886076], 'max_diversity-f1_score-num_gurus-1': [0.892998417721519, 0.535996835443038, 0.5547863924050633, 0.8231803797468354, 0.33158623417721517], 'max_diversity-f1_score-num_gurus-2': [0.874307753164557, 0.6251977848101266, 0.5107792721518988, 0.876681170886076, 0.6115506329113924], 'max_diversity-f1_score-num_gurus-3': [0.6666337025316456, 0.4553006329113924, 0.41060126582278483, 0.7524723101265823, 0.928995253164557], 'max_diversity-f1_score-num_gurus-4': [0.7231012658227848, 0.24574762658227847, 0.45935522151898733, 0.8439477848101266, 0.9378955696202531], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.9361155063291139, 0.2467365506329114, 0.9403678797468354, 0.9442246835443038, 0.9400712025316456], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.9356210443037974, 0.2500988924050633, 0.9144580696202531, 0.9411590189873418, 0.9363132911392406], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.9359177215189873, 0.912381329113924, 0.36095727848101267, 0.9279074367088608, 0.9331487341772152], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.9376977848101266, 0.8854825949367089, 0.3794501582278481, 0.9103045886075949, 0.8659018987341772], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9275118670886076, 0.3160601265822785, 0.9141613924050633, 0.9458069620253164, 0.9410601265822784], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.9262262658227848, 0.232001582278481, 0.9402689873417721, 0.9494659810126582, 0.9416534810126582], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.9348299050632911, 0.8798457278481012, 0.887559335443038, 0.9480814873417721, 0.9414556962025317], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9322587025316456, 0.8620450949367089, 0.8079509493670886, 0.931368670886076, 0.940565664556962], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.8499802215189873, 0.3394976265822785, 0.9180181962025317, 0.9455102848101266, 0.9403678797468354], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8796479430379747, 0.29410601265822783, 0.9160403481012658, 0.9543117088607594, 0.9427412974683544], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.8536392405063291, 0.26908623417721517, 0.9224683544303798, 0.9505537974683544, 0.946993670886076], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.8535403481012658, 0.275810917721519, 0.90625, 0.9439280063291139, 0.9444224683544303], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.8521558544303798, 0.3403876582278481, 0.8649129746835443, 0.9508504746835443, 0.9444224683544303], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.8519580696202531, 0.3509691455696203, 0.8552215189873418, 0.9517405063291139, 0.9472903481012658], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.8513647151898734, 0.28589794303797467, 0.7106408227848101, 0.9544106012658228, 0.9457080696202531], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.8525514240506329, 0.2575158227848101, 0.8698575949367089, 0.8947784810126582, 0.9474881329113924], 'single_Net': [0.32792721518987344, 0.16811708860759494, 0.31596123417721517, 0.3771756329113924, 0.953817246835443]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.40it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1829\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5451\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.25it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.8951\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2901\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.24it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.5021\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4340\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.46it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.0442\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5991\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.21it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2959\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9702\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.1840\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5677\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.32it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.6316\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3425\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.29it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.8026\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2225\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.84it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.4766\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2641\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.40it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.7906\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3680\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.23it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1088\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9647\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.9621\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4324\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.42it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.6434\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3746\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.17it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.5289\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2470\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.00it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.3987\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3298\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.14it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.4402\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4256\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.29it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1125\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9620\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.8247\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [8:25:13<52:46, 3166.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.84it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2594\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9237\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.72it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2576\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9232\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.16it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2529\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9246\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.96it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9513\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9099\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.39it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2327\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9312\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.09it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2364\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9297\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.02it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7243\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9356\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.66it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2139\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9365\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.07it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2104\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9369\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.39it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5156\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9495\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.06it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1891\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9433\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 31.10it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1884\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9430\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.24it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7036\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9394\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.27it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2237\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9353\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.05it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2312\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9328\n",
      "-- >> End of training phase << --\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d580070>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d582dd0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d582aa0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d582ad0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x1c2d80ac0>\n",
      "Experience results are: \n",
      "{'full-ensemble': [0.30982990506329117, 0.19907041139240506, 0.2578125, 0.3248615506329114, 0.955498417721519], 'random_better-accuracy_score-num_gurus-1': [0.9237539556962026, 0.4407634493670886, 0.3088409810126582, 0.8651107594936709, 0.4131724683544304], 'random_better-accuracy_score-num_gurus-2': [0.9068433544303798, 0.489121835443038, 0.3537381329113924, 0.9023931962025317, 0.5700158227848101], 'random_better-accuracy_score-num_gurus-3': [0.8262460443037974, 0.3587816455696203, 0.3412776898734177, 0.9042721518987342, 0.8351463607594937], 'random_better-accuracy_score-num_gurus-4': [0.6448773734177216, 0.23971518987341772, 0.4053599683544304, 0.7983583860759493, 0.9464992088607594], 'random_better-balanced_accuracy_score-num_gurus-1': [0.923556170886076, 0.3302017405063291, 0.3160601265822785, 0.8556170886075949, 0.2867879746835443], 'random_better-balanced_accuracy_score-num_gurus-2': [0.8928006329113924, 0.32861946202531644, 0.5484572784810127, 0.8984375, 0.6618868670886076], 'random_better-balanced_accuracy_score-num_gurus-3': [0.8206091772151899, 0.3263449367088608, 0.4248417721518987, 0.914754746835443, 0.8470134493670886], 'random_better-balanced_accuracy_score-num_gurus-4': [0.6790941455696202, 0.23358386075949367, 0.35799050632911394, 0.8221914556962026, 0.9411590189873418], 'random_better-f1_score-num_gurus-1': [0.9145569620253164, 0.3805379746835443, 0.3004351265822785, 0.8399920886075949, 0.31952136075949367], 'random_better-f1_score-num_gurus-2': [0.9013053797468354, 0.25316455696202533, 0.7247824367088608, 0.8893393987341772, 0.5096914556962026], 'random_better-f1_score-num_gurus-3': [0.7612737341772152, 0.42207278481012656, 0.421875, 0.8625395569620253, 0.8824169303797469], 'random_better-f1_score-num_gurus-4': [0.6912579113924051, 0.239814082278481, 0.45263053797468356, 0.7872824367088608, 0.9408623417721519], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9376977848101266, 0.1932357594936709, 0.26631724683544306, 0.8427610759493671, 0.24901107594936708], 'probabilistic_better-accuracy_score-num_gurus-2': [0.9175237341772152, 0.18591772151898733, 0.6020569620253164, 0.8890427215189873, 0.4615308544303797], 'probabilistic_better-accuracy_score-num_gurus-3': [0.7890625, 0.2076740506329114, 0.5442049050632911, 0.8779667721518988, 0.8536392405063291], 'probabilistic_better-accuracy_score-num_gurus-4': [0.6511075949367089, 0.24228639240506328, 0.634493670886076, 0.7266613924050633, 0.9433346518987342], 'probabilistic_better-balanced_accuracy_score-num_gurus-1': [0.9366099683544303, 0.14220727848101267, 0.27838212025316456, 0.8382120253164557, 0.26730617088607594], 'probabilistic_better-balanced_accuracy_score-num_gurus-2': [0.9108979430379747, 0.19313686708860758, 0.6231210443037974, 0.8662974683544303, 0.4955498417721519], 'probabilistic_better-balanced_accuracy_score-num_gurus-3': [0.7802610759493671, 0.2354628164556962, 0.5542919303797469, 0.8579905063291139, 0.8847903481012658], 'probabilistic_better-balanced_accuracy_score-num_gurus-4': [0.6318235759493671, 0.18453322784810128, 0.576443829113924, 0.7076740506329114, 0.9432357594936709], 'probabilistic_better-f1_score-num_gurus-1': [0.9374011075949367, 0.1828520569620253, 0.25919699367088606, 0.8435522151898734, 0.25731803797468356], 'probabilistic_better-f1_score-num_gurus-2': [0.9167325949367089, 0.18888449367088608, 0.600870253164557, 0.8774723101265823, 0.47399129746835444], 'probabilistic_better-f1_score-num_gurus-3': [0.7852056962025317, 0.20895965189873417, 0.5647745253164557, 0.8754944620253164, 0.8724287974683544], 'probabilistic_better-f1_score-num_gurus-4': [0.614121835443038, 0.22804588607594936, 0.4630142405063291, 0.7219145569620253, 0.9492681962025317], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9345332278481012, 0.16989715189873417, 0.22260680379746836, 0.8344541139240507, 0.25187895569620256], 'probabilistic_weighted-accuracy_score-num_gurus-2': [0.9129746835443038, 0.18710443037974683, 0.6229232594936709, 0.8792523734177216, 0.49732990506329117], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.791435917721519, 0.224189082278481, 0.5638844936708861, 0.8731210443037974, 0.8711431962025317], 'probabilistic_weighted-accuracy_score-num_gurus-4': [0.6655458860759493, 0.21311313291139242, 0.6090783227848101, 0.7330893987341772, 0.9370055379746836], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-1': [0.9348299050632911, 0.13864715189873417, 0.2704707278481013, 0.840684335443038, 0.28411787974683544], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-2': [0.9259295886075949, 0.30033623417721517, 0.40644778481012656, 0.8981408227848101, 0.5196795886075949], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-3': [0.7868868670886076, 0.2299248417721519, 0.5505340189873418, 0.8699564873417721, 0.844442246835443], 'probabilistic_weighted-balanced_accuracy_score-num_gurus-4': [0.6347903481012658, 0.2196400316455696, 0.6263844936708861, 0.6986748417721519, 0.9432357594936709], 'probabilistic_weighted-f1_score-num_gurus-1': [0.9369066455696202, 0.13231803797468356, 0.25949367088607594, 0.8401898734177216, 0.26967958860759494], 'probabilistic_weighted-f1_score-num_gurus-2': [0.9160403481012658, 0.45905854430379744, 0.2565268987341772, 0.9074367088607594, 0.5369857594936709], 'probabilistic_weighted-f1_score-num_gurus-3': [0.7936115506329114, 0.1964992088607595, 0.5780261075949367, 0.8925039556962026, 0.8431566455696202], 'probabilistic_weighted-f1_score-num_gurus-4': [0.5687302215189873, 0.1706882911392405, 0.44788370253164556, 0.6852254746835443, 0.9481803797468354], 'max_diversity-accuracy_score-num_gurus-1': [0.9232594936708861, 0.30429193037974683, 0.31991693037974683, 0.8667919303797469, 0.4026898734177215], 'max_diversity-accuracy_score-num_gurus-2': [0.8879549050632911, 0.37114319620253167, 0.48724287974683544, 0.8481012658227848, 0.7339794303797469], 'max_diversity-accuracy_score-num_gurus-3': [0.6135284810126582, 0.38449367088607594, 0.44877373417721517, 0.7089596518987342, 0.9364121835443038], 'max_diversity-accuracy_score-num_gurus-4': [0.6174841772151899, 0.2219145569620253, 0.5266020569620253, 0.6952136075949367, 0.9443235759493671], 'max_diversity-balanced_accuracy_score-num_gurus-1': [0.8966574367088608, 0.6585245253164557, 0.6050237341772152, 0.8421677215189873, 0.346815664556962], 'max_diversity-balanced_accuracy_score-num_gurus-2': [0.8462223101265823, 0.6561511075949367, 0.5146360759493671, 0.8596716772151899, 0.5884098101265823], 'max_diversity-balanced_accuracy_score-num_gurus-3': [0.7641416139240507, 0.3916139240506329, 0.4110957278481013, 0.8469145569620253, 0.9023931962025317], 'max_diversity-balanced_accuracy_score-num_gurus-4': [0.6374604430379747, 0.23566060126582278, 0.3521558544303797, 0.8136867088607594, 0.9435324367088608], 'max_diversity-f1_score-num_gurus-1': [0.9228639240506329, 0.3674841772151899, 0.4501582278481013, 0.8575949367088608, 0.3647151898734177], 'max_diversity-f1_score-num_gurus-2': [0.9016020569620253, 0.46380537974683544, 0.5190862341772152, 0.9065466772151899, 0.5399525316455697], 'max_diversity-f1_score-num_gurus-3': [0.6620846518987342, 0.400810917721519, 0.44699367088607594, 0.7617681962025317, 0.9326542721518988], 'max_diversity-f1_score-num_gurus-4': [0.6709849683544303, 0.24594541139240506, 0.4384889240506329, 0.7786787974683544, 0.9410601265822784], 'StudentExpert-num_train_gurus-1-num_test_gurus-1': [0.932060917721519, 0.24050632911392406, 0.9321598101265823, 0.9022943037974683, 0.9371044303797469], 'StudentExpert-num_train_gurus-1-num_test_gurus-2': [0.935818829113924, 0.9107001582278481, 0.3095332278481013, 0.9397745253164557, 0.9374011075949367], 'StudentExpert-num_train_gurus-1-num_test_gurus-3': [0.9377966772151899, 0.21944224683544303, 0.9152492088607594, 0.8849881329113924, 0.9279074367088608], 'StudentExpert-num_train_gurus-1-num_test_gurus-4': [0.9394778481012658, 0.8565071202531646, 0.3482001582278481, 0.9004153481012658, 0.8849881329113924], 'StudentExpert-num_train_gurus-2-num_test_gurus-1': [0.9300830696202531, 0.9105023734177216, 0.9332476265822784, 0.9468947784810127, 0.9384889240506329], 'StudentExpert-num_train_gurus-2-num_test_gurus-2': [0.9329509493670886, 0.8890427215189873, 0.924248417721519, 0.9386867088607594, 0.9400712025316456], 'StudentExpert-num_train_gurus-2-num_test_gurus-3': [0.9367088607594937, 0.8812302215189873, 0.9251384493670886, 0.9339398734177216, 0.9434335443037974], 'StudentExpert-num_train_gurus-2-num_test_gurus-4': [0.9153481012658228, 0.850870253164557, 0.8924050632911392, 0.9012064873417721, 0.9397745253164557], 'StudentExpert-num_train_gurus-3-num_test_gurus-1': [0.8041930379746836, 0.35235363924050633, 0.9315664556962026, 0.9212816455696202, 0.939873417721519], 'StudentExpert-num_train_gurus-3-num_test_gurus-2': [0.8373219936708861, 0.29529272151898733, 0.9151503164556962, 0.939181170886076, 0.943631329113924], 'StudentExpert-num_train_gurus-3-num_test_gurus-3': [0.8543314873417721, 0.8863726265822784, 0.8862737341772152, 0.9385878164556962, 0.9442246835443038], 'StudentExpert-num_train_gurus-3-num_test_gurus-4': [0.821004746835443, 0.2827333860759494, 0.9137658227848101, 0.9145569620253164, 0.9449169303797469], 'StudentExpert-num_train_gurus-4-num_test_gurus-1': [0.724881329113924, 0.24920886075949367, 0.8893393987341772, 0.865506329113924, 0.9408623417721519], 'StudentExpert-num_train_gurus-4-num_test_gurus-2': [0.8215981012658228, 0.33999208860759494, 0.8948773734177216, 0.9384889240506329, 0.9434335443037974], 'StudentExpert-num_train_gurus-4-num_test_gurus-3': [0.7860957278481012, 0.30181962025316456, 0.8974485759493671, 0.9052610759493671, 0.9464992088607594], 'StudentExpert-num_train_gurus-4-num_test_gurus-4': [0.7813488924050633, 0.19679588607594936, 0.9099090189873418, 0.7386273734177216, 0.9437302215189873], 'single_Net': [0.2875791139240506, 0.18947784810126583, 0.27778876582278483, 0.35868275316455694, 0.9457080696202531]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.10it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1932\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5389\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.06it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.0613\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2505\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.20it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.6778\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3789\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.29it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.0203\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6240\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.93it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2799\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9674\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.2465\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5519\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.15it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.9073\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3559\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.82it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.6912\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2498\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.88it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.8274\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3135\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.20it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.7185\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3951\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.74it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0932\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9705\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.0475\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4570\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.32it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.3048\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3105\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.82it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.6990\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2102\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.82it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.2748\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3110\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 36.29it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.0342\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3531\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:02<00:00, 35.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [9:13:29<00:00, 3321.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1158\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9630\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.0857\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train ensembles - single guru\n",
    "\n",
    "data = RotatedMNIST(n_experiences=5, seed=0)\n",
    "\n",
    "ensembles_dict = get_ensembles_dict()\n",
    "\n",
    "exp = Experiment(\n",
    "    n_trials=num_trials,\n",
    "    ensembles=list(ensembles_dict.values()),\n",
    "    benchmark=data,\n",
    "    strategies_to_evaluate=initialize_strategies_to_evaluate,\n",
    ")\n",
    "_ = exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics = exp.get_aggregate_batch_metrics()\n",
    "dfs = []\n",
    "for ens, metric_dict in batch_metrics.items():\n",
    "    df = pd.DataFrame.from_dict(metric_dict, orient=\"index\")\n",
    "    df[\"ensemble_name\"] = ens\n",
    "    dfs.append(df)\n",
    "single_active_df = pd.concat(dfs)\n",
    "col_order = [len(single_active_df.columns) - 1] + list(\n",
    "    range(len(single_active_df.columns) - 1)\n",
    ")\n",
    "single_active_df = single_active_df[single_active_df.columns[col_order]]\n",
    "file_prefix = f\"domain_incremental_single_guru-trials={num_trials}-batch_size={batch_size}_window_size={window_size}-feb10\"\n",
    "path = \"results\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "filepath = f\"{path}/{file_prefix}.csv\"\n",
    "single_active_df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train acc for full-ensemble: 0.92+-0.021\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-1: 0.9+-0.037\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-2: 0.911+-0.026\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-3: 0.915+-0.023\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-4: 0.914+-0.022\n",
      "Mean train acc for random_better-balanced_accuracy_score-num_gurus-1: 0.9+-0.036\n",
      "Mean train acc for random_better-balanced_accuracy_score-num_gurus-2: 0.912+-0.026\n",
      "Mean train acc for random_better-balanced_accuracy_score-num_gurus-3: 0.915+-0.023\n",
      "Mean train acc for random_better-balanced_accuracy_score-num_gurus-4: 0.915+-0.022\n",
      "Mean train acc for random_better-f1_score-num_gurus-1: 0.9+-0.036\n",
      "Mean train acc for random_better-f1_score-num_gurus-2: 0.91+-0.027\n",
      "Mean train acc for random_better-f1_score-num_gurus-3: 0.915+-0.023\n",
      "Mean train acc for random_better-f1_score-num_gurus-4: 0.913+-0.023\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-1: 0.911+-0.024\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-2: 0.915+-0.022\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-3: 0.916+-0.022\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-4: 0.915+-0.022\n",
      "Mean train acc for probabilistic_better-balanced_accuracy_score-num_gurus-1: 0.911+-0.024\n",
      "Mean train acc for probabilistic_better-balanced_accuracy_score-num_gurus-2: 0.915+-0.022\n",
      "Mean train acc for probabilistic_better-balanced_accuracy_score-num_gurus-3: 0.916+-0.022\n",
      "Mean train acc for probabilistic_better-balanced_accuracy_score-num_gurus-4: 0.914+-0.022\n",
      "Mean train acc for probabilistic_better-f1_score-num_gurus-1: 0.911+-0.023\n",
      "Mean train acc for probabilistic_better-f1_score-num_gurus-2: 0.915+-0.022\n",
      "Mean train acc for probabilistic_better-f1_score-num_gurus-3: 0.916+-0.022\n",
      "Mean train acc for probabilistic_better-f1_score-num_gurus-4: 0.915+-0.022\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-1: 0.911+-0.024\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-2: 0.915+-0.022\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-3: 0.916+-0.022\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-4: 0.915+-0.022\n",
      "Mean train acc for probabilistic_weighted-balanced_accuracy_score-num_gurus-1: 0.911+-0.024\n",
      "Mean train acc for probabilistic_weighted-balanced_accuracy_score-num_gurus-2: 0.915+-0.022\n",
      "Mean train acc for probabilistic_weighted-balanced_accuracy_score-num_gurus-3: 0.917+-0.021\n",
      "Mean train acc for probabilistic_weighted-balanced_accuracy_score-num_gurus-4: 0.915+-0.022\n",
      "Mean train acc for probabilistic_weighted-f1_score-num_gurus-1: 0.911+-0.023\n",
      "Mean train acc for probabilistic_weighted-f1_score-num_gurus-2: 0.915+-0.022\n",
      "Mean train acc for probabilistic_weighted-f1_score-num_gurus-3: 0.916+-0.022\n",
      "Mean train acc for probabilistic_weighted-f1_score-num_gurus-4: 0.914+-0.022\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-1: 0.893+-0.042\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-2: 0.903+-0.032\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-3: 0.909+-0.026\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-4: 0.912+-0.023\n",
      "Mean train acc for max_diversity-balanced_accuracy_score-num_gurus-1: 0.893+-0.042\n",
      "Mean train acc for max_diversity-balanced_accuracy_score-num_gurus-2: 0.905+-0.031\n",
      "Mean train acc for max_diversity-balanced_accuracy_score-num_gurus-3: 0.909+-0.026\n",
      "Mean train acc for max_diversity-balanced_accuracy_score-num_gurus-4: 0.912+-0.023\n",
      "Mean train acc for max_diversity-f1_score-num_gurus-1: 0.895+-0.041\n",
      "Mean train acc for max_diversity-f1_score-num_gurus-2: 0.904+-0.032\n",
      "Mean train acc for max_diversity-f1_score-num_gurus-3: 0.909+-0.026\n",
      "Mean train acc for max_diversity-f1_score-num_gurus-4: 0.912+-0.023\n",
      "Mean train acc for StudentExpert-num_train_gurus-1-num_test_gurus-1: 0.911+-0.023\n",
      "Mean train acc for StudentExpert-num_train_gurus-1-num_test_gurus-2: 0.907+-0.027\n",
      "Mean train acc for StudentExpert-num_train_gurus-1-num_test_gurus-3: 0.898+-0.036\n",
      "Mean train acc for StudentExpert-num_train_gurus-1-num_test_gurus-4: 0.87+-0.061\n",
      "Mean train acc for StudentExpert-num_train_gurus-2-num_test_gurus-1: 0.912+-0.022\n",
      "Mean train acc for StudentExpert-num_train_gurus-2-num_test_gurus-2: 0.915+-0.022\n",
      "Mean train acc for StudentExpert-num_train_gurus-2-num_test_gurus-3: 0.913+-0.023\n",
      "Mean train acc for StudentExpert-num_train_gurus-2-num_test_gurus-4: 0.905+-0.028\n",
      "Mean train acc for StudentExpert-num_train_gurus-3-num_test_gurus-1: 0.913+-0.022\n",
      "Mean train acc for StudentExpert-num_train_gurus-3-num_test_gurus-2: 0.915+-0.022\n",
      "Mean train acc for StudentExpert-num_train_gurus-3-num_test_gurus-3: 0.917+-0.021\n",
      "Mean train acc for StudentExpert-num_train_gurus-3-num_test_gurus-4: 0.915+-0.022\n",
      "Mean train acc for StudentExpert-num_train_gurus-4-num_test_gurus-1: 0.912+-0.022\n",
      "Mean train acc for StudentExpert-num_train_gurus-4-num_test_gurus-2: 0.914+-0.022\n",
      "Mean train acc for StudentExpert-num_train_gurus-4-num_test_gurus-3: 0.915+-0.022\n",
      "Mean train acc for StudentExpert-num_train_gurus-4-num_test_gurus-4: 0.915+-0.022\n",
      "Mean train acc for single_Net: 0.91+-0.022\n",
      "Mean train acc for LwF: 0.933+-0.019\n",
      "Mean train acc for EWC: 0.934+-0.019\n",
      "Mean train acc for SynapticIntelligence: 0.934+-0.019\n",
      "--------------\n",
      "Mean test acc for full-ensemble: 0.425+-0.008\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-1: 0.594+-0.028\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-2: 0.65+-0.027\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-3: 0.66+-0.009\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-4: 0.598+-0.019\n",
      "Mean test acc for random_better-balanced_accuracy_score-num_gurus-1: 0.587+-0.03\n",
      "Mean test acc for random_better-balanced_accuracy_score-num_gurus-2: 0.64+-0.031\n",
      "Mean test acc for random_better-balanced_accuracy_score-num_gurus-3: 0.659+-0.015\n",
      "Mean test acc for random_better-balanced_accuracy_score-num_gurus-4: 0.611+-0.012\n",
      "Mean test acc for random_better-f1_score-num_gurus-1: 0.573+-0.027\n",
      "Mean test acc for random_better-f1_score-num_gurus-2: 0.65+-0.022\n",
      "Mean test acc for random_better-f1_score-num_gurus-3: 0.662+-0.011\n",
      "Mean test acc for random_better-f1_score-num_gurus-4: 0.613+-0.018\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-1: 0.493+-0.005\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-2: 0.608+-0.007\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-3: 0.661+-0.01\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-4: 0.617+-0.021\n",
      "Mean test acc for probabilistic_better-balanced_accuracy_score-num_gurus-1: 0.494+-0.007\n",
      "Mean test acc for probabilistic_better-balanced_accuracy_score-num_gurus-2: 0.613+-0.006\n",
      "Mean test acc for probabilistic_better-balanced_accuracy_score-num_gurus-3: 0.659+-0.012\n",
      "Mean test acc for probabilistic_better-balanced_accuracy_score-num_gurus-4: 0.615+-0.016\n",
      "Mean test acc for probabilistic_better-f1_score-num_gurus-1: 0.495+-0.004\n",
      "Mean test acc for probabilistic_better-f1_score-num_gurus-2: 0.608+-0.009\n",
      "Mean test acc for probabilistic_better-f1_score-num_gurus-3: 0.664+-0.006\n",
      "Mean test acc for probabilistic_better-f1_score-num_gurus-4: 0.61+-0.011\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-1: 0.491+-0.005\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-2: 0.61+-0.01\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-3: 0.66+-0.004\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-4: 0.62+-0.01\n",
      "Mean test acc for probabilistic_weighted-balanced_accuracy_score-num_gurus-1: 0.493+-0.007\n",
      "Mean test acc for probabilistic_weighted-balanced_accuracy_score-num_gurus-2: 0.614+-0.006\n",
      "Mean test acc for probabilistic_weighted-balanced_accuracy_score-num_gurus-3: 0.662+-0.008\n",
      "Mean test acc for probabilistic_weighted-balanced_accuracy_score-num_gurus-4: 0.619+-0.01\n",
      "Mean test acc for probabilistic_weighted-f1_score-num_gurus-1: 0.493+-0.008\n",
      "Mean test acc for probabilistic_weighted-f1_score-num_gurus-2: 0.609+-0.012\n",
      "Mean test acc for probabilistic_weighted-f1_score-num_gurus-3: 0.656+-0.006\n",
      "Mean test acc for probabilistic_weighted-f1_score-num_gurus-4: 0.611+-0.024\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-1: 0.617+-0.033\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-2: 0.671+-0.031\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-3: 0.636+-0.016\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-4: 0.588+-0.028\n",
      "Mean test acc for max_diversity-balanced_accuracy_score-num_gurus-1: 0.619+-0.028\n",
      "Mean test acc for max_diversity-balanced_accuracy_score-num_gurus-2: 0.665+-0.019\n",
      "Mean test acc for max_diversity-balanced_accuracy_score-num_gurus-3: 0.641+-0.033\n",
      "Mean test acc for max_diversity-balanced_accuracy_score-num_gurus-4: 0.61+-0.016\n",
      "Mean test acc for max_diversity-f1_score-num_gurus-1: 0.618+-0.022\n",
      "Mean test acc for max_diversity-f1_score-num_gurus-2: 0.664+-0.028\n",
      "Mean test acc for max_diversity-f1_score-num_gurus-3: 0.638+-0.02\n",
      "Mean test acc for max_diversity-f1_score-num_gurus-4: 0.605+-0.021\n",
      "Mean test acc for StudentExpert-num_train_gurus-1-num_test_gurus-1: 0.803+-0.016\n",
      "Mean test acc for StudentExpert-num_train_gurus-1-num_test_gurus-2: 0.803+-0.018\n",
      "Mean test acc for StudentExpert-num_train_gurus-1-num_test_gurus-3: 0.79+-0.036\n",
      "Mean test acc for StudentExpert-num_train_gurus-1-num_test_gurus-4: 0.778+-0.02\n",
      "Mean test acc for StudentExpert-num_train_gurus-2-num_test_gurus-1: 0.84+-0.057\n",
      "Mean test acc for StudentExpert-num_train_gurus-2-num_test_gurus-2: 0.831+-0.048\n",
      "Mean test acc for StudentExpert-num_train_gurus-2-num_test_gurus-3: 0.884+-0.052\n",
      "Mean test acc for StudentExpert-num_train_gurus-2-num_test_gurus-4: 0.824+-0.039\n",
      "Mean test acc for StudentExpert-num_train_gurus-3-num_test_gurus-1: 0.793+-0.01\n",
      "Mean test acc for StudentExpert-num_train_gurus-3-num_test_gurus-2: 0.815+-0.048\n",
      "Mean test acc for StudentExpert-num_train_gurus-3-num_test_gurus-3: 0.844+-0.058\n",
      "Mean test acc for StudentExpert-num_train_gurus-3-num_test_gurus-4: 0.792+-0.022\n",
      "Mean test acc for StudentExpert-num_train_gurus-4-num_test_gurus-1: 0.769+-0.018\n",
      "Mean test acc for StudentExpert-num_train_gurus-4-num_test_gurus-2: 0.775+-0.009\n",
      "Mean test acc for StudentExpert-num_train_gurus-4-num_test_gurus-3: 0.766+-0.008\n",
      "Mean test acc for StudentExpert-num_train_gurus-4-num_test_gurus-4: 0.75+-0.017\n",
      "Mean test acc for single_Net: 0.408+-0.013\n",
      "Mean test acc for LwF: 0.573+-0.013\n",
      "Mean test acc for EWC: 0.45+-0.011\n",
      "Mean test acc for SynapticIntelligence: 0.451+-0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    }
   ],
   "source": [
    "# Print results - single guru\n",
    "\n",
    "# Collect and print train accuracies - aggregate and by batch\n",
    "train_results_dict = dict()\n",
    "for ens_name, ensemble in ensembles_dict.items():\n",
    "    train_acc, train_acc_std = calculate_avg_std_train_accs(exp, ens_name, num_trials)\n",
    "    train_results_dict[ens_name] = (train_acc, train_acc_std)\n",
    "\n",
    "for strat_name, (strat, eval_plugin) in initialize_strategies_to_evaluate().items():\n",
    "    train_acc, train_acc_std = calculate_avg_std_train_accs(exp, strat_name, num_trials)\n",
    "    train_results_dict[strat_name] = (train_acc, train_acc_std)\n",
    "\n",
    "for ens_name, (train_acc, train_acc_std) in train_results_dict.items():\n",
    "    print(\n",
    "        f\"Mean train acc for {ens_name}: {round(np.mean(train_acc), 3)}+-{round(np.mean(train_acc_std), 3)}\"\n",
    "    )\n",
    "# for ens_name, (train_acc, train_acc_std) in train_results_dict.items():\n",
    "#     print(f\"All train accs for {ens_name}: {train_acc}\")\n",
    "\n",
    "print(\"--------------\")\n",
    "\n",
    "# Collect and print test accuracies\n",
    "# results_dict = dict()\n",
    "# for ens_name, ensemble in ensembles_dict.items():\n",
    "#     test_acc, test_acc_std = calculate_avg_std_test_accs(exp, ens_name, num_trials)\n",
    "#     results_dict[ens_name] = (test_acc, test_acc_std)\n",
    "\n",
    "# for strat_name, (strat, eval_plugin) in initialize_strategies_to_evaluate().items():\n",
    "#     test_acc, test_acc_std = calculate_avg_std_test_accs(exp, strat_name, num_trials)\n",
    "#     results_dict[strat_name] = (test_acc, test_acc_std)\n",
    "\n",
    "# for ens_name, (test_acc, test_acc_std) in results_dict.items():\n",
    "#     print(\n",
    "#         f\"Mean test acc for {ens_name}: {round(np.mean(test_acc), 3)}+-{round(np.mean(test_acc_std), 3)}\"\n",
    "#     )\n",
    "\n",
    "results_dict = dict()\n",
    "\n",
    "for ens_name, ensemble in ensembles_dict.items():\n",
    "    test_acc, _ = calculate_avg_std_test_accs_per_trial(exp, ens_name, num_trials)\n",
    "    print(\n",
    "        f\"Mean test acc for {ens_name}: {round(np.mean(test_acc), 3)}+-{round(np.std(test_acc), 3)}\"\n",
    "    )\n",
    "    results_dict[ens_name] = (np.mean(test_acc), np.std(test_acc))\n",
    "\n",
    "for strat_name, (strat, eval_plugin) in initialize_strategies_to_evaluate().items():\n",
    "    test_acc, _ = calculate_avg_std_test_accs_per_trial(exp, strat_name, num_trials)\n",
    "    print(\n",
    "        f\"Mean test acc for {strat_name}: {round(np.mean(test_acc), 3)}+-{round(np.std(test_acc), 3)}\"\n",
    "    )\n",
    "    results_dict[strat_name] = (np.mean(test_acc), np.std(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"mean\", \"std\"])\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={\"index\": \"name\"})\n",
    "df = df.sort_values(by=\"mean\", ascending=False, ignore_index=True)\n",
    "# write to csv in results/keepers/class_inc_avgs.csv\n",
    "df.to_csv(\"results/keepers/domain_inc_avgs-feb11.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Results\n",
    "\n",
    "(leftover copied code from other file, not adapted for the above code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_avg_test_accs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xticklabels([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo Delegation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProba Slope\u001b[39m\u001b[38;5;124m\"\u001b[39m], rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m, ha\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Data for bar plot\u001b[39;00m\n\u001b[1;32m     23\u001b[0m means \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 24\u001b[0m     np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mfull_avg_test_accs\u001b[49m),\n\u001b[1;32m     25\u001b[0m     np\u001b[38;5;241m.\u001b[39mmean(proba_slope_avg_test_accs),\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# np.mean(restricted_max_guru_avg_test_accs),\u001b[39;00m\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     28\u001b[0m stds \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     29\u001b[0m     np\u001b[38;5;241m.\u001b[39mstd(full_avg_test_accs),\n\u001b[1;32m     30\u001b[0m     np\u001b[38;5;241m.\u001b[39mstd(proba_slope_avg_test_accs),\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# np.std(restricted_max_guru_avg_test_accs),\u001b[39;00m\n\u001b[1;32m     32\u001b[0m ]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Create each bar individually to set different colors\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_avg_test_accs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = \"Georgia\"\n",
    "\n",
    "# set colors for each bar. Use pastel\n",
    "colors = sns.color_palette(\"pastel\")\n",
    "# assign colors for each bar\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Test Accuracies\")\n",
    "ax.set_ylabel(\"Test Accuracy\")\n",
    "ax.set_xlabel(\"Delegation Mechanism\")\n",
    "# ax.set_xticks([0, 1, 2])\n",
    "# ax.set_xticklabels(\n",
    "#     [\"No Delegation\", \"Proba Slope\", \"Restricted Max Guru\"], rotation=45, ha=\"right\"\n",
    "# )\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"No Delegation\", \"Proba Slope\"], rotation=45, ha=\"right\")\n",
    "# Data for bar plot\n",
    "means = [\n",
    "    np.mean(full_avg_test_accs),\n",
    "    np.mean(proba_slope_avg_test_accs),\n",
    "    # np.mean(restricted_max_guru_avg_test_accs),\n",
    "]\n",
    "stds = [\n",
    "    np.std(full_avg_test_accs),\n",
    "    np.std(proba_slope_avg_test_accs),\n",
    "    # np.std(restricted_max_guru_avg_test_accs),\n",
    "]\n",
    "\n",
    "# Create each bar individually to set different colors\n",
    "for i in range(len(ensembles)):\n",
    "    ax.bar(i, means[i], color=colors[i], yerr=stds[i], capsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_slope_avg_train_accs, proba_slope_std_train_accs = calculate_avg_std_train_accs(\n",
    "    exp, \"proba_slope_delegations\", num_trials\n",
    ")\n",
    "full_avg_train_accs, full_std_train_accs = calculate_avg_std_train_accs(\n",
    "    exp, \"full_ensemble\", num_trials\n",
    ")\n",
    "\n",
    "# (\n",
    "#     restricted_max_guru_avg_train_accs,\n",
    "#     restricted_max_guru_std_train_accs,\n",
    "# ) = calculate_avg_std_train_accs(exp, \"restricted_max_guru_delegations\", num_trials)\n",
    "\n",
    "print(\n",
    "    \"Mean train accs for proba_slope delegation ensemble: \",\n",
    "    np.mean(proba_slope_avg_train_accs),\n",
    ")\n",
    "print(\"Mean train accs for full ensemble: \", np.mean(full_avg_train_accs))\n",
    "\n",
    "# print(\n",
    "#     \"Mean train accs for restricted_max_guru delegation ensemble: \",\n",
    "#     np.mean(restricted_max_guru_avg_train_accs),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits = exp.train_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"pastel\", context=\"paper\")\n",
    "\n",
    "# Set the font to Georgia\n",
    "mpl.rcParams[\"font.family\"] = \"Georgia\"\n",
    "mpl.rcParams[\"font.size\"] = 12\n",
    "mpl.rcParams[\"axes.labelsize\"] = 14\n",
    "mpl.rcParams[\"axes.titlesize\"] = 16\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "colors = sns.color_palette(\"pastel\")\n",
    "proba_slope_color = colors[1]\n",
    "full_color = colors[0]\n",
    "restricted_max_guru_color = colors[2]\n",
    "\n",
    "ax.plot(\n",
    "    proba_slope_avg_train_accs,\n",
    "    label=\"ProbaSlope Delegation Ensemble\",\n",
    "    color=proba_slope_color,\n",
    "    linewidth=2,\n",
    ")\n",
    "ax.fill_between(\n",
    "    range(len(proba_slope_avg_train_accs)),\n",
    "    np.array(proba_slope_avg_train_accs) - np.array(proba_slope_std_train_accs),\n",
    "    np.array(proba_slope_avg_train_accs) + np.array(proba_slope_std_train_accs),\n",
    "    color=proba_slope_color,\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "ax.plot(full_avg_train_accs, label=\"Full Ensemble\", color=full_color, linewidth=2)\n",
    "ax.fill_between(\n",
    "    range(len(full_avg_train_accs)),\n",
    "    np.array(full_avg_train_accs) - np.array(full_std_train_accs),\n",
    "    np.array(full_avg_train_accs) + np.array(full_std_train_accs),\n",
    "    color=full_color,\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "# ax.plot(\n",
    "#     restricted_max_guru_avg_train_accs,\n",
    "#     label=\"Restricted Max Guru Delegation Ensemble\",\n",
    "#     color=restricted_max_guru_color,\n",
    "#     linewidth=2,\n",
    "# )\n",
    "# ax.fill_between(\n",
    "#     range(len(restricted_max_guru_avg_train_accs)),\n",
    "#     np.array(restricted_max_guru_avg_train_accs)\n",
    "#     - np.array(restricted_max_guru_std_train_accs),\n",
    "#     np.array(restricted_max_guru_avg_train_accs)\n",
    "#     + np.array(restricted_max_guru_std_train_accs),\n",
    "#     color=colors[2],\n",
    "#     alpha=0.3,\n",
    "# )\n",
    "\n",
    "\n",
    "# plot vertical lines at test splits\n",
    "for split in train_splits[:-1]:\n",
    "    ax.axvline(x=split, color=\"k\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Setting labels, title, and legend\n",
    "ax.set_xlabel(\"Batch Number\")\n",
    "ax.set_ylabel(\"Train Accuracy\")\n",
    "ax.set_title(\n",
    "    \"ProbaSlope Delegation Ensemble vs Full Ensemble vs Restricted Max Guru Delegation Ensemble\"\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "# set y lim to lower\n",
    "ax.set_ylim(top=1.3)\n",
    "# set y ticks to 0-1\n",
    "ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_voters = exp.ensembles[1].voters\n",
    "print(ensembles[1].name)\n",
    "batch_accs = []\n",
    "for v in ps_voters:\n",
    "    batch_accs.append(v.batch_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len(data.train_data_loader.dataset) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_active_streaks(voter_id, trial_num):\n",
    "    \"\"\"\n",
    "    Find active streaks for a specified voter.\n",
    "\n",
    "    :param voter_id: ID of the voter for which to find active streaks.\n",
    "    :param batch_metric_values: Dictionary containing the batch metric values.\n",
    "    :param metric_key: Key to access the relevant metric in batch_metric_values.\n",
    "    :return: List of active streaks for the specified voter.\n",
    "    \"\"\"\n",
    "    active_batches = []\n",
    "    active_streak = [None, None]\n",
    "    voter_active = False\n",
    "\n",
    "    for i, av in enumerate(\n",
    "        exp.batch_metric_values[\"proba_slope_delegations\"][trial_num][\n",
    "            \"active_voters-train\"\n",
    "        ]\n",
    "    ):\n",
    "        # print(av)\n",
    "        if voter_id in av:\n",
    "            if not voter_active:\n",
    "                # Start a new streak\n",
    "                active_streak[0] = i\n",
    "                voter_active = True\n",
    "                # print(\"streak started\")\n",
    "            active_streak[1] = i\n",
    "        else:\n",
    "            if voter_active:\n",
    "                # End the current streak\n",
    "                active_batches.append(active_streak.copy())\n",
    "                active_streak = [None, None]\n",
    "                voter_active = False\n",
    "                # print(\"streak done\")\n",
    "\n",
    "    # Handle case where the streak continues till the end of the list\n",
    "    if voter_active:\n",
    "        active_batches.append(active_streak.copy())\n",
    "\n",
    "    return active_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at activity on last trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for voter_id in range(n_voters):\n",
    "    active_streaks = find_active_streaks(voter_id, num_trials - 1)\n",
    "    # print(f\"Active Streaks for Voter {voter_id}: {active_streaks}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))  # Create a new figure for each voter\n",
    "    plt.plot(batch_accs[voter_id])\n",
    "    plt.axvline(x=len_train, color=\"k\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # Shade the active batches for this voter\n",
    "    for streak in active_streaks:\n",
    "        if streak[0] is not None and streak[1] is not None:\n",
    "            plt.axvspan(streak[0], streak[1], alpha=0.3, color=\"red\")\n",
    "\n",
    "    # Plot a green vertical line at all train splits\n",
    "    for split in train_splits[:-1]:\n",
    "        plt.axvline(x=split, color=\"g\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "    plt.title(f\"Voter {voter_id} Activity\")\n",
    "    plt.xlabel(\"Batches\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()  # Display the plot for each voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
