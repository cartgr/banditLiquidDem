{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/carterblair/waterloo/research/BanditLiquidDem/banditLiquidDem/experiments', '/Users/carterblair/opt/anaconda3/envs/LDE/lib/python310.zip', '/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10', '/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/lib-dynload', '', '/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages', '/Users/carterblair/waterloo/research/BanditLiquidDem/banditLiquidDem']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if \"/Users/carterblair/waterloo/research/BanditLiquidDem/banditLiquidDem\" not in sys.path:\n",
    "    sys.path.append(\"/Users/carterblair/waterloo/research/BanditLiquidDem/banditLiquidDem\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from exp_framework.Ensemble import Ensemble, PretrainedEnsemble, StudentExpertEnsemble\n",
    "from exp_framework.delegation import (\n",
    "    DelegationMechanism,\n",
    "    UCBDelegationMechanism,\n",
    "    ProbaSlopeDelegationMechanism,\n",
    "    RestrictedMaxGurusDelegationMechanism,\n",
    "    StudentExpertDelegationMechanism,\n",
    ")\n",
    "from exp_framework.learning import Net\n",
    "from exp_framework.experiment import (\n",
    "    Experiment,\n",
    "    calculate_avg_std_test_accs,\n",
    "    calculate_avg_std_train_accs,\n",
    "    calculate_avg_std_test_accs_per_trial,\n",
    ")\n",
    "from avalanche.training.supervised import Naive\n",
    "from matplotlib import pyplot as plt\n",
    "from exp_framework.data_utils import Data\n",
    "from avalanche.benchmarks.classic import RotatedMNIST, SplitMNIST\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.plugins import (\n",
    "    CWRStarPlugin,\n",
    "    ReplayPlugin,\n",
    "    EWCPlugin,\n",
    "    TrainGeneratorAfterExpPlugin,\n",
    "    LwFPlugin,\n",
    "    SynapticIntelligencePlugin,\n",
    ")\n",
    "from exp_framework.MinibatchEvalAccuracy import MinibatchEvalAccuracy\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import accuracy_metrics\n",
    "\n",
    "from avalanche.training import EWC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning the mapping $\\mathcal{X} \\rightarrow \\mathcal{G}$ (i.e. $\\mathcal{X} \\rightarrow \\mathcal{Y}\\times\\mathcal{C}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up global experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "window_size = 50\n",
    "num_trials = 10\n",
    "n_voters = 30\n",
    "\n",
    "ensemble_width = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Delegation Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Delegation Mechanisms and Ensembles\n",
    "\n",
    "For simplicity, only explore full ensemble and variants of ProbaSlopeDelegationMechanism since they can be created programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensembles_dict(lo_num_gurus=[1, 3, 5, 7, 9, 11]):\n",
    "    NOOP_del_mech = DelegationMechanism(batch_size=batch_size, window_size=window_size)\n",
    "    NOOP_del_mech2 = DelegationMechanism(batch_size=batch_size, window_size=window_size)\n",
    "\n",
    "    probability_functions = [\n",
    "        \"random_better\",\n",
    "        \"probabilistic_better\",\n",
    "        \"probabilistic_weighted\",\n",
    "        \"max_diversity\",\n",
    "    ]\n",
    "    score_functions = [\n",
    "        \"accuracy_score\",\n",
    "        # \"balanced_accuracy_score\",\n",
    "        # \"f1_score\",\n",
    "        # \"precision_score\",\n",
    "        # \"recall_score\",\n",
    "        # \"top_k_accuracy_score\",\n",
    "        # \"roc_auc_score\",\n",
    "        # \"log_loss_score\",\n",
    "        # \"max_diversity\",\n",
    "    ]\n",
    "    # probability_functions = [\"max_diversity\"]\n",
    "    # score_functions = [\"accuracy_score\"]\n",
    "\n",
    "    del_mechs = {\"full-ensemble\": NOOP_del_mech}\n",
    "    for prob_func, score_func in product(probability_functions, score_functions):\n",
    "        for num_gurus in lo_num_gurus:\n",
    "            dm = ProbaSlopeDelegationMechanism(\n",
    "                batch_size=batch_size,\n",
    "                window_size=window_size,\n",
    "                max_active=num_gurus,\n",
    "                probability_function=prob_func,\n",
    "                score_method=score_func,\n",
    "            )\n",
    "            del_mechs[f\"{prob_func}-{score_func}-num_gurus-{num_gurus}\"] = dm\n",
    "\n",
    "    ensembles_dict = {\n",
    "        dm_name: Ensemble(\n",
    "            training_epochs=1,\n",
    "            n_voters=n_voters,\n",
    "            delegation_mechanism=dm,\n",
    "            name=dm_name,\n",
    "            input_dim=28 * 28,\n",
    "            output_dim=10,\n",
    "            width=16,\n",
    "        )\n",
    "        for dm_name, dm in del_mechs.items()\n",
    "    }\n",
    "    ensembles_dict[\"single_Net\"] = Ensemble(\n",
    "        training_epochs=1,\n",
    "        n_voters=1,\n",
    "        delegation_mechanism=NOOP_del_mech2,\n",
    "        name=\"single_Net\",\n",
    "        input_dim=28 * 28,\n",
    "        output_dim=10,\n",
    "        width=512,\n",
    "    )\n",
    "    return ensembles_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Avalanche Strategies to Compare Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_strategies_to_evaluate():\n",
    "    plugins_to_evaluate = {\n",
    "        \"LwF\": LwFPlugin(),\n",
    "        \"EWC\": EWCPlugin(ewc_lambda=0.001),\n",
    "        \"SynapticIntelligence\": SynapticIntelligencePlugin(si_lambda=0.5),\n",
    "        # \"Replay\": ReplayPlugin(mem_size=100),\n",
    "    }\n",
    "\n",
    "    strategies_to_evaluate = {}\n",
    "    for name, pte in plugins_to_evaluate.items():\n",
    "        model = Net(input_dim=28 * 28, output_dim=10, width=512)\n",
    "        optimize = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        mb_eval = MinibatchEvalAccuracy()\n",
    "        evp = EvaluationPlugin(\n",
    "            accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            mb_eval,\n",
    "        )\n",
    "        cl_strategy = Naive(\n",
    "            model=model,\n",
    "            optimizer=optimize,\n",
    "            criterion=CrossEntropyLoss(),\n",
    "            train_mb_size=batch_size,\n",
    "            train_epochs=1,\n",
    "            eval_mb_size=batch_size,\n",
    "            # plugins=[pte, evp],\n",
    "            plugins=[pte, evp, mb_eval],\n",
    "        )\n",
    "        # cl_strategy = EWC(\n",
    "        #     model=model,\n",
    "        #     optimizer=optimize,\n",
    "        #     criterion=CrossEntropyLoss(),\n",
    "        #     ewc_lambda=0.001,\n",
    "        #     train_mb_size=batch_size,\n",
    "        #     train_epochs=1,\n",
    "        #     eval_mb_size=batch_size,\n",
    "        # )\n",
    "        strategies_to_evaluate[name] = (cl_strategy, evp)\n",
    "\n",
    "    return strategies_to_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Ensemble - single active voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 63.67it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0725\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9863\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 67.53it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0812\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9874\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 54.41it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0706\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9875\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 54.01it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0963\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8896\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 54.17it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9392\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8529\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 52.12it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1021\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8743\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 58.73it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5025\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8121\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 50.49it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2352\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7676\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 53.93it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3781\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7892\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 60.04it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6026\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8401\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 42.64it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3084\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8158\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 54.80it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3919\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8536\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 50.68it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0952\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7427\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 40.23it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5660\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7771\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 51.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0862\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6697\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9959753787878788, 0.8412828947368421, 0.7081846703182567, 0.7566271796822548, 0.6370127688172043], 'random_better-accuracy_score-num_gurus-1': [0.9957386363636364, 0.4977796052631579, 0.6012038913640109, 0.6623110566288233, 0.6486055107526881], 'random_better-accuracy_score-num_gurus-3': [0.9959753787878788, 0.7255756578947369, 0.8121441873637113, 0.862060546875, 0.751008064516129], 'random_better-accuracy_score-num_gurus-5': [0.9960542929292929, 0.6743421052631579, 0.7419204657728021, 0.8238932291666666, 0.6694388440860215], 'random_better-accuracy_score-num_gurus-7': [0.9967645202020202, 0.7095394736842106, 0.8098359487273477, 0.8129069010416666, 0.7641969086021505], 'random_better-accuracy_score-num_gurus-9': [0.9959753787878788, 0.7401315789473685, 0.7584332498637113, 0.8616536458333334, 0.744119623655914], 'random_better-accuracy_score-num_gurus-11': [0.9962121212121212, 0.7446546052631579, 0.7884403521364386, 0.8069661458333334, 0.7386592741935484], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9962121212121212, 0.6635690789473684, 0.7344616814093157, 0.8369954427083334, 0.7859543010752689], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9961332070707071, 0.7955592105263158, 0.8111676248637113, 0.8570149739583334, 0.7332829301075269], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9958175505050505, 0.7550164473684211, 0.804686801000075, 0.8308919270833334, 0.7852822580645161], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9962121212121212, 0.780921052631579, 0.8071704994548451, 0.8409830729166666, 0.8133400537634409], 'probabilistic_better-accuracy_score-num_gurus-9': [0.9960542929292929, 0.8143914473684211, 0.7824034203182567, 0.8454129869739214, 0.767557123655914], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9962910353535354, 0.7971217105263158, 0.7962528521364386, 0.8614448880155882, 0.7557963709677419], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9962910353535354, 0.7715460526315789, 0.775300448591059, 0.744873046875, 0.7407594086021505], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9959753787878788, 0.7306743421052632, 0.7873750112273477, 0.8662923177083334, 0.7825100806451613], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9961332070707071, 0.7695723684210526, 0.7962528521364386, 0.8583984375, 0.667002688172043], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9966856060606061, 0.7449013157894737, 0.7551484487273477, 0.8605497057239214, 0.6917002688172043], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9961332070707071, 0.815625, 0.7963416305455294, 0.873291015625, 0.7777217741935484], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.9960542929292929, 0.7935855263157895, 0.7863984487273477, 0.8457385078072548, 0.7475638440860215], 'max_diversity-accuracy_score-num_gurus-1': [0.9960542929292929, 0.7222861842105263, 0.7380121187730269, 0.7728678385416666, 0.42545922917704426], 'max_diversity-accuracy_score-num_gurus-3': [0.9963699494949495, 0.44810855263157895, 0.6974417838183317, 0.8578287760416666, 0.5539594536186546], 'max_diversity-accuracy_score-num_gurus-5': [0.9960542929292929, 0.5771381578947369, 0.7689964825456793, 0.7918648098905882, 0.764616935483871], 'max_diversity-accuracy_score-num_gurus-7': [0.9961332070707071, 0.6257401315789474, 0.7317088517275724, 0.8412272135416666, 0.7344030020057514], 'max_diversity-accuracy_score-num_gurus-9': [0.9958175505050505, 0.6163651315789473, 0.7323303005912087, 0.8101753567655882, 0.6747311827956989], 'max_diversity-accuracy_score-num_gurus-11': [0.9961332070707071, 0.6217105263157895, 0.7131562612273477, 0.7719266588489214, 0.6843077956989247], 'single_Net': [0.9973958333333334, 0.9041940789473685, 0.8288345282728021, 0.8329264322916666, 0.7867943548387096]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c5793f0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d45dc60>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d3d7160>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d45e950>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d45e770>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.0, 0.9574885293841362], 'random_better-accuracy_score-num_gurus-1': [0.9384191176470589, 0.00048828125, 0.22892530461152394, 0.05643347557634115, 0.0], 'random_better-accuracy_score-num_gurus-3': [0.9379595588235294, 0.10831839125603437, 0.2098196138938268, 0.08960700780153275, 0.0244140625], 'random_better-accuracy_score-num_gurus-5': [0.9132668446092045, 0.0024654200533404946, 0.0, 0.8531753085553646, 0.41298518143594265], 'random_better-accuracy_score-num_gurus-7': [0.5661147377070259, 0.0, 0.0, 0.8396513983607292, 0.9320669025182724], 'random_better-accuracy_score-num_gurus-9': [0.0, 0.0, 0.0, 0.980527937412262, 0.30504402332007885], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.984922468662262, 0.20820932555943727], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9370404411764706, 0.0, 0.3980564018090566, 0.0, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9370404411764706, 0.08480884972959757, 0.2270706295967102, 0.5903764218091965, 0.051804315531626344], 'probabilistic_better-accuracy_score-num_gurus-5': [0.7945703478420482, 0.0, 0.3508892277876536, 0.9425011835992336, 0.27617342583835125], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9054543446092045, 0.0, 0.0, 0.8590938672423363, 0.18822079617530107], 'probabilistic_better-accuracy_score-num_gurus-9': [0.007730190916096463, 0.0, 0.0, 0.9663973711431026, 0.5064019113779068], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.976133406162262, 0.36513361893594265], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9388786764705882, 0.0, 0.1819232722123464, 0.0, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9384191176470589, 0.0, 0.0, 0.06665778905153275, 0.002945188549347222], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9388786764705882, 0.0, 0.0, 0.10654888767749071, 0.003921751049347222], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9287683823529411, 0.22525774873793125, 0.0, 0.8006184883415699, 0.7082480788230896], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.0, 0.0009765625, 0.0, 0.981992781162262, 0.26347811333835125], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.985410749912262, 0.14517454151064157], 'max_diversity-accuracy_score-num_gurus-1': [0.9384191176470589, 0.00048828125, 0.4028709352016449, 0.1557469218969345, 0.0], 'max_diversity-accuracy_score-num_gurus-3': [0.9972426470588235, 0.00341796875, 0.0, 0.26586174219846725, 0.003433469799347222], 'max_diversity-accuracy_score-num_gurus-5': [0.9361213235294118, 0.05885790195316076, 0.0, 0.6431107968091965, 0.031769283348694444], 'max_diversity-accuracy_score-num_gurus-7': [0.37451300550909605, 0.0, 0.0, 0.9595614336431026, 0.7048146091401577], 'max_diversity-accuracy_score-num_gurus-9': [0.5759369520580068, 0.0, 0.0, 0.968809187412262, 0.37346540205180645], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.972227156162262, 0.39156281016767025], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.97314453125]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 90.34it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 19.0518\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 90.50it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 19.3161\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 84.41it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 17.7395\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 93.14it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.5014\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 96.31it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0903\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9657\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 13.0045\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1915\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 88.78it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 10.0663\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 75.23it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 10.9370\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 96.29it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 15.8312\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 89.29it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 18.1880\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 90.93it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0922\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9718\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.9595\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1927\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 91.53it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 13.9919\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 90.24it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.3742\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 67.00it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 14.4221\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 85.55it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 17.7703\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 92.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [15:04<2:15:37, 904.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0891\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9713\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 11.7357\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1926\n",
      "Starting trial  1\n",
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 61.73it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0891\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9874\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 55.64it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0867\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9864\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 50.43it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0646\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9874\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 57.31it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9305\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8986\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 57.78it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7801\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8985\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 50.46it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0384\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8629\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 56.82it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3128\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8163\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 48.25it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2487\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8262\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 53.28it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3307\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7842\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 56.19it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4240\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8549\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 44.20it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5397\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7845\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 53.10it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2448\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8264\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 57.53it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0650\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7975\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 39.75it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5566\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7708\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 51.91it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5550\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7931\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9964488636363636, 0.831887696291271, 0.7612720619548451, 0.7657063802083334, 0.6651265678867218], 'random_better-accuracy_score-num_gurus-1': [0.9962910353535354, 0.6828745383965341, 0.8481868234547701, 0.7110613395149509, 0.409890232868092], 'random_better-accuracy_score-num_gurus-3': [0.9936868686868687, 0.7107528278702184, 0.7769865393638611, 0.8405549420664707, 0.7253584227254314], 'random_better-accuracy_score-num_gurus-5': [0.9962121212121212, 0.7267067752386395, 0.8268807042728771, 0.834716796875, 0.7453517022953239], 'random_better-accuracy_score-num_gurus-7': [0.9961332070707071, 0.7332034857649552, 0.8125866814093157, 0.880126953125, 0.6686547936931733], 'random_better-accuracy_score-num_gurus-9': [0.9962121212121212, 0.7273646699754815, 0.7999801473184065, 0.8173828125, 0.7793738797146786], 'random_better-accuracy_score-num_gurus-11': [0.9958964646464646, 0.7530225647123236, 0.8148061416365884, 0.8351236979166666, 0.6892361108974744], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9960542929292929, 0.5988082873193841, 0.6747990948232737, 0.7432702103008827, 0.7701332883168293], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9961332070707071, 0.7881376962912711, 0.7768082835457542, 0.8707293082649509, 0.7138496861662916], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9957386363636364, 0.7407692752386394, 0.8265248916365884, 0.8827311197916666, 0.7470318098222056], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9959753787878788, 0.7692232226070604, 0.7817812724546953, 0.853515625, 0.7471158151985496], 'probabilistic_better-accuracy_score-num_gurus-9': [0.9962121212121212, 0.7870686173439025, 0.8016669370911338, 0.86328125, 0.7261984764888723], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9957386363636364, 0.8158515120807447, 0.8243942098184065, 0.8268229166666666, 0.7359431001447863], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9955808080808081, 0.7459299978456999, 0.794563965363936, 0.7779381790508827, 0.6601702506824206], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9961332070707071, 0.7607528278702184, 0.7591413801366632, 0.887451171875, 0.7811379926179045], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9960542929292929, 0.7609173015544289, 0.7834673632274974, 0.8683268229166666, 0.8151601700372594], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9962121212121212, 0.7933186173439026, 0.8192450620911338, 0.857666015625, 0.732834901220055], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9962910353535354, 0.7786602610035946, 0.7947415221821178, 0.8133951822916666, 0.7574484764888723], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.9962121212121212, 0.8179896699754815, 0.8288324312730269, 0.8286946614583334, 0.7134296592845711], 'max_diversity-accuracy_score-num_gurus-1': [0.9958964646464646, 0.48491026100359463, 0.7560348348184065, 0.744384765625, 0.6611783151985496], 'max_diversity-accuracy_score-num_gurus-3': [0.9956597222222222, 0.59718374892285, 0.7313145913861014, 0.8081868489583334, 0.8263328850910228], 'max_diversity-accuracy_score-num_gurus-5': [0.9955018939393939, 0.5675799281973588, 0.7710383859547701, 0.8125813802083334, 0.673275089392098], 'max_diversity-accuracy_score-num_gurus-7': [0.9948705808080808, 0.5622547325335051, 0.7531939257274974, 0.8086751302083334, 0.5262376791046511], 'max_diversity-accuracy_score-num_gurus-9': [0.9963699494949495, 0.5969788783474972, 0.7070242593234236, 0.7696126302083334, 0.7061771955541385], 'max_diversity-accuracy_score-num_gurus-11': [0.9958964646464646, 0.6389600647123237, 0.7289567210457542, 0.74560546875, 0.7247983870967742], 'single_Net': [0.9974747474747475, 0.8852594068175867, 0.842772738500075, 0.8771158854166666, 0.813424059139785]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d3d6290>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c578250>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c581b40>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c578250>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c581b40>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.00244140625, 0.9613947793841362], 'random_better-accuracy_score-num_gurus-1': [0.9467323317247278, 0.0, 0.319969513018926, 0.34740471094846725, 0.0], 'random_better-accuracy_score-num_gurus-3': [0.9370815964306102, 0.12487192638218403, 0.0, 0.28114642575383186, 0.00341796875], 'random_better-accuracy_score-num_gurus-5': [0.930188214077669, 0.0, 0.0, 0.7216648906469345, 0.18130735401064157], 'random_better-accuracy_score-num_gurus-7': [0.3291812994900872, 0.00390625, 0.0, 0.983916312456131, 0.20477585587650537], 'random_better-accuracy_score-num_gurus-9': [0.0, 0.0, 0.0, 0.978574812412262, 0.32942708395421505], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.980010062456131, 0.3015020461753011], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9366220376070808, 0.0, 0.15594512224197388, 0.00341796875, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9370815964306102, 0.0009765625, 0.027439024299383163, 0.04147431347519159, 0.0], 'probabilistic_better-accuracy_score-num_gurus-5': [0.8898293446092045, 0.0, 0.010708841433127721, 0.9190636835992336, 0.06401134678162634], 'probabilistic_better-accuracy_score-num_gurus-7': [0.7588070666088778, 0.0, 0.0, 0.980039656162262, 0.1490342882461846], 'probabilistic_better-accuracy_score-num_gurus-9': [0.0, 0.21939837373793125, 0.0, 0.980986624956131, 0.1548626613803208], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.973203718662262, 0.44620380736887455], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9370815964306102, 0.0, 0.024542682866255442, 0.0, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9343242434894338, 0.007372246356680989, 0.6449822147687276, 0.00390625, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.7519136842559365, 0.0, 0.0, 0.971738874912262, 0.21307663712650537], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.8761248904116014, 0.0, 0.0, 0.8912908397614956, 0.41586836613714695], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.00045955882352941176, 0.0, 0.0, 0.987334281206131, 0.1534288194961846], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9707919023931026, 0.5288163460791111], 'max_diversity-accuracy_score-num_gurus-1': [0.938000714077669, 0.0, 0.0, 0.12522194627672434, 0.0], 'max_diversity-accuracy_score-num_gurus-3': [0.9058727516847498, 0.10629322472959757, 0.8647230704625447, 0.13455847557634115, 0.10656932089477777], 'max_diversity-accuracy_score-num_gurus-5': [0.8990205210797927, 0.0, 0.003125, 0.8366625234484673, 0.7053028903901577], 'max_diversity-accuracy_score-num_gurus-7': [0.550825834274292, 0.0, 0.0, 0.978086531162262, 0.36557539738714695], 'max_diversity-accuracy_score-num_gurus-9': [0.17409734427928925, 0.0, 0.0, 0.9532433710992336, 0.6407722607254982], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.959043562412262, 0.6192103810608387], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.9731290303170681]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 92.23it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 16.4300\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 89.61it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 16.3346\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 85.72it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 15.7329\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 91.57it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.5191\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 88.04it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0944\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9718\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 11.4694\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1927\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 73.88it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.2109\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 89.06it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 9.5910\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 91.48it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.9389\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 85.23it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 14.0892\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 92.83it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0871\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9702\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.3341\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1924\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 91.43it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 12.6302\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 76.69it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.3209\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 87.70it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 18.8869\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 95.59it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 21.4080\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 93.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [29:47<1:58:55, 891.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0694\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9733\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 12.9920\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1930\n",
      "Starting trial  2\n",
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 53.88it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0699\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9871\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 50.89it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0660\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9905\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:03<00:00, 30.58it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0660\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9871\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 57.03it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4273\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8271\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 53.87it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1133\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8826\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 53.44it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2931\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8244\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 51.20it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5302\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7948\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 46.78it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4613\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7969\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 50.64it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5800\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7565\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 51.81it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5484\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8468\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 39.22it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3477\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8416\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 45.89it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4996\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7768\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 55.95it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2187\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7437\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 39.30it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8584\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7605\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 51.36it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7836\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6958\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9965277777777778, 0.8368219068175868, 0.7251392494548451, 0.759033203125, 0.6102430557691922], 'random_better-accuracy_score-num_gurus-1': [0.9955018939393939, 0.6260488805017973, 0.7143068855459039, 0.7018653759732842, 0.6504256270265066], 'random_better-accuracy_score-num_gurus-3': [0.9948705808080808, 0.6518510504772789, 0.7129766074093905, 0.8749186197916666, 0.7407034052315579], 'random_better-accuracy_score-num_gurus-5': [0.9943181818181818, 0.7207655241614894, 0.8092117038640109, 0.8400065104166666, 0.7921987009304826], 'random_better-accuracy_score-num_gurus-7': [0.9960542929292929, 0.7253707873193841, 0.7416513345458291, 0.8570963541666666, 0.7814740141232809], 'random_better-accuracy_score-num_gurus-9': [0.9964488636363636, 0.7636311173439025, 0.7728132551366632, 0.841552734375, 0.6848398299627406], 'random_better-accuracy_score-num_gurus-11': [0.9948705808080808, 0.7292561173439026, 0.7719247720458291, 0.8334147135416666, 0.7409554213605901], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9952651515151515, 0.5711146699754815, 0.8146278858184814, 0.7813278418034315, 0.6935763891025256], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9959753787878788, 0.6154619693756104, 0.64408386295492, 0.8382161458333334, 0.7768257170595149], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9956597222222222, 0.7981503925825421, 0.7610959031365134, 0.8248697916666666, 0.8091117829404851], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9960542929292929, 0.7895155241614894, 0.7693508971821178, 0.8700358072916666, 0.7233142923283321], 'probabilistic_better-accuracy_score-num_gurus-9': [0.9958175505050505, 0.8008844068175868, 0.8222628290002997, 0.839599609375, 0.7585405463813454], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9959753787878788, 0.8089234188983315, 0.7752102721821178, 0.8427734375, 0.7433075718982245], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9961332070707071, 0.6138576294246473, 0.8094787380912087, 0.740234375, 0.8443100356286571], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9939236111111112, 0.7813740767930684, 0.7431619655002247, 0.811767578125, 0.7492719536186546], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9961332070707071, 0.7798938136351736, 0.8236832835457542, 0.83447265625, 0.6805835571340335], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9951073232323232, 0.8182363805017974, 0.7961612777276472, 0.8689778645833334, 0.7813060033705926], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9961332070707071, 0.801275392582542, 0.8243928118185564, 0.840087890625, 0.7055051525433859], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.9961332070707071, 0.7919205910281131, 0.8154268915002997, 0.83740234375, 0.7092013891025256], 'max_diversity-accuracy_score-num_gurus-1': [0.9956597222222222, 0.5679492730843393, 0.6342007985169237, 0.650546308606863, 0.5624439966294074], 'max_diversity-accuracy_score-num_gurus-3': [0.9957386363636364, 0.6190385504772788, 0.6953090050003745, 0.8085902115950981, 0.559167786951988], 'max_diversity-accuracy_score-num_gurus-5': [0.9958964646464646, 0.5178872346878052, 0.7324190790002997, 0.8155464505155882, 0.6465333783498375], 'max_diversity-accuracy_score-num_gurus-7': [0.9962121212121212, 0.540008945214121, 0.7553253065456044, 0.806640625, 0.6634184589949987], 'max_diversity-accuracy_score-num_gurus-9': [0.9958175505050505, 0.601584141505392, 0.6858998916365884, 0.7679036458333334, 0.7404793904673669], 'max_diversity-accuracy_score-num_gurus-11': [0.9962121212121212, 0.545354339950963, 0.7589638233184814, 0.7303059895833334, 0.6261200718982245], 'single_Net': [0.9977904040404041, 0.9050784857649552, 0.8765085339546204, 0.8299967447916666, 0.764084901220055]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c579330>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c6ffbe0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d128040>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d1d3fa0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d3d4700>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.001953125, 0.9521174356341362], 'random_better-accuracy_score-num_gurus-1': [0.9558823529411765, 0.0, 0.01643800809979439, 0.0, 0.0], 'random_better-accuracy_score-num_gurus-3': [0.9297286552541396, 0.26011782698333263, 0.1174415647983551, 0.7246833555400372, 0.12118675606325269], 'random_better-accuracy_score-num_gurus-5': [0.9356617647058824, 0.00048828125, 0.0010416666666666667, 0.2748283613473177, 0.6363777294754982], 'random_better-accuracy_score-num_gurus-7': [0.06245884545804823, 0.17928726971149445, 0.0, 0.981474906206131, 0.24832589365541935], 'random_better-accuracy_score-num_gurus-9': [0.013745610163930585, 0.0, 0.0, 0.977109968662262, 0.44818793423473835], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9620324335992336, 0.5909210704267025], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9379595588235294, 0.0, 0.07362804859876633, 0.0, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9384191176470589, 0.0, 0.4686229666074117, 0.13001598045229912, 0.20241195522248745], 'probabilistic_better-accuracy_score-num_gurus-5': [0.6740356122746187, 0.0, 0.12977642317612967, 0.967832624912262, 0.42528521828353405], 'probabilistic_better-accuracy_score-num_gurus-7': [0.6636303768438452, 0.2934890501201153, 0.0, 0.9712801836431026, 0.05038597481325269], 'probabilistic_better-accuracy_score-num_gurus-9': [0.5773979355307186, 0.0, 0.0, 0.979063093662262, 0.38660249300301075], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.981474906206131, 0.30602058582007885], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9384191176470589, 0.0, 0.11525660554567972, 0.0, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9379595588235294, 0.0, 0.0, 0.37972005270421505, 0.007339719799347222], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9301470588235294, 0.009789638803340495, 0.0, 0.7957652695477009, 0.15542844776064157], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.7555489995900322, 0.00146484375, 0.0, 0.974638968706131, 0.19456845242530107], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.013663301134810728, 0.0, 0.0, 0.962461531162262, 0.6070343516767025], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9527254961431026, 0.7371186763048172], 'max_diversity-accuracy_score-num_gurus-1': [0.8935058151974398, 0.0, 0.9275787591934204, 0.035496567375957966, 0.0], 'max_diversity-accuracy_score-num_gurus-3': [0.9375, 0.03183433646336198, 0.3558689018090566, 0.014618844725191593, 0.0], 'max_diversity-accuracy_score-num_gurus-5': [0.8861940292751088, 0.27239689975976944, 0.0, 0.7272431328892708, 0.5528351329267025], 'max_diversity-accuracy_score-num_gurus-7': [0.6874039734111113, 0.0, 0.0, 0.9190340898931026, 0.8079659603536129], 'max_diversity-accuracy_score-num_gurus-9': [0.003216911764705882, 0.0, 0.0, 0.6937440820038319, 0.9008014015853405], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9659090898931026, 0.6515299491584301], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.9721369668841362]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 88.01it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 19.7308\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 84.94it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 16.6082\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 78.65it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 15.9589\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 93.97it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 7.7185\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 93.81it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0827\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9728\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 12.1044\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1929\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 94.14it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 10.9835\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 76.85it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 14.1145\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 92.47it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 14.2163\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 87.99it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 14.1504\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 92.66it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0812\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9728\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.6957\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1929\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 93.54it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.4754\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 92.76it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.9183\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 73.26it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 14.0787\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 91.16it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.3893\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 94.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [45:06<1:45:29, 904.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1287\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9622\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.9496\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1908\n",
      "Starting trial  3\n",
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 64.34it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0779\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9862\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 60.24it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0977\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9807\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 51.53it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0663\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9897\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 54.72it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2870\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8376\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 52.23it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9192\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8854\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 52.42it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1150\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8810\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 56.40it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6240\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7673\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 47.64it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1066\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8300\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 52.15it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4394\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8017\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 53.08it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8403\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8774\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 40.26it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3152\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8212\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 48.51it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1129\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8204\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 51.14it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8445\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7684\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 32.62it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8130\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7764\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 48.30it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5192\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7806\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9962075557371582, 0.8346015120807447, 0.7402329770001498, 0.74072265625, 0.6246639784946236], 'random_better-accuracy_score-num_gurus-1': [0.9958918991715017, 0.6226771699754815, 0.7881733179092407, 0.8333333333333334, 0.6559139784946236], 'random_better-accuracy_score-num_gurus-3': [0.9962864698785724, 0.7454567752386394, 0.7499979030002247, 0.8622233072916666, 0.6115591397849462], 'random_better-accuracy_score-num_gurus-5': [0.9959708133129158, 0.7225949331333763, 0.795808261091059, 0.8385416666666666, 0.8089717741935484], 'random_better-accuracy_score-num_gurus-7': [0.9950238436159461, 0.7580390120807446, 0.817382113500075, 0.8790690104166666, 0.7183019711125281], 'random_better-accuracy_score-num_gurus-9': [0.995497328464431, 0.7568876962912711, 0.8204893578182567, 0.8650716145833334, 0.7098454301075269], 'random_better-accuracy_score-num_gurus-11': [0.99604972745433, 0.7770357226070604, 0.788972323591059, 0.826416015625, 0.7481518817204301], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9959708133129158, 0.6552429594491658, 0.7347287156365134, 0.8404947916666666, 0.741263440860215], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9961286415957441, 0.692825196291271, 0.8021115281365134, 0.7803158968066176, 0.4474686377791948], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9951816718987744, 0.7551607226070605, 0.8128516186367382, 0.8350423177083334, 0.7622367829404851], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9959708133129158, 0.747512696291271, 0.7845327041365884, 0.859619140625, 0.7726814516129032], 'probabilistic_better-accuracy_score-num_gurus-9': [0.99604972745433, 0.7682363805017973, 0.7973174940456044, 0.8523763020833334, 0.7741935483870968], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9961286415957441, 0.8036804594491658, 0.8020241477272727, 0.8212076822916666, 0.6752352150537635], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9955762426058451, 0.6032490767930684, 0.8149850964546204, 0.8746744791666666, 0.8392137096774194], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9953395001816027, 0.73937124892285, 0.7879943630912087, 0.8583170572916666, 0.7505040322580645], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9952605860401885, 0.6977594068175867, 0.7873743122274225, 0.8870442708333334, 0.7804099462365591], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9961286415957441, 0.7914271699754816, 0.8084154941818931, 0.8658040364583334, 0.7710013440860215], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9947871011917038, 0.7779403278702184, 0.7944765849546953, 0.8636067708333334, 0.7526041666666666], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.9955762426058451, 0.7688120383965341, 0.8032656474546953, 0.8251139322916666, 0.765625], 'max_diversity-accuracy_score-num_gurus-1': [0.9961286415957441, 0.6319699331333762, 0.6899368624118242, 0.6568196614583334, 0.6107190860215054], 'max_diversity-accuracy_score-num_gurus-3': [0.9953395001816027, 0.6071344068175868, 0.7376486164602366, 0.7689722033683211, 0.5737007170595149], 'max_diversity-accuracy_score-num_gurus-5': [0.9958129850300875, 0.5370686173439025, 0.7573658119548451, 0.786865234375, 0.4128584227254314], 'max_diversity-accuracy_score-num_gurus-7': [0.99604972745433, 0.5989727610035946, 0.7341946471821178, 0.852294921875, 0.7451836915426356], 'max_diversity-accuracy_score-num_gurus-9': [0.9954184143230168, 0.6220192752386394, 0.7891449867324396, 0.76513671875, 0.6789874549834959], 'max_diversity-accuracy_score-num_gurus-11': [0.9962075557371582, 0.6914271699754815, 0.7594978917728771, 0.797119140625, 0.6450492829404851], 'single_Net': [0.9975536616161617, 0.8533515120807447, 0.8072613748637113, 0.8560384114583334, 0.8249327956989247]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d12bf70>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d1d3fd0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d27f490>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d1d3fd0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c5786a0>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.0029296875, 0.9604182168841362], 'random_better-accuracy_score-num_gurus-1': [0.9370404411764706, 0.0, 0.14696392317612966, 0.00341796875, 0.0], 'random_better-accuracy_score-num_gurus-3': [0.9379595588235294, 0.01323162135668099, 0.0, 0.10859079100191593, 0.00439453125], 'random_better-accuracy_score-num_gurus-5': [0.8750823105082792, 0.6684250123798847, 0.012563516199588776, 0.8495058007538319, 0.46727740578353405], 'random_better-accuracy_score-num_gurus-7': [0.6921298819429734, 0.019066982553340495, 0.0, 0.973691999912262, 0.18620566744357347], 'random_better-accuracy_score-num_gurus-9': [0.04896702135310454, 0.0, 0.0, 0.9469253085553646, 0.7111777663230896], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.976621687412262, 0.43401227705180645], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9375, 0.0, 0.0885035569469134, 0.0, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9375, 0.0, 0.008625508099794389, 0.5020714960992336, 0.00146484375], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9379595588235294, 0.0, 0.0, 0.2676225146278739, 0.055206783348694444], 'probabilistic_better-accuracy_score-num_gurus-7': [0.7499519867055556, 0.00048828125, 0.0, 0.971250593662262, 0.18963913712650537], 'probabilistic_better-accuracy_score-num_gurus-9': [0.015041977605398963, 0.0, 0.0, 0.985381156206131, 0.20819382462650537], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9703036211431026, 0.5205930694937706], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9388786764705882, 0.0, 0.1441946138938268, 0.005829782225191593, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9370404411764706, 0.00932537135668099, 0.4399771332740784, 0.33632220700383186, 0.004898313549347222], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9209970376070808, 0.0029296875, 0.0, 0.8500532656908035, 0.20871310774236917], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.014664727810989408, 0.0, 0.0026041666666666665, 0.8846324570477009, 0.7067677341401577], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.0, 0.0, 0.0, 0.983916312456131, 0.20923239178955555], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.975645124912262, 0.43163287453353405], 'max_diversity-accuracy_score-num_gurus-1': [0.961438214077669, 0.0, 0.8278455297152202, 0.0, 0.44577752985060215], 'max_diversity-accuracy_score-num_gurus-3': [0.9765625, 0.0, 0.33011941115061444, 0.2948774863034487, 0.00634765625], 'max_diversity-accuracy_score-num_gurus-5': [0.9361213235294118, 0.00048828125, 0.0, 0.8822502382099628, 0.1250775051303208], 'max_diversity-accuracy_score-num_gurus-7': [0.9007764493717867, 0.0009765625, 0.0, 0.7443329766392708, 0.7463340163230896], 'max_diversity-accuracy_score-num_gurus-9': [0.12299714653807528, 0.0, 0.0, 0.9668856523931026, 0.6236824169754982], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.979063093662262, 0.34757099486887455], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.9721524678170681]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 91.83it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 19.1588\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 81.37it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 21.0541\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 88.99it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 18.0594\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 83.56it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.1205\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 85.12it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0712\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9743\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 13.3625\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1932\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 70.07it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.6963\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 82.86it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.1421\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 92.86it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 14.8839\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 92.15it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 15.7390\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 94.37it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0733\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9758\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.8827\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1935\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 67.14it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 12.1521\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 83.22it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.0614\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 79.65it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 15.5661\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 89.68it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 18.7281\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 81.69it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0876\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9677\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 11.4828\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [1:01:41<1:34:01, 940.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial  4\n",
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 63.62it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0700\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9865\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 61.01it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0815\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9779\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 53.03it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0616\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9925\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 56.79it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6306\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7825\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 54.32it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9781\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8618\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 49.53it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0714\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8782\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 55.92it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6711\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7493\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 47.08it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0886\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8275\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 49.91it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4583\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7906\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 54.34it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8558\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8087\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 43.69it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2438\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8523\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 51.41it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5714\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8246\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 54.99it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0972\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7465\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 33.56it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5219\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7595\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 50.28it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6927\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6906\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9956551567472592, 0.8369863805017973, 0.7176825620911338, 0.7704618150989214, 0.6137992829404851], 'random_better-accuracy_score-num_gurus-1': [0.9941557880603906, 0.4573811173439026, 0.7707706527276472, 0.7772163723905882, 0.857750895843711], 'random_better-accuracy_score-num_gurus-3': [0.9948660153331179, 0.676604339950963, 0.7307329882274974, 0.8619331692655882, 0.8509184589949987], 'random_better-accuracy_score-num_gurus-5': [0.9959708133129158, 0.672512696291271, 0.7708615281365134, 0.8648628567655882, 0.7897625450165041], 'random_better-accuracy_score-num_gurus-7': [0.99604972745433, 0.7741372346878052, 0.8366463292728771, 0.8450874661405882, 0.7102934589949987], 'random_better-accuracy_score-num_gurus-9': [0.9957340708886734, 0.7160982226070605, 0.8166711872274225, 0.8437853828072548, 0.7633288528329583], 'random_better-accuracy_score-num_gurus-11': [0.9958129850300875, 0.7825455910281132, 0.8097464713183317, 0.8276721015572548, 0.6894881270265066], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9961286415957441, 0.39739006255802356, 0.7310894998637113, 0.845947265625, 0.4286514337985746], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9962075557371582, 0.7508844068175868, 0.755769198591059, 0.7877144192655882, 0.7460237453060765], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9958129850300875, 0.7934830910281131, 0.7986484711820429, 0.8592476223905882, 0.7467797936931733], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9958129850300875, 0.7511931557404368, 0.838777011091059, 0.8568875963489214, 0.7473678313275819], 'probabilistic_better-accuracy_score-num_gurus-9': [0.9955762426058451, 0.7616992730843394, 0.810456698591059, 0.8513537421822548, 0.694780465736184], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9962075557371582, 0.8031048015544289, 0.7967841245911338, 0.8327990546822548, 0.7623767923283321], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9953395001816027, 0.5309008541860079, 0.795630005272952, 0.8009546252433211, 0.5032202063068267], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9959708133129158, 0.6883021699754815, 0.8006015961820429, 0.8898465807239214, 0.8404457883168293], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9958918991715017, 0.71593374892285, 0.8014013008637861, 0.8929390286405882, 0.8198644711125281], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9958918991715017, 0.7929074331333763, 0.8109012896364386, 0.8329618150989214, 0.6850358420802701], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9962075557371582, 0.8118219068175868, 0.8214659203182567, 0.8221382473905882, 0.7522121417906976], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.99604972745433, 0.7973482226070605, 0.8101008859547701, 0.8251493150989214, 0.673191084015754], 'max_diversity-accuracy_score-num_gurus-1': [0.99604972745433, 0.6698609188983314, 0.7776086872274225, 0.8070015286405882, 0.7326948924731183], 'max_diversity-accuracy_score-num_gurus-3': [0.9961286415957441, 0.5550582873193841, 0.7418302893638611, 0.8090360338489214, 0.7286346324028508], 'max_diversity-accuracy_score-num_gurus-5': [0.994392530484633, 0.4988905241614894, 0.609102373096076, 0.8109077786405882, 0.545950940860215], 'max_diversity-accuracy_score-num_gurus-7': [0.9958129850300875, 0.5393553784019068, 0.7051627094095404, 0.8090006510416666, 0.6113911290322581], 'max_diversity-accuracy_score-num_gurus-9': [0.99604972745433, 0.6237260504772789, 0.7089808800003745, 0.8334147135416666, 0.6238519267369342], 'max_diversity-accuracy_score-num_gurus-11': [0.9955762426058451, 0.653762696291271, 0.7115582498637113, 0.7818550442655882, 0.7087253582093024], 'single_Net': [0.9974701819997845, 0.8934008541860079, 0.7799176248637113, 0.8135119453072548, 0.7207381270265066]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c579ae0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d27dff0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c579ae0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d27dff0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c579ae0>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.00390625, 0.9564964659512043], 'random_better-accuracy_score-num_gurus-1': [0.8811388822162852, 0.0, 0.895515751838684, 0.0, 0.0], 'random_better-accuracy_score-num_gurus-3': [0.9269713023129631, 0.010277920053340495, 0.5076854666074117, 0.6955048516392708, 0.2638888889923692], 'random_better-accuracy_score-num_gurus-5': [0.9334051258423749, 0.05820152396336198, 0.0, 0.6350467577576637, 0.017578125], 'random_better-accuracy_score-num_gurus-7': [0.1612296972204657, 0.0, 0.0, 0.9742098711431026, 0.36705574207007885], 'random_better-accuracy_score-num_gurus-9': [0.0, 0.0, 0.0, 0.972227156162262, 0.48383246548473835], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.976592093706131, 0.33231026865541935], 'probabilistic_better-accuracy_score-num_gurus-1': [0.938000714077669, 0.0, 0.13608993887901305, 0.0107421875, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9384602729011985, 0.0, 0.0, 0.0, 0.0], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9054131928612205, 0.0, 0.11913109719753265, 0.8908321484923363, 0.041534908348694444], 'probabilistic_better-accuracy_score-num_gurus-7': [0.8609182939809912, 0.0, 0.0, 0.9371596835553646, 0.1504991319961846], 'probabilistic_better-accuracy_score-num_gurus-9': [0.11827809495084426, 0.0, 0.0, 0.9205581210553646, 0.7604631707072258], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9503432773053646, 0.7179982028901577], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9375411552541396, 0.0, 0.08521341482798259, 0.07022372167557478, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9375411552541396, 0.01274334010668099, 0.0, 0.10287937987595797, 0.09628441231325269], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9370815964306102, 0.009301357553340495, 0.0, 0.20063920505344868, 0.5078512541949749], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9343242434894338, 0.0, 0.0, 0.4171105585992336, 0.45302424393594265], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.043452315470751596, 0.0, 0.0, 0.973691999912262, 0.37973555363714695], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.98681640625, 0.08839440729934722], 'max_diversity-accuracy_score-num_gurus-1': [0.9899308611364925, 0.0, 0.40489075183868406, 0.0, 0.0], 'max_diversity-accuracy_score-num_gurus-3': [0.9343242434894338, 0.0, 0.2460746943950653, 0.2377189863473177, 0.504906065762043], 'max_diversity-accuracy_score-num_gurus-5': [0.593441342606264, 0.040063076303340495, 0.027896341433127723, 0.973691999912262, 0.32252914272248745], 'max_diversity-accuracy_score-num_gurus-7': [0.7253004277453703, 0.00927734375, 0.0, 0.9707919023931026, 0.37830171175301075], 'max_diversity-accuracy_score-num_gurus-9': [0.00045955882352941176, 0.0, 0.0, 0.975156843662262, 0.46478949673473835], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.517030656337738, 0.9120008684694767], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.9736018106341362]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 89.12it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 24.1248\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 80.34it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 21.9709\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 88.88it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 18.2996\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 82.10it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 10.4883\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 74.01it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0920\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9738\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 15.1194\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1931\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 84.34it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.6598\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 84.19it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 10.1943\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 88.53it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 16.2197\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 84.16it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 14.2312\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 70.27it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0836\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9692\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.0072\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1922\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 92.57it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 10.4568\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 78.85it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 10.9298\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 82.85it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 15.2555\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 69.53it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 14.7051\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 86.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [1:17:55<1:19:21, 952.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0834\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9743\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.2393\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1932\n",
      "Starting trial  5\n",
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 57.29it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0680\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9883\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 60.37it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0732\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9867\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:02<00:00, 48.86it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0659\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9873\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 51.20it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1718\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8799\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 55.56it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8276\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9007\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 50.41it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9848\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8812\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 55.10it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7834\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7704\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 47.18it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2319\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8088\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 51.48it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6383\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7589\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 53.74it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5855\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8096\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 41.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1262\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8501\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 49.79it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1481\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8242\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 55.57it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9779\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7840\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 37.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4986\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8055\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 50.98it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0294\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6812\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9962910353535354, 0.8381174978456999, 0.7502621412277222, 0.7638346354166666, 0.6477654569892473], 'random_better-accuracy_score-num_gurus-1': [0.9962910353535354, 0.5573811173439026, 0.4282509677789428, 0.555419921875, 0.6463373655913979], 'random_better-accuracy_score-num_gurus-3': [0.9960542929292929, 0.6652758541860079, 0.8195994767275724, 0.8025256171822548, 0.6793514784946236], 'random_better-accuracy_score-num_gurus-5': [0.9958175505050505, 0.6631578947368421, 0.8348693630912087, 0.849609375, 0.7863743279569892], 'random_better-accuracy_score-num_gurus-7': [0.9964488636363636, 0.7147824331333763, 0.843392090363936, 0.7967936197916666, 0.7775537634408602], 'random_better-accuracy_score-num_gurus-9': [0.9958175505050505, 0.7536804594491657, 0.825813965363936, 0.851318359375, 0.761676747311828], 'random_better-accuracy_score-num_gurus-11': [0.9955018939393939, 0.7332034857649552, 0.7719254710457542, 0.819580078125, 0.7443716397849462], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9966066919191919, 0.5362664473684211, 0.7220802388407968, 0.4385579427083333, 0.6640625], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9955018939393939, 0.8038651315789473, 0.7780511812730269, 0.8759765625, 0.7741935483870968], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9962910353535354, 0.7149671052631579, 0.79154480045492, 0.7849934895833334, 0.7391633064516129], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9962121212121212, 0.8025291436596921, 0.8153374140912836, 0.8147786458333334, 0.7319388440860215], 'probabilistic_better-accuracy_score-num_gurus-9': [0.9962121212121212, 0.7544205910281131, 0.7887038913640109, 0.849365234375, 0.6744791666666666], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9958964646464646, 0.7958059210526316, 0.7721023288640109, 0.8758138020833334, 0.7101814516129032], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9960542929292929, 0.5389600647123236, 0.7123558575456793, 0.8160807291666666, 0.8125840053763441], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9958964646464646, 0.7991574331333763, 0.72220886295492, 0.8550618489583334, 0.7887264784946236], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9958964646464646, 0.752200196291271, 0.8113430846821178, 0.84375, 0.7022849462365591], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9962910353535354, 0.7806743421052632, 0.7719247720458291, 0.845703125, 0.7841061827956989], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9958964646464646, 0.7440789473684211, 0.7906570163640109, 0.8607584635416666, 0.7204301075268817], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.9955018939393939, 0.8014802631578948, 0.7833771868185564, 0.806884765625, 0.7426075268817204], 'max_diversity-accuracy_score-num_gurus-1': [0.9959753787878788, 0.6156048015544289, 0.6789465146985921, 0.5970865885416666, 0.5512152778044823], 'max_diversity-accuracy_score-num_gurus-3': [0.9957386363636364, 0.5651936173439026, 0.6689327298240229, 0.7190755208333334, 0.6390288978494624], 'max_diversity-accuracy_score-num_gurus-5': [0.9958964646464646, 0.6148646699754815, 0.7689063061367382, 0.8350423177083334, 0.6529737903225806], 'max_diversity-accuracy_score-num_gurus-7': [0.991082702020202, 0.5989742034359982, 0.7270909764549949, 0.8282877604166666, 0.6234038978494624], 'max_diversity-accuracy_score-num_gurus-9': [0.9960542929292929, 0.578453947368421, 0.761267168278044, 0.767333984375, 0.6561659946236559], 'max_diversity-accuracy_score-num_gurus-11': [0.9956597222222222, 0.5825657894736842, 0.7969595844095404, 0.80859375, 0.6548219086021505], 'single_Net': [0.9975536616161617, 0.8977594068175868, 0.8192450620911338, 0.828369140625, 0.7553763440860215]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c321d20>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d1d2b90>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c321d20>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d1d2b90>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c321d20>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.0009765625, 0.9609064981341362], 'random_better-accuracy_score-num_gurus-1': [0.9366220376070808, 0.0, 0.0, 0.00390625, 0.0], 'random_better-accuracy_score-num_gurus-3': [0.9384602729011985, 0.0, 0.0, 0.16623757127672434, 0.00146484375], 'random_better-accuracy_score-num_gurus-5': [0.8853572221363292, 0.0029537013033404946, 0.0, 0.8913204297423363, 0.36206442303955555], 'random_better-accuracy_score-num_gurus-7': [0.7771894195500542, 0.0, 0.0, 0.9683800898492336, 0.34843905083835125], 'random_better-accuracy_score-num_gurus-9': [0.0, 0.0, 0.0, 0.979063093662262, 0.31328280083835125], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.984375, 0.20091610867530107], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9375411552541396, 0.0, 0.05087652429938316, 0.0, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9347838023129631, 0.00244140625, 0.3678861796855927, 0.37190755270421505, 0.0], 'probabilistic_better-accuracy_score-num_gurus-5': [0.7662011630394879, 0.16114882193505764, 0.0, 0.969267874956131, 0.16079954151064157], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9114286093150868, 0.0, 0.0, 0.8119081445038319, 0.11483909981325269], 'probabilistic_better-accuracy_score-num_gurus-9': [0.024315463105107054, 0.0, 0.0, 0.98486328125, 0.13980344776064157], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9781161211431026, 0.24782211147248745], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9375411552541396, 0.0, 0.018229166666666668, 0.0, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9375411552541396, 0.0, 0.0036458333333333334, 0.14237097557634115, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9366220376070808, 0.00048828125, 0.0, 0.4180871210992336, 0.39403521828353405], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9352433611364925, 0.0, 0.0, 0.6164032891392708, 0.5030459463596344], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.004136029411764706, 0.0009765625, 0.0, 0.9523259960114956, 0.6378425732254982], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.980039656162262, 0.24634176678955555], 'max_diversity-accuracy_score-num_gurus-1': [0.9352433611364925, 0.0, 0.567581299940745, 0.01123046875, 0.0], 'max_diversity-accuracy_score-num_gurus-3': [0.9416771846659043, 0.0, 0.7865472555160522, 0.4400893710553646, 0.01123046875], 'max_diversity-accuracy_score-num_gurus-5': [0.935702919960022, 0.00146484375, 0.0, 0.534638375043869, 0.053757440531626344], 'max_diversity-accuracy_score-num_gurus-7': [0.7207459947642159, 0.0, 0.0, 0.9766512773931026, 0.24484592024236917], 'max_diversity-accuracy_score-num_gurus-9': [0.806395411491394, 0.0, 0.0, 0.9523259960114956, 0.44563802145421505], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9727746210992336, 0.39143880270421505], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.9662930928170681]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 95.01it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 19.5068\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 87.64it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 20.3304\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 77.71it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 16.1181\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 81.23it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.8608\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 92.98it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1128\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9667\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 13.0798\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1917\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 87.68it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.2283\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 93.24it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 10.4164\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 92.25it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.7935\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 88.26it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 16.0995\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 72.36it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0759\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9723\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.2991\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1928\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 90.17it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.6490\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 77.33it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.7314\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 90.75it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 12.0055\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 87.22it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.1108\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 82.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [1:35:28<1:05:46, 986.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1189\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9617\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.3191\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1907\n",
      "Starting trial  6\n",
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 64.55it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0721\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9871\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 63.16it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0785\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9876\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 51.64it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0663\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9871\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:03<00:00, 27.89it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0560\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8942\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:03<00:00, 26.87it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9613\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8683\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:02<00:00, 43.85it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0197\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8710\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 52.90it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4428\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8436\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:02<00:00, 43.80it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3763\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7794\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 46.91it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2366\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8118\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 56.12it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7121\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8555\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 42.64it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4528\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7759\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 51.44it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5287\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7843\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 55.23it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3938\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7657\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 38.18it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6267\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7764\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 50.79it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9847\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7500\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9963699494949495, 0.8417157204527604, 0.7169723348184065, 0.7728678385416666, 0.5505712365591398], 'random_better-accuracy_score-num_gurus-1': [0.9965277777777778, 0.6152974956913998, 0.783821777863936, 0.816650390625, 0.713485663296074], 'random_better-accuracy_score-num_gurus-3': [0.9969223484848485, 0.5528595334605166, 0.7317976301366632, 0.8121744791666666, 0.6094590053763441], 'random_better-accuracy_score-num_gurus-5': [0.9964488636363636, 0.7151532204527604, 0.779206698591059, 0.8681640625, 0.6708389334781195], 'random_better-accuracy_score-num_gurus-7': [0.9963699494949495, 0.6880150625580236, 0.8093025792728771, 0.834228515625, 0.7121695786394099], 'random_better-accuracy_score-num_gurus-9': [0.9955808080808081, 0.7583896009545578, 0.7963409315456044, 0.8357747395833334, 0.7270665322580645], 'random_better-accuracy_score-num_gurus-11': [0.9956597222222222, 0.7464234188983315, 0.7981158007274974, 0.8240559895833334, 0.7691532258064516], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9961332070707071, 0.7827317062177156, 0.7590372223745693, 0.6194661458333334, 0.8419018817204301], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9961332070707071, 0.5741170362422341, 0.7842670679092407, 0.83935546875, 0.6736951162738185], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9962121212121212, 0.7490146009545577, 0.8081477609547701, 0.8446451822916666, 0.805695564516129], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9964488636363636, 0.8157086799019262, 0.7978501645001498, 0.827880859375, 0.7729334677419355], 'probabilistic_better-accuracy_score-num_gurus-9': [0.9957386363636364, 0.8250014430598209, 0.7974062724546953, 0.8599446614583334, 0.6863239247311828], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9961332070707071, 0.8015639430598209, 0.7898594086820429, 0.8504231770833334, 0.7280745967741935], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9950284090909091, 0.562850588873813, 0.6089304089546204, 0.8274739583333334, 0.7623487903225806], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9960542929292929, 0.7736034167440314, 0.8178253065456044, 0.8838704427083334, 0.7740255376344086], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9936868686868687, 0.7728012467685499, 0.8235064257274974, 0.8507486979166666, 0.7020329301075269], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9962910353535354, 0.7923736151896025, 0.7914574200456793, 0.782470703125, 0.7620967741935484], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9962910353535354, 0.7988501272703472, 0.7975838292728771, 0.8605143229166666, 0.6696908602150538], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.9956597222222222, 0.8128924281973587, 0.770328857681968, 0.7782389322916666, 0.6749831989247311], 'max_diversity-accuracy_score-num_gurus-1': [0.9964488636363636, 0.6290108492499904, 0.743073886091059, 0.8318684895833334, 0.6569500450165041], 'max_diversity-accuracy_score-num_gurus-3': [0.9962910353535354, 0.6482340718570508, 0.6554468003186312, 0.7925618489583334, 0.6997647849462365], 'max_diversity-accuracy_score-num_gurus-5': [0.9961332070707071, 0.6143322944641113, 0.757633545181968, 0.7903645833333334, 0.6327004926179045], 'max_diversity-accuracy_score-num_gurus-7': [0.9969223484848485, 0.6117613114808735, 0.7221221815456044, 0.7720788040508827, 0.6455813172043011], 'max_diversity-accuracy_score-num_gurus-9': [0.9961332070707071, 0.6402354572948656, 0.7044538801366632, 0.8048502604166666, 0.6471494173490873], 'max_diversity-accuracy_score-num_gurus-11': [0.9964488636363636, 0.6564361151896025, 0.7416527325456793, 0.836181640625, 0.6549059139784946], 'single_Net': [0.9978693181818182, 0.8819497346878051, 0.8352265737273477, 0.8677571614583334, 0.8130040322580645]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d69cd00>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d12b310>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d1d1ab0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d12b310>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d1d1ab0>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.0048828125, 0.9613482765853405], 'random_better-accuracy_score-num_gurus-1': [0.9407169117647058, 0.0, 0.0055005080997943875, 0.00048828125, 0.0], 'random_better-accuracy_score-num_gurus-3': [0.9384191176470589, 0.0010005763033404946, 0.15321392317612967, 0.00390625, 0.12321738619357347], 'random_better-accuracy_score-num_gurus-5': [0.8021702135310453, 0.0, 0.0, 0.9546786211431026, 0.27623542957007885], 'random_better-accuracy_score-num_gurus-7': [0.3342364465489107, 0.0, 0.0, 0.9717684648931026, 0.463402159512043], 'random_better-accuracy_score-num_gurus-9': [0.0009191176470588235, 0.0, 0.0, 0.9834872148931026, 0.19360739178955555], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9820223711431026, 0.20875961147248745], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9370404411764706, 0.0, 0.5345401426156362, 0.0, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9342830882352942, 0.0, 0.7594258149464925, 0.0078125, 0.0], 'probabilistic_better-accuracy_score-num_gurus-5': [0.7998724194133983, 0.0, 0.03495934953292211, 0.9483309648931026, 0.4907304085791111], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9141448105082792, 0.0, 0.0, 0.8767607733607292, 0.42076667957007885], 'probabilistic_better-accuracy_score-num_gurus-9': [0.4896976509514977, 0.0, 0.0, 0.9722567461431026, 0.25618489645421505], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9688683710992336, 0.6296037957072258], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9384191176470589, 0.0, 0.0020833333333333333, 0.0, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9229175799033221, 0.008372822776436806, 0.38434959252675377, 0.7457386367022991, 0.045441158348694444], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9003991975503809, 0.0, 0.0, 0.8534120507538319, 0.5044022835791111], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.7901805323712966, 0.0, 0.0, 0.9649325273931026, 0.6031746044754982], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.0, 0.0, 0.0, 0.9396010898053646, 0.6842912957072258], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9795809648931026, 0.23563058115541935], 'max_diversity-accuracy_score-num_gurus-1': [0.9613970588235294, 0.0029537013033404946, 0.6779852628707885, 0.0, 0.003921751049347222], 'max_diversity-accuracy_score-num_gurus-3': [0.9384191176470589, 0.15328829362988472, 0.2377794712781906, 0.16281960252672434, 0.31427486427128315], 'max_diversity-accuracy_score-num_gurus-5': [0.6437390271355125, 0.19347143918275833, 0.0, 0.9732333086431026, 0.30502852238714695], 'max_diversity-accuracy_score-num_gurus-7': [0.5331911216763889, 0.0, 0.0005208333333333333, 0.7797999531030655, 0.811368428170681], 'max_diversity-accuracy_score-num_gurus-9': [0.12057588906849132, 0.0, 0.0, 0.9518081210553646, 0.483909972012043], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9478426836431026, 0.7468843013048172], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.9779653400182724]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 84.89it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 23.9023\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 88.21it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 22.2289\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 91.41it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 17.1408\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 71.35it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 7.0924\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 93.25it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0920\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9718\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 14.2334\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1927\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 87.10it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 15.3828\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 89.78it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 15.0716\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 87.13it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 18.2534\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 91.98it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 17.6104\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 72.15it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0908\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9718\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 13.2672\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1927\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 92.44it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.7703\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 82.93it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 13.0121\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 91.76it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.9700\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 89.83it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.2702\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 91.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [1:52:40<50:03, 1001.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0845\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9677\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.2181\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1919\n",
      "Starting trial  7\n",
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 55.79it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0747\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9873\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 55.23it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0770\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9866\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:02<00:00, 46.34it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0792\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9874\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 56.60it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0857\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8543\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 56.82it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9946\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8676\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 52.99it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1112\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8561\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 57.02it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7277\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7969\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 49.25it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1873\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8048\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 54.10it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2411\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8187\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 58.64it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5783\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8174\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 42.87it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5936\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7514\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 53.99it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2003\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8664\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 58.82it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9797\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7785\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 40.83it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4822\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7646\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 53.40it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8199\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7769\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9960542929292929, 0.8392067752386394, 0.7346392382274974, 0.7491048177083334, 0.6197636646609153], 'random_better-accuracy_score-num_gurus-1': [0.9955808080808081, 0.6341903278702183, 0.7024077820506963, 0.69287109375, 0.7218581989247311], 'random_better-accuracy_score-num_gurus-3': [0.9943181818181818, 0.6698811173439025, 0.7597642270001498, 0.8780924479166666, 0.7939908151985496], 'random_better-accuracy_score-num_gurus-5': [0.9960542929292929, 0.674404143659692, 0.7861307155002247, 0.7644856770833334, 0.6894881270265066], 'random_better-accuracy_score-num_gurus-7': [0.9962910353535354, 0.7380554594491657, 0.822175448591059, 0.87451171875, 0.7522961471670417], 'random_better-accuracy_score-num_gurus-9': [0.9954229797979798, 0.7322166436596921, 0.8193345395001498, 0.8600260416666666, 0.737707213048012], 'random_better-accuracy_score-num_gurus-11': [0.9958964646464646, 0.7415094068175868, 0.8179140849546953, 0.79638671875, 0.7038530463813454], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9951862373737373, 0.5800784857649552, 0.7573364519260146, 0.7271321614583334, 0.803147401220055], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9962121212121212, 0.7302429594491657, 0.8084140961820429, 0.8868815104166666, 0.8412858420802701], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9961332070707071, 0.7321344068175868, 0.7806264541365884, 0.8406575520833334, 0.7662690410050013], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9957386363636364, 0.739700196291271, 0.8164034540002997, 0.8658040364583334, 0.7774417560587648], 'probabilistic_better-accuracy_score-num_gurus-9': [0.9958175505050505, 0.8026113805017974, 0.8236832835457542, 0.8556315104166666, 0.7388272849462365], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9962121212121212, 0.8003909857649553, 0.8203111020001498, 0.8356119791666666, 0.7413194442308078], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9957386363636364, 0.6520357226070604, 0.6352968974546953, 0.7918294270833334, 0.7897065410050013], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9958964646464646, 0.7492396699754815, 0.804419067772952, 0.8558756510416666, 0.7782818098222056], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9962910353535354, 0.7124798015544289, 0.8073494542728771, 0.8495279947916666, 0.6573140678867218], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9956597222222222, 0.76124624892285, 0.7842663689093157, 0.761474609375, 0.7414034496071518], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9964488636363636, 0.8090258541860078, 0.7863089713183317, 0.8253580729166666, 0.7306507614351088], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.9960542929292929, 0.8188942752386394, 0.8125873804092407, 0.8572591145833334, 0.6732470880272567], 'max_diversity-accuracy_score-num_gurus-1': [0.9956597222222222, 0.502837892582542, 0.7254062836820429, 0.7374214505155882, 0.38205645161290325], 'max_diversity-accuracy_score-num_gurus-3': [0.9958175505050505, 0.5994041436596921, 0.7811584255912087, 0.7662760416666666, 0.7307347668114529], 'max_diversity-accuracy_score-num_gurus-5': [0.9962121212121212, 0.5751442752386394, 0.6672564257274974, 0.7086588541666666, 0.660198252688172], 'max_diversity-accuracy_score-num_gurus-7': [0.9958175505050505, 0.6299140120807447, 0.6773743683641608, 0.7462565104166666, 0.5034442204301075], 'max_diversity-accuracy_score-num_gurus-9': [0.9961332070707071, 0.7093548015544289, 0.720434692772952, 0.758056640625, 0.7089773743383346], 'max_diversity-accuracy_score-num_gurus-11': [0.9957386363636364, 0.6597876272703472, 0.6684091470458291, 0.7974446614583334, 0.6602542560587648], 'single_Net': [0.9970012626262627, 0.8739107226070605, 0.8346939032728021, 0.8473307291666666, 0.6832717291770443]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d69d9f0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d1283a0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d129090>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d69dd80>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d129090>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.0, 0.9506370909512043], 'random_better-accuracy_score-num_gurus-1': [0.938000714077669, 0.0, 0.33653455376625063, 0.0, 0.0], 'random_better-accuracy_score-num_gurus-3': [0.9375411552541396, 0.0029296875, 0.0005208333333333333, 0.490263968706131, 0.006851438549347222], 'random_better-accuracy_score-num_gurus-5': [0.9370815964306102, 0.0, 0.0, 0.29665305465459824, 0.36606367863714695], 'random_better-accuracy_score-num_gurus-7': [0.7504938525312087, 0.0, 0.0, 0.971738874912262, 0.35440693236887455], 'random_better-accuracy_score-num_gurus-9': [0.17413849865688996, 0.0, 0.0, 0.977568656206131, 0.46675812266767025], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.98583984375, 0.23852926678955555], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9384602729011985, 0.0, 0.3662220537662506, 0.0, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.935702919960022, 0.053782979026436806, 0.6514227628707886, 0.30745442770421505, 0.00830078125], 'probabilistic_better-accuracy_score-num_gurus-5': [0.83760425974341, 0.49765465036034584, 0.0, 0.9293471835553646, 0.21507626492530107], 'probabilistic_better-accuracy_score-num_gurus-7': [0.7123916254324072, 0.09652759972959757, 0.0, 0.960508406162262, 0.6182958222925663], 'probabilistic_better-accuracy_score-num_gurus-9': [0.08807067594983999, 0.0, 0.0, 0.980498343706131, 0.28647383488714695], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.6187263242900372, 0.9110553078353405], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.938000714077669, 0.0, 0.42705792586008706, 0.0009765625, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.935702919960022, 0.0, 0.7077997962633769, 0.5583570078015327, 0.043976314598694444], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.938000714077669, 0.0, 0.0, 0.21204723045229912, 0.04988219263032079], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.7825395079220042, 0.0, 0.0, 0.9195815585553646, 0.7038845494389534], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.6364340992534862, 0.0, 0.0, 0.9219933710992336, 0.6275731660425663], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.984404593706131, 0.21261935774236917], 'max_diversity-accuracy_score-num_gurus-1': [0.9963646846659043, 0.0, 0.0, 0.472197562456131, 0.0], 'max_diversity-accuracy_score-num_gurus-3': [0.9361624787835514, 0.08464075298979878, 0.7001143296559652, 0.22542317770421505, 0.43048580177128315], 'max_diversity-accuracy_score-num_gurus-5': [0.9352845163906321, 0.00048828125, 0.0, 0.23768939450383186, 0.42081318236887455], 'max_diversity-accuracy_score-num_gurus-7': [0.704702591194826, 0.7836033552885056, 0.0, 0.8966619335114956, 0.009796627098694444], 'max_diversity-accuracy_score-num_gurus-9': [0.3253813648925108, 0.0, 0.0, 0.9097863398492336, 0.8646530881524086], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.8762133046984673, 0.8455326147377491], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.9696955606341362]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 89.74it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 19.2502\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 93.81it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 20.5686\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 72.48it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 16.5114\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 95.57it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.3960\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 51.63it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1068\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9667\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 13.0544\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1917\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 45.96it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 10.2294\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 40.65it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.2655\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 47.50it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 15.2836\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 46.83it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 14.2403\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 46.35it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0759\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9753\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.3755\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1934\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 46.30it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 12.1705\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 46.17it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.0809\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 40.85it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.8257\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 46.39it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 17.4385\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 47.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [2:07:47<32:22, 971.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0882\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9697\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.9085\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1923\n",
      "Starting trial  8\n",
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 52.75it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0716\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9868\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:03<00:00, 32.26it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0772\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9871\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:03<00:00, 25.24it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0679\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9892\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 60.49it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2584\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8701\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 58.66it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9597\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8665\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 54.69it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9721\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8755\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 58.22it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5920\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7903\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 51.00it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1571\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8357\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 55.56it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3263\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7589\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 58.90it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2168\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8761\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 46.31it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1773\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8384\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 55.35it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7082\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7304\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 52.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8706\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8028\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 36.78it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3595\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7719\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 35.19it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2350\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6645\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9960542929292929, 0.836617036242234, 0.7294034090909091, 0.7430013020833334, 0.5867775537634409], 'random_better-accuracy_score-num_gurus-1': [0.9959753787878788, 0.701584141505392, 0.7549715909090909, 0.7256000904987255, 0.6339885752688172], 'random_better-accuracy_score-num_gurus-3': [0.9961332070707071, 0.7054492730843394, 0.7529296875, 0.8234049479166666, 0.7885584677419355], 'random_better-accuracy_score-num_gurus-5': [0.9961332070707071, 0.6965474956913998, 0.7850674715909091, 0.867095505197843, 0.732442876344086], 'random_better-accuracy_score-num_gurus-7': [0.9961332070707071, 0.736288088873813, 0.8366477272727273, 0.8258463541666666, 0.7082493279569892], 'random_better-accuracy_score-num_gurus-9': [0.9960542929292929, 0.7301203257159183, 0.8243075284090909, 0.8885904947916666, 0.7785618279569892], 'random_better-accuracy_score-num_gurus-11': [0.9955018939393939, 0.7305113114808736, 0.7885298295454546, 0.82080078125, 0.7422715053763441], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9958964646464646, 0.6697584836106552, 0.7426313920454546, 0.8498641304516544, 0.7637768817204301], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9963699494949495, 0.7291753229342008, 0.7477798407728021, 0.8196614583333334, 0.7416834677419355], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9962121212121212, 0.7809224956913998, 0.7871981534090909, 0.77734375, 0.580057123655914], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9962121212121212, 0.7518106535861366, 0.8275923295454546, 0.829345703125, 0.7391633064516129], 'probabilistic_better-accuracy_score-num_gurus-9': [0.9963699494949495, 0.8052025625580236, 0.8256392045454546, 0.82666015625, 0.7405073924731183], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9963699494949495, 0.8082871650394641, 0.8138316761363636, 0.8470052083333334, 0.6680667560587648], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9962121212121212, 0.6306959836106552, 0.7691761363636364, 0.81201171875, 0.7449596774193549], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9958964646464646, 0.706066770302622, 0.7731711647727273, 0.8089192708333334, 0.8169522849462365], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9956597222222222, 0.728475588873813, 0.8100142045454546, 0.844970703125, 0.6612063172043011], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.99447601010101, 0.8042157204527604, 0.8318536931818182, 0.8473307291666666, 0.8033434139784946], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9958964646464646, 0.7935249309790762, 0.7830255681818182, 0.8489583333333334, 0.7224462365591398], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.9964488636363636, 0.7813538783474973, 0.7415660511363636, 0.7991536458333334, 0.7457157258064516], 'max_diversity-accuracy_score-num_gurus-1': [0.9962121212121212, 0.4707236842105263, 0.6839062219316309, 0.6478678385416666, 0.6809475806451613], 'max_diversity-accuracy_score-num_gurus-3': [0.9962910353535354, 0.6292157204527604, 0.7290482954545454, 0.7270790872474512, 0.7866823474566141], 'max_diversity-accuracy_score-num_gurus-5': [0.9961332070707071, 0.5409149929096825, 0.7312670566818931, 0.7683600826809803, 0.6688228044458615], 'max_diversity-accuracy_score-num_gurus-7': [0.9958175505050505, 0.5702317062177156, 0.6576697555455294, 0.7895047838489214, 0.617579524875969], 'max_diversity-accuracy_score-num_gurus-9': [0.9961332070707071, 0.5681555860920956, 0.7719282670454546, 0.778564453125, 0.6495295698924731], 'max_diversity-accuracy_score-num_gurus-11': [0.9962910353535354, 0.5650926244886298, 0.7385475852272727, 0.7740071614583334, 0.6842237903225806], 'single_Net': [0.9970801767676768, 0.8816207873193841, 0.8606178977272727, 0.8394368489583334, 0.7331989247311828]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d45f250>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d08ea10>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19c320790>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d08ea10>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19d08c370>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.027314157225191593, 0.9599144347012043], 'random_better-accuracy_score-num_gurus-1': [0.9375, 0.001953125, 0.46416412591934203, 0.007265033200383186, 0.0], 'random_better-accuracy_score-num_gurus-3': [0.9370404411764706, 0.1004098360426724, 0.5699822147687276, 0.3463985566049814, 0.009292844799347222], 'random_better-accuracy_score-num_gurus-5': [0.7096685697050655, 0.035812627989798784, 0.7016133149464925, 0.968779593706131, 0.001953125], 'random_better-accuracy_score-num_gurus-7': [0.2649665273287717, 0.0009765625, 0.0, 0.98681640625, 0.13977244589477777], 'random_better-accuracy_score-num_gurus-9': [0.3382078584502725, 0.0024654200533404946, 0.0, 0.9195223711431026, 0.7346462681889534], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.977568656206131, 0.39882502518594265], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9375, 0.0, 0.2852388213078181, 0.0, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9375, 0.12231045076623559, 0.14963160554567972, 0.516054093837738, 0.16177610401064157], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9384191176470589, 0.0, 0.0, 0.020448626950383186, 0.0048828125], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9311073317247278, 0.0, 0.0, 0.8313802070915699, 0.14221385214477777], 'probabilistic_better-accuracy_score-num_gurus-9': [0.0, 0.0, 0.0, 0.9287997148931026, 0.7639586441218853], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9892578125, 0.043015253031626344], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9384191176470589, 0.0, 0.3395325203736623, 0.0, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9393382352941176, 0.0, 0.0036458333333333334, 0.00732421875, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9292690964306102, 0.0, 0.0, 0.7451615780591965, 0.09137059794738889], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.6725677672554465, 0.00244140625, 0.0, 0.944365531206131, 0.7610134556889534], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.1768546972204657, 0.0, 0.0, 0.9108812734484673, 0.7272445447742939], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.970732718706131, 0.47850787453353405], 'max_diversity-accuracy_score-num_gurus-1': [0.9361213235294118, 0.0, 0.533689026037852, 0.0, 0.0], 'max_diversity-accuracy_score-num_gurus-3': [0.9311073317247278, 0.08217533305287361, 0.7676575183868408, 0.1910215439274907, 0.0], 'max_diversity-accuracy_score-num_gurus-5': [0.9058727516847498, 0.21293064765632153, 0.0, 0.7837653867900372, 0.07673766138032079], 'max_diversity-accuracy_score-num_gurus-7': [0.18896784501917221, 0.0974801485426724, 0.0, 0.970732718706131, 0.45407831110060215], 'max_diversity-accuracy_score-num_gurus-9': [0.45009328337276683, 0.0, 0.0, 0.9624911211431026, 0.6129402294754982], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9503432773053646, 0.6456395722925663], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.9623093381524086]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 94.98it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 21.6915\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 92.22it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 21.7238\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 86.32it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 17.5883\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 76.45it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.8648\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 89.08it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0776\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9748\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 14.0957\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1933\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 95.98it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.3162\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 91.79it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.8999\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 50.21it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 14.8595\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 45.65it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 13.1141\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 42.91it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0854\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9733\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.4336\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1930\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 45.67it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 10.6176\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 44.99it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.0344\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 46.34it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 16.3104\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 44.78it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.9885\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [2:22:17<15:39, 939.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1254\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9617\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.1598\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1907\n",
      "Starting trial  9\n",
      "Creating dataset\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 64.37it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0708\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9876\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 64.73it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0775\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9868\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 99/99 [00:01<00:00, 53.83it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0654\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9901\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 57.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2756\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8598\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:01<00:00, 56.78it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9822\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8630\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [00:02<00:00, 39.80it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9786\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8611\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 54.74it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2330\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8500\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 49.49it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6110\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8155\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 88/88 [00:01<00:00, 44.87it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2430\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7657\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 58.40it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7405\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8060\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:02<00:00, 41.97it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4887\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8208\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 96/96 [00:01<00:00, 52.70it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5460\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8380\n",
      "-- >> End of training phase << --\n",
      "Training: LwF!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 56.71it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4212\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7781\n",
      "-- >> End of training phase << --\n",
      "Training: EWC!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:02<00:00, 39.39it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5876\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7864\n",
      "-- >> End of training phase << --\n",
      "Training: SynapticIntelligence!\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 93/93 [00:01<00:00, 54.19it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3779\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7544\n",
      "-- >> End of training phase << --\n",
      "Train Experience results are: \n",
      "{'full-ensemble': [0.9955808080808081, 0.8308604572948657, 0.7241640849546953, 0.7599283854166666, 0.5761088709677419], 'random_better-accuracy_score-num_gurus-1': [0.9958964646464646, 0.7141663783474972, 0.7726377953182567, 0.7920735677083334, 0.7184699818652164], 'random_better-accuracy_score-num_gurus-3': [0.9958175505050505, 0.7697584836106551, 0.8071725964546204, 0.8111165364583334, 0.766633064516129], 'random_better-accuracy_score-num_gurus-5': [0.9959753787878788, 0.7212185483229788, 0.7986498691818931, 0.8462727864583334, 0.6764952956989247], 'random_better-accuracy_score-num_gurus-7': [0.9955808080808081, 0.7415512467685499, 0.8139197555455294, 0.898193359375, 0.7662130376344086], 'random_better-accuracy_score-num_gurus-9': [0.9960542929292929, 0.7273242730843393, 0.7816931930455294, 0.8157552083333334, 0.7251344086021505], 'random_better-accuracy_score-num_gurus-11': [0.9955018939393939, 0.7741992730843393, 0.818358676000075, 0.8453776041666666, 0.7440356182795699], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9955808080808081, 0.6083694018815693, 0.712800448591059, 0.7669553893307844, 0.45346102150537637], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9963699494949495, 0.5552444018815693, 0.771394897590984, 0.84912109375, 0.802755376344086], 'probabilistic_better-accuracy_score-num_gurus-5': [0.9962121212121212, 0.7857124309790762, 0.8102791417728771, 0.8811848958333334, 0.7566364247311828], 'probabilistic_better-accuracy_score-num_gurus-7': [0.9958175505050505, 0.815050785165084, 0.8072613748637113, 0.8452962239583334, 0.7242103494623656], 'probabilistic_better-accuracy_score-num_gurus-9': [0.9961332070707071, 0.7580606535861366, 0.848543335090984, 0.8601888020833334, 0.6971606182795699], 'probabilistic_better-accuracy_score-num_gurus-11': [0.9953440656565656, 0.7735413783474973, 0.821110107681968, 0.8006184895833334, 0.7201780913978495], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9957386363636364, 0.729709141505392, 0.776188232681968, 0.8579915364583334, 0.7778897849462365], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9962121212121212, 0.7151330220071893, 0.8020234487273477, 0.8406575520833334, 0.7165658602150538], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.9957386363636364, 0.7954784167440314, 0.8189801248637113, 0.884765625, 0.8042674731182796], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9961332070707071, 0.768771641505392, 0.801668335090984, 0.8311360677083334, 0.7191700268817204], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.9962121212121212, 0.8069295362422341, 0.7814261588183317, 0.8509114583333334, 0.7906586021505376], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.9965277777777778, 0.7952519046632867, 0.8138309771364386, 0.8545735677083334, 0.7530241935483871], 'max_diversity-accuracy_score-num_gurus-1': [0.9959753787878788, 0.561412165039464, 0.5147288272326643, 0.6461588541666666, 0.7501680107526881], 'max_diversity-accuracy_score-num_gurus-3': [0.9958964646464646, 0.6633858492499903, 0.7444733692841097, 0.7794950182239214, 0.6902161740487621], 'max_diversity-accuracy_score-num_gurus-5': [0.9957386363636364, 0.6341297325335051, 0.7190149372274225, 0.7679213372369608, 0.5739527331885471], 'max_diversity-accuracy_score-num_gurus-7': [0.9928188131313131, 0.6686071678211815, 0.7622507214546204, 0.7692057291666666, 0.6859879032258065], 'max_diversity-accuracy_score-num_gurus-9': [0.9953440656565656, 0.6948003229342009, 0.7773423520001498, 0.8232775703072548, 0.7132056451612904], 'max_diversity-accuracy_score-num_gurus-11': [0.9962121212121212, 0.6021396009545578, 0.7840874140912836, 0.8101399739583334, 0.6600302419354839], 'single_Net': [0.9976325757575758, 0.8844788783474973, 0.8079723011363636, 0.8467610677083334, 0.7613407258064516]}\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19cff76d0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19cff5750>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19cff76d0>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19cff5750>\n",
      "<avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCExperience object at 0x19cff76d0>\n",
      "Test Experience results are: \n",
      "{'full-ensemble': [0.0, 0.0, 0.0, 0.0, 0.9579768106341362], 'random_better-accuracy_score-num_gurus-1': [0.951327919960022, 0.0, 0.6676321148872375, 0.0, 0.0029296875], 'random_better-accuracy_score-num_gurus-3': [0.9366220376070808, 0.21441950555890799, 0.0005208333333333333, 0.17447916697710752, 0.09381200419738889], 'random_better-accuracy_score-num_gurus-5': [0.9196595163906321, 0.3047195188701153, 0.0, 0.8286280781030655, 0.19250682089477777], 'random_better-accuracy_score-num_gurus-7': [0.7029055076486924, 0.0, 0.0005208333333333333, 0.9551964960992336, 0.6783544160425663], 'random_better-accuracy_score-num_gurus-9': [0.8145851633127998, 0.0, 0.0, 0.5902432538568974, 0.9149615578353405], 'random_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.981992781162262, 0.20472935307770967], 'probabilistic_better-accuracy_score-num_gurus-1': [0.9375411552541396, 0.0, 0.28865599632263184, 0.23401988670229912, 0.0], 'probabilistic_better-accuracy_score-num_gurus-3': [0.9375411552541396, 0.0, 0.0, 0.00341796875, 0.0], 'probabilistic_better-accuracy_score-num_gurus-5': [0.8103668233927559, 0.0, 0.008104674766461055, 0.948789656162262, 0.46474299393594265], 'probabilistic_better-accuracy_score-num_gurus-7': [0.8305462563739103, 0.01220703125, 0.0, 0.9532137773931026, 0.44232855923473835], 'probabilistic_better-accuracy_score-num_gurus-9': [0.7487379277453703, 0.0, 0.0, 0.9576379023492336, 0.49162946455180645], 'probabilistic_better-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.979551374912262, 0.31911117397248745], 'probabilistic_weighted-accuracy_score-num_gurus-1': [0.9370815964306102, 0.0, 0.20311229626337687, 0.0, 0.0], 'probabilistic_weighted-accuracy_score-num_gurus-3': [0.9357440752141616, 0.0, 0.19357215464115143, 0.2941080732271075, 0.00341796875], 'probabilistic_weighted-accuracy_score-num_gurus-5': [0.7466527644325706, 0.2315813908353448, 0.0010416666666666667, 0.8421223945915699, 0.46923053078353405], 'probabilistic_weighted-accuracy_score-num_gurus-7': [0.9352433611364925, 0.0, 0.0, 0.619081437587738, 0.04640221979934722], 'probabilistic_weighted-accuracy_score-num_gurus-9': [0.24178281426429749, 0.0, 0.0, 0.984922468662262, 0.17201450932770967], 'probabilistic_weighted-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9015743359923363, 0.8171657994389534], 'max_diversity-accuracy_score-num_gurus-1': [0.9375411552541396, 0.0, 0.03785569096604983, 0.0, 0.0], 'max_diversity-accuracy_score-num_gurus-3': [0.9375411552541396, 0.0, 0.0036458333333333334, 0.001953125, 0.0009765625], 'max_diversity-accuracy_score-num_gurus-5': [0.9375411552541396, 0.0, 0.0, 0.4075816757977009, 0.11189391138032079], 'max_diversity-accuracy_score-num_gurus-7': [0.9123065752141616, 0.08464075298979878, 0.0005208333333333333, 0.7875828593969345, 0.560570128262043], 'max_diversity-accuracy_score-num_gurus-9': [0.09943618318613838, 0.0, 0.0, 0.9557439647614956, 0.748713418841362], 'max_diversity-accuracy_score-num_gurus-11': [0.0, 0.0, 0.0, 0.9756747148931026, 0.39336092583835125], 'single_Net': [0.0, 0.0, 0.0, 0.0, 0.9643244668841362]}\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 93.50it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 14.3623\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 89.90it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 14.9577\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 90.73it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 16.9495\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 75.10it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 6.4770\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 96.67it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0779\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9753\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.5701\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1934\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 51.06it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.3411\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 93.36it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.6081\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 96.62it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 15.2734\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 86.16it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 13.3593\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 86.14it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0781\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9753\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.2999\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1934\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:00<00:00, 88.02it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 12.5508\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 70.13it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.0505\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 92.92it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 16.1797\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 84.64it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 18.0779\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 92.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [2:37:57<00:00, 947.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0717\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9758\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 11.5476\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train ensembles - single guru\n",
    "\n",
    "# data = SplitMNIST(n_experiences=5, fixed_class_order=list(range(10)))\n",
    "\n",
    "\n",
    "ensembles_dict = get_ensembles_dict()\n",
    "\n",
    "exp = Experiment(\n",
    "    n_trials=num_trials,\n",
    "    ensembles=list(ensembles_dict.values()),\n",
    "    # benchmark=data,\n",
    "    strategies_to_evaluate=initialize_strategies_to_evaluate,\n",
    "    dataset_name=\"SplitMNIST\",\n",
    ")\n",
    "_ = exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensemble</th>\n",
       "      <th>avg_test_acc</th>\n",
       "      <th>context_1_test_acc</th>\n",
       "      <th>context_2_test_acc</th>\n",
       "      <th>context_3_test_acc</th>\n",
       "      <th>context_4_test_acc</th>\n",
       "      <th>context_5_test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-7</td>\n",
       "      <td>$42.69 \\pm 4.66$</td>\n",
       "      <td>$62.99 \\pm 21.32$</td>\n",
       "      <td>$9.76 \\pm 23.14$</td>\n",
       "      <td>$0.01 \\pm 0.02$</td>\n",
       "      <td>$89.83 \\pm 8.79$</td>\n",
       "      <td>$50.84 \\pm 25.25$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-7</td>\n",
       "      <td>$41.97 \\pm 6.85$</td>\n",
       "      <td>$76.25 \\pm 26.43$</td>\n",
       "      <td>$2.29 \\pm 6.75$</td>\n",
       "      <td>$0.03 \\pm 0.08$</td>\n",
       "      <td>$80.33 \\pm 17.92$</td>\n",
       "      <td>$50.96 \\pm 22.67$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-5</td>\n",
       "      <td>$41.64 \\pm 7.27$</td>\n",
       "      <td>$88.42 \\pm 7.03$</td>\n",
       "      <td>$10.73 \\pm 20.72$</td>\n",
       "      <td>$7.15 \\pm 21.01$</td>\n",
       "      <td>$72.74 \\pm 24.01$</td>\n",
       "      <td>$29.14 \\pm 18.87$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-7</td>\n",
       "      <td>$40.52 \\pm 3.50$</td>\n",
       "      <td>$82.38 \\pm 9.12$</td>\n",
       "      <td>$4.03 \\pm 8.91$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$91.53 \\pm 6.07$</td>\n",
       "      <td>$24.66 \\pm 17.29$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-5</td>\n",
       "      <td>$39.34 \\pm 9.29$</td>\n",
       "      <td>$83.54 \\pm 7.96$</td>\n",
       "      <td>$6.59 \\pm 15.17$</td>\n",
       "      <td>$6.54 \\pm 10.62$</td>\n",
       "      <td>$78.04 \\pm 32.37$</td>\n",
       "      <td>$21.98 \\pm 17.65$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-5</td>\n",
       "      <td>$38.25 \\pm 6.71$</td>\n",
       "      <td>$86.09 \\pm 12.29$</td>\n",
       "      <td>$7.80 \\pm 10.06$</td>\n",
       "      <td>$0.31 \\pm 0.83$</td>\n",
       "      <td>$70.00 \\pm 23.22$</td>\n",
       "      <td>$27.06 \\pm 21.98$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-7</td>\n",
       "      <td>$36.75 \\pm 6.85$</td>\n",
       "      <td>$46.41 \\pm 25.04$</td>\n",
       "      <td>$2.03 \\pm 5.33$</td>\n",
       "      <td>$0.01 \\pm 0.02$</td>\n",
       "      <td>$96.07 \\pm 4.12$</td>\n",
       "      <td>$39.23 \\pm 23.33$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-9</td>\n",
       "      <td>$36.26 \\pm 4.71$</td>\n",
       "      <td>$26.79 \\pm 25.35$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$92.90 \\pm 8.02$</td>\n",
       "      <td>$61.59 \\pm 17.01$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-5</td>\n",
       "      <td>$35.56 \\pm 7.63$</td>\n",
       "      <td>$89.30 \\pm 7.27$</td>\n",
       "      <td>$2.54 \\pm 6.88$</td>\n",
       "      <td>$0.01 \\pm 0.03$</td>\n",
       "      <td>$59.96 \\pm 31.14$</td>\n",
       "      <td>$25.98 \\pm 18.35$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-3</td>\n",
       "      <td>$35.08 \\pm 8.63$</td>\n",
       "      <td>$94.36 \\pm 2.41$</td>\n",
       "      <td>$4.62 \\pm 5.33$</td>\n",
       "      <td>$42.93 \\pm 30.92$</td>\n",
       "      <td>$19.69 \\pm 12.34$</td>\n",
       "      <td>$13.78 \\pm 18.99$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-9</td>\n",
       "      <td>$31.80 \\pm 6.41$</td>\n",
       "      <td>$20.69 \\pm 26.99$</td>\n",
       "      <td>$2.19 \\pm 6.58$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$96.56 \\pm 2.21$</td>\n",
       "      <td>$39.55 \\pm 21.91$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-9</td>\n",
       "      <td>$31.20 \\pm 6.85$</td>\n",
       "      <td>$13.91 \\pm 24.85$</td>\n",
       "      <td>$0.02 \\pm 0.07$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$93.05 \\pm 11.50$</td>\n",
       "      <td>$49.01 \\pm 21.70$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-3</td>\n",
       "      <td>$30.97 \\pm 8.74$</td>\n",
       "      <td>$93.58 \\pm 0.38$</td>\n",
       "      <td>$8.36 \\pm 9.03$</td>\n",
       "      <td>$15.59 \\pm 20.51$</td>\n",
       "      <td>$30.81 \\pm 24.02$</td>\n",
       "      <td>$6.52 \\pm 8.16$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-3</td>\n",
       "      <td>$30.38 \\pm 7.77$</td>\n",
       "      <td>$93.68 \\pm 0.14$</td>\n",
       "      <td>$2.64 \\pm 4.25$</td>\n",
       "      <td>$26.60 \\pm 26.89$</td>\n",
       "      <td>$24.71 \\pm 22.54$</td>\n",
       "      <td>$4.26 \\pm 7.20$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-9</td>\n",
       "      <td>$30.36 \\pm 6.02$</td>\n",
       "      <td>$11.17 \\pm 19.29$</td>\n",
       "      <td>$0.02 \\pm 0.04$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$95.99 \\pm 2.64$</td>\n",
       "      <td>$44.62 \\pm 22.05$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-1</td>\n",
       "      <td>$30.24 \\pm 6.83$</td>\n",
       "      <td>$94.88 \\pm 2.83$</td>\n",
       "      <td>$0.03 \\pm 0.09$</td>\n",
       "      <td>$43.80 \\pm 31.96$</td>\n",
       "      <td>$8.00 \\pm 14.15$</td>\n",
       "      <td>$4.50 \\pm 13.36$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-11</td>\n",
       "      <td>$30.12 \\pm 2.86$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$91.16 \\pm 13.45$</td>\n",
       "      <td>$59.45 \\pm 19.43$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-3</td>\n",
       "      <td>$29.23 \\pm 8.59$</td>\n",
       "      <td>$93.57 \\pm 0.45$</td>\n",
       "      <td>$0.38 \\pm 0.48$</td>\n",
       "      <td>$23.78 \\pm 27.02$</td>\n",
       "      <td>$26.37 \\pm 23.48$</td>\n",
       "      <td>$2.04 \\pm 3.03$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-11</td>\n",
       "      <td>$27.79 \\pm 3.62$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$93.86 \\pm 10.71$</td>\n",
       "      <td>$45.07 \\pm 23.94$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_guru...</td>\n",
       "      <td>$27.22 \\pm 4.32$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$96.88 \\pm 2.43$</td>\n",
       "      <td>$39.21 \\pm 23.63$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-11</td>\n",
       "      <td>$25.82 \\pm 2.34$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$97.92 \\pm 0.66$</td>\n",
       "      <td>$31.19 \\pm 12.31$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-1</td>\n",
       "      <td>$25.74 \\pm 5.84$</td>\n",
       "      <td>$93.63 \\pm 1.95$</td>\n",
       "      <td>$0.02 \\pm 0.06$</td>\n",
       "      <td>$30.82 \\pm 28.34$</td>\n",
       "      <td>$4.19 \\pm 10.32$</td>\n",
       "      <td>$0.03 \\pm 0.09$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-1</td>\n",
       "      <td>$24.00 \\pm 3.50$</td>\n",
       "      <td>$93.75 \\pm 0.05$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$23.78 \\pm 15.37$</td>\n",
       "      <td>$2.48 \\pm 6.98$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-1</td>\n",
       "      <td>$22.00 \\pm 2.62$</td>\n",
       "      <td>$93.80 \\pm 0.06$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$15.41 \\pm 13.30$</td>\n",
       "      <td>$0.77 \\pm 2.09$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EWC</td>\n",
       "      <td>$19.46 \\pm 0.04$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$97.28 \\pm 0.21$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LwF</td>\n",
       "      <td>$19.43 \\pm 0.07$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$97.14 \\pm 0.34$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>single_Net</td>\n",
       "      <td>$19.41 \\pm 0.09$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$97.05 \\pm 0.46$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SynapticIntelligence</td>\n",
       "      <td>$19.37 \\pm 0.10$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$96.85 \\pm 0.50$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full-ensemble</td>\n",
       "      <td>$19.25 \\pm 0.19$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.00 \\pm 0.00$</td>\n",
       "      <td>$0.44 \\pm 0.78$</td>\n",
       "      <td>$95.79 \\pm 0.36$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ensemble      avg_test_acc  \\\n",
       "22           max_diversity-accuracy_score-num_gurus-7  $42.69 \\pm 4.66$   \n",
       "16  probabilistic_weighted-accuracy_score-num_gurus-7  $41.97 \\pm 6.85$   \n",
       "3            random_better-accuracy_score-num_gurus-5  $41.64 \\pm 7.27$   \n",
       "10    probabilistic_better-accuracy_score-num_gurus-7  $40.52 \\pm 3.50$   \n",
       "9     probabilistic_better-accuracy_score-num_gurus-5  $39.34 \\pm 9.29$   \n",
       "21           max_diversity-accuracy_score-num_gurus-5  $38.25 \\pm 6.71$   \n",
       "4            random_better-accuracy_score-num_gurus-7  $36.75 \\pm 6.85$   \n",
       "23           max_diversity-accuracy_score-num_gurus-9  $36.26 \\pm 4.71$   \n",
       "15  probabilistic_weighted-accuracy_score-num_gurus-5  $35.56 \\pm 7.63$   \n",
       "20           max_diversity-accuracy_score-num_gurus-3  $35.08 \\pm 8.63$   \n",
       "11    probabilistic_better-accuracy_score-num_gurus-9  $31.80 \\pm 6.41$   \n",
       "5            random_better-accuracy_score-num_gurus-9  $31.20 \\pm 6.85$   \n",
       "2            random_better-accuracy_score-num_gurus-3  $30.97 \\pm 8.74$   \n",
       "8     probabilistic_better-accuracy_score-num_gurus-3  $30.38 \\pm 7.77$   \n",
       "17  probabilistic_weighted-accuracy_score-num_gurus-9  $30.36 \\pm 6.02$   \n",
       "19           max_diversity-accuracy_score-num_gurus-1  $30.24 \\pm 6.83$   \n",
       "24          max_diversity-accuracy_score-num_gurus-11  $30.12 \\pm 2.86$   \n",
       "14  probabilistic_weighted-accuracy_score-num_gurus-3  $29.23 \\pm 8.59$   \n",
       "12   probabilistic_better-accuracy_score-num_gurus-11  $27.79 \\pm 3.62$   \n",
       "18  probabilistic_weighted-accuracy_score-num_guru...  $27.22 \\pm 4.32$   \n",
       "6           random_better-accuracy_score-num_gurus-11  $25.82 \\pm 2.34$   \n",
       "1            random_better-accuracy_score-num_gurus-1  $25.74 \\pm 5.84$   \n",
       "7     probabilistic_better-accuracy_score-num_gurus-1  $24.00 \\pm 3.50$   \n",
       "13  probabilistic_weighted-accuracy_score-num_gurus-1  $22.00 \\pm 2.62$   \n",
       "27                                                EWC  $19.46 \\pm 0.04$   \n",
       "26                                                LwF  $19.43 \\pm 0.07$   \n",
       "25                                         single_Net  $19.41 \\pm 0.09$   \n",
       "28                               SynapticIntelligence  $19.37 \\pm 0.10$   \n",
       "0                                       full-ensemble  $19.25 \\pm 0.19$   \n",
       "\n",
       "   context_1_test_acc context_2_test_acc context_3_test_acc  \\\n",
       "22  $62.99 \\pm 21.32$   $9.76 \\pm 23.14$    $0.01 \\pm 0.02$   \n",
       "16  $76.25 \\pm 26.43$    $2.29 \\pm 6.75$    $0.03 \\pm 0.08$   \n",
       "3    $88.42 \\pm 7.03$  $10.73 \\pm 20.72$   $7.15 \\pm 21.01$   \n",
       "10   $82.38 \\pm 9.12$    $4.03 \\pm 8.91$    $0.00 \\pm 0.00$   \n",
       "9    $83.54 \\pm 7.96$   $6.59 \\pm 15.17$   $6.54 \\pm 10.62$   \n",
       "21  $86.09 \\pm 12.29$   $7.80 \\pm 10.06$    $0.31 \\pm 0.83$   \n",
       "4   $46.41 \\pm 25.04$    $2.03 \\pm 5.33$    $0.01 \\pm 0.02$   \n",
       "23  $26.79 \\pm 25.35$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "15   $89.30 \\pm 7.27$    $2.54 \\pm 6.88$    $0.01 \\pm 0.03$   \n",
       "20   $94.36 \\pm 2.41$    $4.62 \\pm 5.33$  $42.93 \\pm 30.92$   \n",
       "11  $20.69 \\pm 26.99$    $2.19 \\pm 6.58$    $0.00 \\pm 0.00$   \n",
       "5   $13.91 \\pm 24.85$    $0.02 \\pm 0.07$    $0.00 \\pm 0.00$   \n",
       "2    $93.58 \\pm 0.38$    $8.36 \\pm 9.03$  $15.59 \\pm 20.51$   \n",
       "8    $93.68 \\pm 0.14$    $2.64 \\pm 4.25$  $26.60 \\pm 26.89$   \n",
       "17  $11.17 \\pm 19.29$    $0.02 \\pm 0.04$    $0.00 \\pm 0.00$   \n",
       "19   $94.88 \\pm 2.83$    $0.03 \\pm 0.09$  $43.80 \\pm 31.96$   \n",
       "24    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "14   $93.57 \\pm 0.45$    $0.38 \\pm 0.48$  $23.78 \\pm 27.02$   \n",
       "12    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "18    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "6     $0.00 \\pm 0.00$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "1    $93.63 \\pm 1.95$    $0.02 \\pm 0.06$  $30.82 \\pm 28.34$   \n",
       "7    $93.75 \\pm 0.05$    $0.00 \\pm 0.00$  $23.78 \\pm 15.37$   \n",
       "13   $93.80 \\pm 0.06$    $0.00 \\pm 0.00$  $15.41 \\pm 13.30$   \n",
       "27    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "26    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "25    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "28    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "0     $0.00 \\pm 0.00$    $0.00 \\pm 0.00$    $0.00 \\pm 0.00$   \n",
       "\n",
       "   context_4_test_acc context_5_test_acc  \n",
       "22   $89.83 \\pm 8.79$  $50.84 \\pm 25.25$  \n",
       "16  $80.33 \\pm 17.92$  $50.96 \\pm 22.67$  \n",
       "3   $72.74 \\pm 24.01$  $29.14 \\pm 18.87$  \n",
       "10   $91.53 \\pm 6.07$  $24.66 \\pm 17.29$  \n",
       "9   $78.04 \\pm 32.37$  $21.98 \\pm 17.65$  \n",
       "21  $70.00 \\pm 23.22$  $27.06 \\pm 21.98$  \n",
       "4    $96.07 \\pm 4.12$  $39.23 \\pm 23.33$  \n",
       "23   $92.90 \\pm 8.02$  $61.59 \\pm 17.01$  \n",
       "15  $59.96 \\pm 31.14$  $25.98 \\pm 18.35$  \n",
       "20  $19.69 \\pm 12.34$  $13.78 \\pm 18.99$  \n",
       "11   $96.56 \\pm 2.21$  $39.55 \\pm 21.91$  \n",
       "5   $93.05 \\pm 11.50$  $49.01 \\pm 21.70$  \n",
       "2   $30.81 \\pm 24.02$    $6.52 \\pm 8.16$  \n",
       "8   $24.71 \\pm 22.54$    $4.26 \\pm 7.20$  \n",
       "17   $95.99 \\pm 2.64$  $44.62 \\pm 22.05$  \n",
       "19   $8.00 \\pm 14.15$   $4.50 \\pm 13.36$  \n",
       "24  $91.16 \\pm 13.45$  $59.45 \\pm 19.43$  \n",
       "14  $26.37 \\pm 23.48$    $2.04 \\pm 3.03$  \n",
       "12  $93.86 \\pm 10.71$  $45.07 \\pm 23.94$  \n",
       "18   $96.88 \\pm 2.43$  $39.21 \\pm 23.63$  \n",
       "6    $97.92 \\pm 0.66$  $31.19 \\pm 12.31$  \n",
       "1    $4.19 \\pm 10.32$    $0.03 \\pm 0.09$  \n",
       "7     $2.48 \\pm 6.98$    $0.00 \\pm 0.00$  \n",
       "13    $0.77 \\pm 2.09$    $0.00 \\pm 0.00$  \n",
       "27    $0.00 \\pm 0.00$   $97.28 \\pm 0.21$  \n",
       "26    $0.00 \\pm 0.00$   $97.14 \\pm 0.34$  \n",
       "25    $0.00 \\pm 0.00$   $97.05 \\pm 0.46$  \n",
       "28    $0.00 \\pm 0.00$   $96.85 \\pm 0.50$  \n",
       "0     $0.44 \\pm 0.78$   $95.79 \\pm 0.36$  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_metrics = exp.batch_metric_values\n",
    "num_trials = exp.n_trials\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for ens in exp_metrics.keys():\n",
    "    num_contexts = len(exp_metrics[ens][0][\"experience_test_acc\"])\n",
    "\n",
    "    ens_values = np.zeros((num_trials, num_contexts))\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        for j in range(num_contexts):\n",
    "            # ith trial, jth context\n",
    "            ens_values[i, j] = exp_metrics[ens][i][\"experience_test_acc\"][j]\n",
    "\n",
    "    # calculate the mean for each context\n",
    "    experience_mean_values = np.mean(ens_values, axis=0)\n",
    "    experience_std_values = np.std(ens_values, axis=0)\n",
    "\n",
    "    # calculate the mean test acc for each trial\n",
    "    trial_mean_values = np.mean(ens_values, axis=1)\n",
    "\n",
    "    # calculate the mean and std of the mean test acc for each trial\n",
    "    avg_test_acc = np.mean(trial_mean_values)\n",
    "    std_test_acc = np.std(trial_mean_values)\n",
    "\n",
    "    # in our final df we want to have the following columns:\n",
    "    # ensemble_name, avg_test_acc, context_1_test_acc, context_2_test_acc, ..., context_n_test_acc\n",
    "    # we want to set up the dictionary to be able to easily convert to a pandas dataframe\n",
    "    result_dict[ens] = {\n",
    "        \"avg_test_acc\": f\"${avg_test_acc*100:.2f} \\pm {std_test_acc*100:.2f}$\"\n",
    "    }\n",
    "    for i in range(num_contexts):\n",
    "        result_dict[ens][\n",
    "            f\"context_{i+1}_test_acc\"\n",
    "        ] = f\"${experience_mean_values[i]*100:.2f} \\pm {experience_std_values[i]*100:.2f}$\"\n",
    "\n",
    "table_df = pd.DataFrame(result_dict).T\n",
    "# add the ensemble name as the first column\n",
    "table_df[\"ensemble\"] = table_df.index\n",
    "table_df = table_df.reset_index(drop=True)\n",
    "\n",
    "# move the ensemble name to the first column\n",
    "cols = table_df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "table_df = table_df[cols]\n",
    "\n",
    "\n",
    "# sort the rows based on the avg_test_acc\n",
    "table_df = table_df.sort_values(by=\"avg_test_acc\", ascending=False)\n",
    "exp_name_suffix = \"CAI-experiments-feb16\"\n",
    "\n",
    "file_prefix = f\"many_v_class_incremental-trials={num_trials}-batch_size={batch_size}-window_size={window_size}-num_voters={n_voters}-width={ensemble_width}-{exp_name_suffix}\"\n",
    "path = \"results\"\n",
    "\n",
    "filepath = f\"{path}/{file_prefix}-tabledata-test-feb16.csv\"\n",
    "table_df.to_csv(filepath, index=False)\n",
    "\n",
    "table_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensemble</th>\n",
       "      <th>avg_test_acc</th>\n",
       "      <th>context_1_test_acc</th>\n",
       "      <th>context_2_test_acc</th>\n",
       "      <th>context_3_test_acc</th>\n",
       "      <th>context_4_test_acc</th>\n",
       "      <th>context_5_test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-7</td>\n",
       "      <td>(0.42685280867182096, 0.046591724857778544)</td>\n",
       "      <td>(0.6298733818180421, 0.21322122350562783)</td>\n",
       "      <td>(0.09759781630709767, 0.2314161489931543)</td>\n",
       "      <td>(0.00010416666666666666, 0.00020833333333333332)</td>\n",
       "      <td>(0.898323567584157, 0.0878625756163807)</td>\n",
       "      <td>(0.5083651109831407, 0.2525438559963803)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-7</td>\n",
       "      <td>(0.41971254492886184, 0.0684984405783983)</td>\n",
       "      <td>(0.7625205773476731, 0.2642577162003916)</td>\n",
       "      <td>(0.022916399873793125, 0.06745186859265988)</td>\n",
       "      <td>(0.00026041666666666666, 0.0007812499999999998)</td>\n",
       "      <td>(0.8032655656337738, 0.17924192592119692)</td>\n",
       "      <td>(0.5095997651224025, 0.22668790077780585)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-5</td>\n",
       "      <td>(0.416369122616344, 0.07270632164832862)</td>\n",
       "      <td>(0.8841541377937092, 0.07025500116672306)</td>\n",
       "      <td>(0.10730660858098418, 0.20716754154190262)</td>\n",
       "      <td>(0.0715218497812748, 0.21006342393610444)</td>\n",
       "      <td>(0.7274280896410346, 0.24014412126233356)</td>\n",
       "      <td>(0.29143492728471754, 0.18872776528179425)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-7</td>\n",
       "      <td>(0.40519822597284527, 0.03499663341029803)</td>\n",
       "      <td>(0.8238380702102885, 0.09120869650725318)</td>\n",
       "      <td>(0.04027119623497129, 0.0890982365810496)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9152595292776823, 0.060655886471500255)</td>\n",
       "      <td>(0.24662233414128423, 0.17290631658093217)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-5</td>\n",
       "      <td>(0.39338250183272083, 0.09291525386720795)</td>\n",
       "      <td>(0.8354271839646732, 0.07961377260173243)</td>\n",
       "      <td>(0.06588034722954035, 0.15173229462625515)</td>\n",
       "      <td>(0.06535696138938268, 0.1062283322124734)</td>\n",
       "      <td>(0.7804036461748183, 0.3236834442629436)</td>\n",
       "      <td>(0.2198443704051897, 0.17653178596394184)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-5</td>\n",
       "      <td>(0.38251666255195754, 0.06709621439858314)</td>\n",
       "      <td>(0.8609038910445044, 0.12293389551149314)</td>\n",
       "      <td>(0.07801613711053505, 0.10058701621114396)</td>\n",
       "      <td>(0.003102134143312772, 0.008317085594861759)</td>\n",
       "      <td>(0.6999866832047701, 0.2321712285539682)</td>\n",
       "      <td>(0.27057446725666523, 0.21979014037341538)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-7</td>\n",
       "      <td>(0.36748627999654115, 0.06848024411252156)</td>\n",
       "      <td>(0.4640906215426238, 0.25044897729914994)</td>\n",
       "      <td>(0.020323706476483495, 0.05328522958404879)</td>\n",
       "      <td>(5.208333333333333e-05, 0.00015625)</td>\n",
       "      <td>(0.9606844820082188, 0.0412193774914316)</td>\n",
       "      <td>(0.3922805066220462, 0.23331669007906114)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-9</td>\n",
       "      <td>(0.362559008657494, 0.04710417207190865)</td>\n",
       "      <td>(0.26785900454749084, 0.2535398012568469)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9289994679391385, 0.08022095008609775)</td>\n",
       "      <td>(0.6159365708008409, 0.17011574919914177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-5</td>\n",
       "      <td>(0.35557163570460626, 0.07627631068242749)</td>\n",
       "      <td>(0.8929961863686054, 0.0726861622376472)</td>\n",
       "      <td>(0.02540903559420258, 0.06882217916530971)</td>\n",
       "      <td>(0.00010416666666666666, 0.0003125)</td>\n",
       "      <td>(0.5995575877837837, 0.3113734104184359)</td>\n",
       "      <td>(0.2597912021097727, 0.18353036093410768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-3</td>\n",
       "      <td>(0.3507551274254973, 0.08633530147014985)</td>\n",
       "      <td>(0.943640941030839, 0.02406090188507261)</td>\n",
       "      <td>(0.04616499096155167, 0.05331551050121002)</td>\n",
       "      <td>(0.42925304859876634, 0.3091933928367468)</td>\n",
       "      <td>(0.1968942355364561, 0.1234055671069808)</td>\n",
       "      <td>(0.13782242099987344, 0.1898954534720106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-9</td>\n",
       "      <td>(0.3179936998945606, 0.06410480543696487)</td>\n",
       "      <td>(0.2069269916754873, 0.26985852984548575)</td>\n",
       "      <td>(0.021939837373793125, 0.06581951212137938)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9656442355364561, 0.02212167998365542)</td>\n",
       "      <td>(0.3954574348870665, 0.21914497609328493)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-9</td>\n",
       "      <td>(0.31198407754480073, 0.06850448569468817)</td>\n",
       "      <td>(0.1390563269584056, 0.2484911860823094)</td>\n",
       "      <td>(0.0002465420053340495, 0.0007396260160021485)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9305249772965908, 0.11501045622429802)</td>\n",
       "      <td>(0.4900925414636731, 0.21697005194241709)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-3</td>\n",
       "      <td>(0.3097060821585029, 0.08739847307596513)</td>\n",
       "      <td>(0.9357783696230723, 0.0038072985185348992)</td>\n",
       "      <td>(0.08355772914364934, 0.09028641647843161)</td>\n",
       "      <td>(0.15591844499111174, 0.20513665776237308)</td>\n",
       "      <td>(0.3080817945301533, 0.2402202363092313)</td>\n",
       "      <td>(0.06519407250452787, 0.08158836122776415)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-3</td>\n",
       "      <td>(0.30378199776877446, 0.07773448681584284)</td>\n",
       "      <td>(0.9368312393917757, 0.0013652176106374355)</td>\n",
       "      <td>(0.026432024827226997, 0.04250340100059976)</td>\n",
       "      <td>(0.2660124491651853, 0.26891981462295605)</td>\n",
       "      <td>(0.2470584754832089, 0.22540928900570417)</td>\n",
       "      <td>(0.04257579997647554, 0.07195127229851896)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-9</td>\n",
       "      <td>(0.3035946472904042, 0.06019906080312677)</td>\n",
       "      <td>(0.11167828155791057, 0.19291360699263815)</td>\n",
       "      <td>(0.0001953125, 0.0003906250000000001)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9599121104925871, 0.026362049545553053)</td>\n",
       "      <td>(0.4461875319015235, 0.22045756844838757)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-1</td>\n",
       "      <td>(0.302425885830385, 0.06830912435217315)</td>\n",
       "      <td>(0.9487962305545807, 0.02832963857227259)</td>\n",
       "      <td>(0.00034419825533404946, 0.0008819322864430616)</td>\n",
       "      <td>(0.4380297255764405, 0.31958430196263554)</td>\n",
       "      <td>(0.07998934667557478, 0.14153139277459972)</td>\n",
       "      <td>(0.044969928089994934, 0.13360765020267526)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>max_diversity-accuracy_score-num_gurus-11</td>\n",
       "      <td>(0.30121706761419775, 0.02864143486037935)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9116122160106898, 0.13454625621309343)</td>\n",
       "      <td>(0.5944731220602989, 0.19426055458641336)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-3</td>\n",
       "      <td>(0.29228004974710264, 0.08593199658354678)</td>\n",
       "      <td>(0.9356528482016394, 0.004467383334036525)</td>\n",
       "      <td>(0.0037813780596479773, 0.004804385968090974)</td>\n",
       "      <td>(0.23779725581407546, 0.27024220813277244)</td>\n",
       "      <td>(0.26373845906928184, 0.2348348875054756)</td>\n",
       "      <td>(0.020430307590868325, 0.03032119736754442)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-11</td>\n",
       "      <td>(0.277850717199035, 0.03620068132925251)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9385978933423758, 0.1070642569780169)</td>\n",
       "      <td>(0.4506556926527992, 0.23942071595293316)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_guru...</td>\n",
       "      <td>(0.27218248348915947, 0.043187391480766356)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9687721949070692, 0.0243285860302408)</td>\n",
       "      <td>(0.39214022253872827, 0.23634509610398655)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-11</td>\n",
       "      <td>(0.2582138350233436, 0.023387537406824564)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9791977398097516, 0.006564082898159719)</td>\n",
       "      <td>(0.3118714353069663, 0.12305313738463756)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_better-accuracy_score-num_gurus-1</td>\n",
       "      <td>(0.25738622652016147, 0.05841392087268253)</td>\n",
       "      <td>(0.9363380709115197, 0.01946756032564854)</td>\n",
       "      <td>(0.000244140625, 0.0005879684852925926)</td>\n",
       "      <td>(0.30816438034176824, 0.2834463324763397)</td>\n",
       "      <td>(0.04189157197251916, 0.10315313507448345)</td>\n",
       "      <td>(0.00029296875, 0.0008789062500000001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>probabilistic_better-accuracy_score-num_gurus-1</td>\n",
       "      <td>(0.2400228485202088, 0.034975364403696356)</td>\n",
       "      <td>(0.9375205776270699, 0.0005075817820915251)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.2377756606787443, 0.15371832015348746)</td>\n",
       "      <td>(0.02481800429522991, 0.06980906180635688)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>probabilistic_weighted-accuracy_score-num_gurus-1</td>\n",
       "      <td>(0.2199687364314701, 0.026244803920402123)</td>\n",
       "      <td>(0.9380260923329521, 0.0006459352236734379)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.15411458318432172, 0.13295673083309045)</td>\n",
       "      <td>(0.007703006640076638, 0.02091159488921758)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EWC</td>\n",
       "      <td>(0.194553706505295, 0.00041584524716264455)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.972768532526475, 0.002079226235813231)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LwF</td>\n",
       "      <td>(0.19427130610186585, 0.0006896750780546093)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9713565305093292, 0.0034483753902730583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>single_Net</td>\n",
       "      <td>(0.1940950521081686, 0.0009126475953015702)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.970475260540843, 0.0045632379765078585)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SynapticIntelligence</td>\n",
       "      <td>(0.19370650529500757, 0.0010057449006408803)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.9685325264750377, 0.005028724503204411)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full-ensemble</td>\n",
       "      <td>(0.19246205078437922, 0.0018864844934801876)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>(0.004440400097519159, 0.007792972517222727)</td>\n",
       "      <td>(0.9578698538243771, 0.003631341558832962)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ensemble  \\\n",
       "22           max_diversity-accuracy_score-num_gurus-7   \n",
       "16  probabilistic_weighted-accuracy_score-num_gurus-7   \n",
       "3            random_better-accuracy_score-num_gurus-5   \n",
       "10    probabilistic_better-accuracy_score-num_gurus-7   \n",
       "9     probabilistic_better-accuracy_score-num_gurus-5   \n",
       "21           max_diversity-accuracy_score-num_gurus-5   \n",
       "4            random_better-accuracy_score-num_gurus-7   \n",
       "23           max_diversity-accuracy_score-num_gurus-9   \n",
       "15  probabilistic_weighted-accuracy_score-num_gurus-5   \n",
       "20           max_diversity-accuracy_score-num_gurus-3   \n",
       "11    probabilistic_better-accuracy_score-num_gurus-9   \n",
       "5            random_better-accuracy_score-num_gurus-9   \n",
       "2            random_better-accuracy_score-num_gurus-3   \n",
       "8     probabilistic_better-accuracy_score-num_gurus-3   \n",
       "17  probabilistic_weighted-accuracy_score-num_gurus-9   \n",
       "19           max_diversity-accuracy_score-num_gurus-1   \n",
       "24          max_diversity-accuracy_score-num_gurus-11   \n",
       "14  probabilistic_weighted-accuracy_score-num_gurus-3   \n",
       "12   probabilistic_better-accuracy_score-num_gurus-11   \n",
       "18  probabilistic_weighted-accuracy_score-num_guru...   \n",
       "6           random_better-accuracy_score-num_gurus-11   \n",
       "1            random_better-accuracy_score-num_gurus-1   \n",
       "7     probabilistic_better-accuracy_score-num_gurus-1   \n",
       "13  probabilistic_weighted-accuracy_score-num_gurus-1   \n",
       "27                                                EWC   \n",
       "26                                                LwF   \n",
       "25                                         single_Net   \n",
       "28                               SynapticIntelligence   \n",
       "0                                       full-ensemble   \n",
       "\n",
       "                                    avg_test_acc  \\\n",
       "22   (0.42685280867182096, 0.046591724857778544)   \n",
       "16     (0.41971254492886184, 0.0684984405783983)   \n",
       "3       (0.416369122616344, 0.07270632164832862)   \n",
       "10    (0.40519822597284527, 0.03499663341029803)   \n",
       "9     (0.39338250183272083, 0.09291525386720795)   \n",
       "21    (0.38251666255195754, 0.06709621439858314)   \n",
       "4     (0.36748627999654115, 0.06848024411252156)   \n",
       "23      (0.362559008657494, 0.04710417207190865)   \n",
       "15    (0.35557163570460626, 0.07627631068242749)   \n",
       "20     (0.3507551274254973, 0.08633530147014985)   \n",
       "11     (0.3179936998945606, 0.06410480543696487)   \n",
       "5     (0.31198407754480073, 0.06850448569468817)   \n",
       "2      (0.3097060821585029, 0.08739847307596513)   \n",
       "8     (0.30378199776877446, 0.07773448681584284)   \n",
       "17     (0.3035946472904042, 0.06019906080312677)   \n",
       "19      (0.302425885830385, 0.06830912435217315)   \n",
       "24    (0.30121706761419775, 0.02864143486037935)   \n",
       "14    (0.29228004974710264, 0.08593199658354678)   \n",
       "12      (0.277850717199035, 0.03620068132925251)   \n",
       "18   (0.27218248348915947, 0.043187391480766356)   \n",
       "6     (0.2582138350233436, 0.023387537406824564)   \n",
       "1     (0.25738622652016147, 0.05841392087268253)   \n",
       "7     (0.2400228485202088, 0.034975364403696356)   \n",
       "13    (0.2199687364314701, 0.026244803920402123)   \n",
       "27   (0.194553706505295, 0.00041584524716264455)   \n",
       "26  (0.19427130610186585, 0.0006896750780546093)   \n",
       "25   (0.1940950521081686, 0.0009126475953015702)   \n",
       "28  (0.19370650529500757, 0.0010057449006408803)   \n",
       "0   (0.19246205078437922, 0.0018864844934801876)   \n",
       "\n",
       "                             context_1_test_acc  \\\n",
       "22    (0.6298733818180421, 0.21322122350562783)   \n",
       "16     (0.7625205773476731, 0.2642577162003916)   \n",
       "3     (0.8841541377937092, 0.07025500116672306)   \n",
       "10    (0.8238380702102885, 0.09120869650725318)   \n",
       "9     (0.8354271839646732, 0.07961377260173243)   \n",
       "21    (0.8609038910445044, 0.12293389551149314)   \n",
       "4     (0.4640906215426238, 0.25044897729914994)   \n",
       "23    (0.26785900454749084, 0.2535398012568469)   \n",
       "15     (0.8929961863686054, 0.0726861622376472)   \n",
       "20     (0.943640941030839, 0.02406090188507261)   \n",
       "11    (0.2069269916754873, 0.26985852984548575)   \n",
       "5      (0.1390563269584056, 0.2484911860823094)   \n",
       "2   (0.9357783696230723, 0.0038072985185348992)   \n",
       "8   (0.9368312393917757, 0.0013652176106374355)   \n",
       "17   (0.11167828155791057, 0.19291360699263815)   \n",
       "19    (0.9487962305545807, 0.02832963857227259)   \n",
       "24                                   (0.0, 0.0)   \n",
       "14   (0.9356528482016394, 0.004467383334036525)   \n",
       "12                                   (0.0, 0.0)   \n",
       "18                                   (0.0, 0.0)   \n",
       "6                                    (0.0, 0.0)   \n",
       "1     (0.9363380709115197, 0.01946756032564854)   \n",
       "7   (0.9375205776270699, 0.0005075817820915251)   \n",
       "13  (0.9380260923329521, 0.0006459352236734379)   \n",
       "27                                   (0.0, 0.0)   \n",
       "26                                   (0.0, 0.0)   \n",
       "25                                   (0.0, 0.0)   \n",
       "28                                   (0.0, 0.0)   \n",
       "0                                    (0.0, 0.0)   \n",
       "\n",
       "                                 context_2_test_acc  \\\n",
       "22        (0.09759781630709767, 0.2314161489931543)   \n",
       "16      (0.022916399873793125, 0.06745186859265988)   \n",
       "3        (0.10730660858098418, 0.20716754154190262)   \n",
       "10        (0.04027119623497129, 0.0890982365810496)   \n",
       "9        (0.06588034722954035, 0.15173229462625515)   \n",
       "21       (0.07801613711053505, 0.10058701621114396)   \n",
       "4       (0.020323706476483495, 0.05328522958404879)   \n",
       "23                                       (0.0, 0.0)   \n",
       "15       (0.02540903559420258, 0.06882217916530971)   \n",
       "20       (0.04616499096155167, 0.05331551050121002)   \n",
       "11      (0.021939837373793125, 0.06581951212137938)   \n",
       "5    (0.0002465420053340495, 0.0007396260160021485)   \n",
       "2        (0.08355772914364934, 0.09028641647843161)   \n",
       "8       (0.026432024827226997, 0.04250340100059976)   \n",
       "17            (0.0001953125, 0.0003906250000000001)   \n",
       "19  (0.00034419825533404946, 0.0008819322864430616)   \n",
       "24                                       (0.0, 0.0)   \n",
       "14    (0.0037813780596479773, 0.004804385968090974)   \n",
       "12                                       (0.0, 0.0)   \n",
       "18                                       (0.0, 0.0)   \n",
       "6                                        (0.0, 0.0)   \n",
       "1           (0.000244140625, 0.0005879684852925926)   \n",
       "7                                        (0.0, 0.0)   \n",
       "13                                       (0.0, 0.0)   \n",
       "27                                       (0.0, 0.0)   \n",
       "26                                       (0.0, 0.0)   \n",
       "25                                       (0.0, 0.0)   \n",
       "28                                       (0.0, 0.0)   \n",
       "0                                        (0.0, 0.0)   \n",
       "\n",
       "                                  context_3_test_acc  \\\n",
       "22  (0.00010416666666666666, 0.00020833333333333332)   \n",
       "16   (0.00026041666666666666, 0.0007812499999999998)   \n",
       "3          (0.0715218497812748, 0.21006342393610444)   \n",
       "10                                        (0.0, 0.0)   \n",
       "9          (0.06535696138938268, 0.1062283322124734)   \n",
       "21      (0.003102134143312772, 0.008317085594861759)   \n",
       "4                (5.208333333333333e-05, 0.00015625)   \n",
       "23                                        (0.0, 0.0)   \n",
       "15               (0.00010416666666666666, 0.0003125)   \n",
       "20         (0.42925304859876634, 0.3091933928367468)   \n",
       "11                                        (0.0, 0.0)   \n",
       "5                                         (0.0, 0.0)   \n",
       "2         (0.15591844499111174, 0.20513665776237308)   \n",
       "8          (0.2660124491651853, 0.26891981462295605)   \n",
       "17                                        (0.0, 0.0)   \n",
       "19         (0.4380297255764405, 0.31958430196263554)   \n",
       "24                                        (0.0, 0.0)   \n",
       "14        (0.23779725581407546, 0.27024220813277244)   \n",
       "12                                        (0.0, 0.0)   \n",
       "18                                        (0.0, 0.0)   \n",
       "6                                         (0.0, 0.0)   \n",
       "1          (0.30816438034176824, 0.2834463324763397)   \n",
       "7          (0.2377756606787443, 0.15371832015348746)   \n",
       "13        (0.15411458318432172, 0.13295673083309045)   \n",
       "27                                        (0.0, 0.0)   \n",
       "26                                        (0.0, 0.0)   \n",
       "25                                        (0.0, 0.0)   \n",
       "28                                        (0.0, 0.0)   \n",
       "0                                         (0.0, 0.0)   \n",
       "\n",
       "                              context_4_test_acc  \\\n",
       "22       (0.898323567584157, 0.0878625756163807)   \n",
       "16     (0.8032655656337738, 0.17924192592119692)   \n",
       "3      (0.7274280896410346, 0.24014412126233356)   \n",
       "10    (0.9152595292776823, 0.060655886471500255)   \n",
       "9       (0.7804036461748183, 0.3236834442629436)   \n",
       "21      (0.6999866832047701, 0.2321712285539682)   \n",
       "4       (0.9606844820082188, 0.0412193774914316)   \n",
       "23     (0.9289994679391385, 0.08022095008609775)   \n",
       "15      (0.5995575877837837, 0.3113734104184359)   \n",
       "20      (0.1968942355364561, 0.1234055671069808)   \n",
       "11     (0.9656442355364561, 0.02212167998365542)   \n",
       "5      (0.9305249772965908, 0.11501045622429802)   \n",
       "2       (0.3080817945301533, 0.2402202363092313)   \n",
       "8      (0.2470584754832089, 0.22540928900570417)   \n",
       "17    (0.9599121104925871, 0.026362049545553053)   \n",
       "19    (0.07998934667557478, 0.14153139277459972)   \n",
       "24     (0.9116122160106898, 0.13454625621309343)   \n",
       "14     (0.26373845906928184, 0.2348348875054756)   \n",
       "12      (0.9385978933423758, 0.1070642569780169)   \n",
       "18      (0.9687721949070692, 0.0243285860302408)   \n",
       "6     (0.9791977398097516, 0.006564082898159719)   \n",
       "1     (0.04189157197251916, 0.10315313507448345)   \n",
       "7     (0.02481800429522991, 0.06980906180635688)   \n",
       "13   (0.007703006640076638, 0.02091159488921758)   \n",
       "27                                    (0.0, 0.0)   \n",
       "26                                    (0.0, 0.0)   \n",
       "25                                    (0.0, 0.0)   \n",
       "28                                    (0.0, 0.0)   \n",
       "0   (0.004440400097519159, 0.007792972517222727)   \n",
       "\n",
       "                             context_5_test_acc  \n",
       "22     (0.5083651109831407, 0.2525438559963803)  \n",
       "16    (0.5095997651224025, 0.22668790077780585)  \n",
       "3    (0.29143492728471754, 0.18872776528179425)  \n",
       "10   (0.24662233414128423, 0.17290631658093217)  \n",
       "9     (0.2198443704051897, 0.17653178596394184)  \n",
       "21   (0.27057446725666523, 0.21979014037341538)  \n",
       "4     (0.3922805066220462, 0.23331669007906114)  \n",
       "23    (0.6159365708008409, 0.17011574919914177)  \n",
       "15    (0.2597912021097727, 0.18353036093410768)  \n",
       "20    (0.13782242099987344, 0.1898954534720106)  \n",
       "11    (0.3954574348870665, 0.21914497609328493)  \n",
       "5     (0.4900925414636731, 0.21697005194241709)  \n",
       "2    (0.06519407250452787, 0.08158836122776415)  \n",
       "8    (0.04257579997647554, 0.07195127229851896)  \n",
       "17    (0.4461875319015235, 0.22045756844838757)  \n",
       "19  (0.044969928089994934, 0.13360765020267526)  \n",
       "24    (0.5944731220602989, 0.19426055458641336)  \n",
       "14  (0.020430307590868325, 0.03032119736754442)  \n",
       "12    (0.4506556926527992, 0.23942071595293316)  \n",
       "18   (0.39214022253872827, 0.23634509610398655)  \n",
       "6     (0.3118714353069663, 0.12305313738463756)  \n",
       "1        (0.00029296875, 0.0008789062500000001)  \n",
       "7                                    (0.0, 0.0)  \n",
       "13                                   (0.0, 0.0)  \n",
       "27    (0.972768532526475, 0.002079226235813231)  \n",
       "26  (0.9713565305093292, 0.0034483753902730583)  \n",
       "25   (0.970475260540843, 0.0045632379765078585)  \n",
       "28   (0.9685325264750377, 0.005028724503204411)  \n",
       "0    (0.9578698538243771, 0.003631341558832962)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a df with mean and std in separate columns using result_dict\n",
    "exp_metrics = exp.batch_metric_values\n",
    "num_trials = exp.n_trials\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for ens in exp_metrics.keys():\n",
    "    num_contexts = len(exp_metrics[ens][0][\"experience_test_acc\"])\n",
    "\n",
    "    ens_values = np.zeros((num_trials, num_contexts))\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        for j in range(num_contexts):\n",
    "            # ith trial, jth context\n",
    "            ens_values[i, j] = exp_metrics[ens][i][\"experience_test_acc\"][j]\n",
    "\n",
    "    # calculate the mean for each context\n",
    "    experience_mean_values = np.mean(ens_values, axis=0)\n",
    "    experience_std_values = np.std(ens_values, axis=0)\n",
    "\n",
    "    # calculate the mean test acc for each trial\n",
    "    trial_mean_values = np.mean(ens_values, axis=1)\n",
    "\n",
    "    # calculate the mean and std of the mean test acc for each trial\n",
    "    avg_test_acc = np.mean(trial_mean_values)\n",
    "    std_test_acc = np.std(trial_mean_values)\n",
    "\n",
    "    # in our final df we want to have the following columns:\n",
    "    # ensemble_name, avg_test_acc, context_1_test_acc, context_2_test_acc, ..., context_n_test_acc\n",
    "    # we want to set up the dictionary to be able to easily convert to a pandas dataframe\n",
    "    result_dict[ens] = {\n",
    "        \"avg_test_acc\": (avg_test_acc, std_test_acc),\n",
    "    }\n",
    "    for i in range(num_contexts):\n",
    "        result_dict[ens][\n",
    "            f\"context_{i+1}_test_acc\"\n",
    "        ] = (experience_mean_values[i], experience_std_values[i])\n",
    "\n",
    "viz_df = pd.DataFrame(result_dict).T\n",
    "# add the ensemble name as the first column\n",
    "viz_df[\"ensemble\"] = viz_df.index\n",
    "viz_df = viz_df.reset_index(drop=True)\n",
    "\n",
    "# move the ensemble name to the first column\n",
    "cols = viz_df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "viz_df = viz_df[cols]\n",
    "\n",
    "\n",
    "# sort the rows based on the avg_test_acc\n",
    "viz_df = viz_df.sort_values(by=\"avg_test_acc\", ascending=False)\n",
    "\n",
    "file_prefix = f\"many_v_class_incremental-trials={num_trials}-batch_size={batch_size}-window_size={window_size}-num_voters={n_voters}-width={ensemble_width}-{exp_name_suffix}\"\n",
    "path = \"results\"\n",
    "\n",
    "filepath = f\"{path}/{file_prefix}-vizdata-test-feb16.csv\"\n",
    "viz_df.to_csv(filepath, index=False)\n",
    "\n",
    "viz_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics = exp.get_aggregate_batch_metrics()\n",
    "dfs = []\n",
    "for ens, metric_dict in batch_metrics.items():\n",
    "    df = pd.DataFrame.from_dict(metric_dict, orient=\"index\")\n",
    "    df[\"ensemble_name\"] = ens\n",
    "    dfs.append(df)\n",
    "single_active_df = pd.concat(dfs)\n",
    "col_order = [len(single_active_df.columns) - 1] + list(\n",
    "    range(len(single_active_df.columns) - 1)\n",
    ")\n",
    "single_active_df = single_active_df[single_active_df.columns[col_order]]\n",
    "file_prefix = f\"many_v_class_incremental-trials={num_trials}-batch_size={batch_size}_window_size={window_size}-feb10\"\n",
    "path = \"results\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "filepath = f\"{path}/{file_prefix}.csv\"\n",
    "single_active_df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for mechanisms\n",
      "Mean train acc for full-ensemble: 0.793+-0.029\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-1: 0.75+-0.111\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-3: 0.8+-0.071\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-5: 0.821+-0.049\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-7: 0.828+-0.044\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-9: 0.818+-0.041\n",
      "Mean train acc for random_better-accuracy_score-num_gurus-11: 0.82+-0.036\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-1: 0.776+-0.103\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-3: 0.83+-0.056\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-5: 0.841+-0.039\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-7: 0.832+-0.045\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-9: 0.837+-0.035\n",
      "Mean train acc for probabilistic_better-accuracy_score-num_gurus-11: 0.837+-0.033\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-1: 0.759+-0.091\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-3: 0.815+-0.051\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-5: 0.834+-0.043\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-7: 0.835+-0.034\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-9: 0.831+-0.038\n",
      "Mean train acc for probabilistic_weighted-accuracy_score-num_gurus-11: 0.831+-0.03\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-1: 0.747+-0.122\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-3: 0.708+-0.136\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-5: 0.731+-0.11\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-7: 0.752+-0.09\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-9: 0.759+-0.086\n",
      "Mean train acc for max_diversity-accuracy_score-num_gurus-11: 0.765+-0.092\n",
      "Mean train acc for single_Net: 0.86+-0.033\n",
      "Mean train acc for LwF: 0.857+-0.031\n",
      "Mean train acc for EWC: 0.85+-0.039\n",
      "Mean train acc for SynapticIntelligence: 0.845+-0.032\n",
      "--------------\n",
      "--------------\n",
      "Mean test acc for full-ensemble: 0.192+-0.001\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-1: 0.292+-0.054\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-3: 0.293+-0.081\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-5: 0.362+-0.077\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-7: 0.408+-0.027\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-9: 0.297+-0.045\n",
      "Mean test acc for random_better-accuracy_score-num_gurus-11: 0.286+-0.034\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-1: 0.271+-0.046\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-3: 0.345+-0.076\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-5: 0.389+-0.097\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-7: 0.396+-0.058\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-9: 0.277+-0.035\n",
      "Mean test acc for probabilistic_better-accuracy_score-num_gurus-11: 0.286+-0.031\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-1: 0.263+-0.071\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-3: 0.333+-0.1\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-5: 0.383+-0.086\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-7: 0.405+-0.055\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-9: 0.277+-0.038\n",
      "Mean test acc for probabilistic_weighted-accuracy_score-num_gurus-11: 0.294+-0.044\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-1: 0.33+-0.053\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-3: 0.374+-0.126\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-5: 0.391+-0.082\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-7: 0.414+-0.055\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-9: 0.314+-0.048\n",
      "Mean test acc for max_diversity-accuracy_score-num_gurus-11: 0.298+-0.04\n",
      "Mean test acc for single_Net: 0.194+-0.001\n",
      "Mean test acc for LwF: 0.194+-0.001\n",
      "Mean test acc for EWC: 0.194+-0.001\n",
      "Mean test acc for SynapticIntelligence: 0.195+-0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carterblair/opt/anaconda3/envs/LDE/lib/python3.10/site-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    }
   ],
   "source": [
    "# Print results - single guru\n",
    "\n",
    "print(f\"Results for mechanisms\")\n",
    "\n",
    "# Collect and print train accuracies - aggregate and by batch\n",
    "train_results_dict = dict()\n",
    "for ens_name, ensemble in ensembles_dict.items():\n",
    "    train_acc, train_acc_std = calculate_avg_std_train_accs(exp, ens_name, num_trials)\n",
    "    train_results_dict[ens_name] = (train_acc, train_acc_std)\n",
    "\n",
    "for strat_name, (strat, eval_plugin) in initialize_strategies_to_evaluate().items():\n",
    "    train_acc, train_acc_std = calculate_avg_std_train_accs(exp, strat_name, num_trials)\n",
    "    train_results_dict[strat_name] = (train_acc, train_acc_std)\n",
    "\n",
    "for ens_name, (train_acc, train_acc_std) in train_results_dict.items():\n",
    "    print(\n",
    "        f\"Mean train acc for {ens_name}: {round(np.mean(train_acc), 3)}+-{round(np.mean(train_acc_std), 3)}\"\n",
    "    )\n",
    "# for ens_name, (train_acc, train_acc_std) in train_results_dict.items():\n",
    "#     print(f\"All train accs for {ens_name}: {train_acc}\")\n",
    "\n",
    "print(\"--------------\")\n",
    "\n",
    "# Collect and print test accuracies\n",
    "# results_dict = dict()\n",
    "# for ens_name, ensemble in ensembles_dict.items():\n",
    "#     test_acc, test_acc_std = calculate_avg_std_test_accs(exp, ens_name, num_trials)\n",
    "#     results_dict[ens_name] = (test_acc, test_acc_std)\n",
    "\n",
    "# for strat_name, (strat, eval_plugin) in initialize_strategies_to_evaluate().items():\n",
    "#     test_acc, test_acc_std = calculate_avg_std_test_accs(exp, strat_name, num_trials)\n",
    "#     results_dict[strat_name] = (test_acc, test_acc_std)\n",
    "\n",
    "\n",
    "# for ens_name, (test_acc, test_acc_std) in results_dict.items():\n",
    "#     print(\n",
    "#         f\"Mean test acc for {ens_name}: {round(np.mean(test_acc), 3)}+-{round(np.mean(test_acc_std), 3)}\"\n",
    "# )\n",
    "\n",
    "print(\"--------------\")\n",
    "\n",
    "results_dict = dict()\n",
    "\n",
    "for ens_name, ensemble in ensembles_dict.items():\n",
    "    test_acc, _ = calculate_avg_std_test_accs_per_trial(exp, ens_name, num_trials)\n",
    "    print(\n",
    "        f\"Mean test acc for {ens_name}: {round(np.mean(test_acc), 3)}+-{round(np.std(test_acc), 3)}\"\n",
    "    )\n",
    "    results_dict[ens_name] = (np.mean(test_acc), np.std(test_acc))\n",
    "\n",
    "for strat_name, (strat, eval_plugin) in initialize_strategies_to_evaluate().items():\n",
    "    test_acc, _ = calculate_avg_std_test_accs_per_trial(exp, strat_name, num_trials)\n",
    "    print(\n",
    "        f\"Mean test acc for {strat_name}: {round(np.mean(test_acc), 3)}+-{round(np.std(test_acc), 3)}\"\n",
    "    )\n",
    "    results_dict[strat_name] = (np.mean(test_acc), np.std(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results_dict)\n",
    "# make data frame with three columns: name, mean, std\n",
    "df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"mean\", \"std\"])\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={\"index\": \"name\"})\n",
    "df = df.sort_values(by=\"mean\", ascending=False, ignore_index=True)\n",
    "# write to csv in results/keepers/class_inc_avgs.csv\n",
    "df.to_csv(\"results/keepers/many_v_class_inc_avgs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'batch_train_acc': [1.0,\n",
       "   1.0,\n",
       "   0.984375,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.984375,\n",
       "   0.984375,\n",
       "   0.984375,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.984375,\n",
       "   0.984375,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.984375,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9917355179786682,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.015625,\n",
       "   0.09375,\n",
       "   0.0,\n",
       "   0.828125,\n",
       "   0.0,\n",
       "   0.8359375,\n",
       "   0.9375,\n",
       "   0.921875,\n",
       "   0.90625,\n",
       "   0.875,\n",
       "   0.921875,\n",
       "   0.8671875,\n",
       "   0.921875,\n",
       "   0.890625,\n",
       "   0.9375,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.21875,\n",
       "   0.171875,\n",
       "   0.9453125,\n",
       "   0.9609375,\n",
       "   0.9609375,\n",
       "   0.96875,\n",
       "   0.96875,\n",
       "   0.9453125,\n",
       "   0.9609375,\n",
       "   0.9296875,\n",
       "   0.9453125,\n",
       "   0.984375,\n",
       "   0.984375,\n",
       "   0.9453125,\n",
       "   0.921875,\n",
       "   0.953125,\n",
       "   0.96875,\n",
       "   0.9453125,\n",
       "   0.9765625,\n",
       "   0.9296875,\n",
       "   0.90625,\n",
       "   0.9296875,\n",
       "   0.96875,\n",
       "   0.953125,\n",
       "   0.9296875,\n",
       "   0.9375,\n",
       "   0.9375,\n",
       "   0.9375,\n",
       "   0.953125,\n",
       "   0.9375,\n",
       "   0.9609375,\n",
       "   0.953125,\n",
       "   0.96875,\n",
       "   0.921875,\n",
       "   0.9375,\n",
       "   0.9765625,\n",
       "   0.9453125,\n",
       "   0.9921875,\n",
       "   0.953125,\n",
       "   0.9296875,\n",
       "   0.9765625,\n",
       "   0.921875,\n",
       "   0.9609375,\n",
       "   0.9765625,\n",
       "   0.9296875,\n",
       "   0.96875,\n",
       "   0.953125,\n",
       "   0.96875,\n",
       "   0.9375,\n",
       "   0.953125,\n",
       "   0.953125,\n",
       "   0.9609375,\n",
       "   0.953125,\n",
       "   0.9609375,\n",
       "   0.9375,\n",
       "   0.0,\n",
       "   0.984375,\n",
       "   1.0,\n",
       "   0.984375,\n",
       "   0.9765625,\n",
       "   0.984375,\n",
       "   0.9609375,\n",
       "   0.9921875,\n",
       "   0.9375,\n",
       "   0.96875,\n",
       "   0.9921875,\n",
       "   0.9296875,\n",
       "   0.953125,\n",
       "   0.96875,\n",
       "   0.96875,\n",
       "   0.9473684430122375,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.28125,\n",
       "   0.4765625,\n",
       "   0.6015625,\n",
       "   0.6796875,\n",
       "   0.7109375,\n",
       "   0.7265625,\n",
       "   0.796875,\n",
       "   0.765625,\n",
       "   0.7265625,\n",
       "   0.7734375,\n",
       "   0.8203125,\n",
       "   0.796875,\n",
       "   0.75,\n",
       "   0.78125,\n",
       "   0.859375,\n",
       "   0.875,\n",
       "   0.8828125,\n",
       "   0.9609375,\n",
       "   0.9453125,\n",
       "   0.9609375,\n",
       "   0.8984375,\n",
       "   0.9453125,\n",
       "   0.9765625,\n",
       "   0.921875,\n",
       "   0.9296875,\n",
       "   0.96875,\n",
       "   0.9453125,\n",
       "   0.9609375,\n",
       "   0.9453125,\n",
       "   0.9453125,\n",
       "   0.9921875,\n",
       "   0.953125,\n",
       "   0.984375,\n",
       "   0.9453125,\n",
       "   0.953125,\n",
       "   0.953125,\n",
       "   0.9296875,\n",
       "   0.9453125,\n",
       "   0.96875,\n",
       "   0.953125,\n",
       "   0.9609375,\n",
       "   0.96875,\n",
       "   0.9765625,\n",
       "   0.9453125,\n",
       "   0.9609375,\n",
       "   0.953125,\n",
       "   0.96875,\n",
       "   0.984375,\n",
       "   0.953125,\n",
       "   0.953125,\n",
       "   0.921875,\n",
       "   0.9765625,\n",
       "   0.984375,\n",
       "   0.96875,\n",
       "   1.0,\n",
       "   0.9765625,\n",
       "   0.9609375,\n",
       "   0.4921875,\n",
       "   0.5390625,\n",
       "   0.453125,\n",
       "   0.484375,\n",
       "   0.53125,\n",
       "   0.609375,\n",
       "   0.421875,\n",
       "   0.4765625,\n",
       "   0.8984375,\n",
       "   0.6796875,\n",
       "   0.8203125,\n",
       "   0.7890625,\n",
       "   0.8203125,\n",
       "   0.921875,\n",
       "   0.9375,\n",
       "   0.984375,\n",
       "   0.9609375,\n",
       "   0.9765625,\n",
       "   0.9609375,\n",
       "   0.9765625,\n",
       "   0.9609375,\n",
       "   0.9765625,\n",
       "   0.9448819160461426,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.203125,\n",
       "   0.375,\n",
       "   0.5625,\n",
       "   0.65625,\n",
       "   0.5703125,\n",
       "   0.609375,\n",
       "   0.46875,\n",
       "   0.6953125,\n",
       "   0.59375,\n",
       "   0.6484375,\n",
       "   0.765625,\n",
       "   0.8125,\n",
       "   0.84375,\n",
       "   0.9296875,\n",
       "   0.9375,\n",
       "   0.96875,\n",
       "   0.9765625,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.984375,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   0.984375,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.984375,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.984375,\n",
       "   0.9921875,\n",
       "   0.984375,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9921875,\n",
       "   0.4140625,\n",
       "   0.6484375,\n",
       "   0.7265625,\n",
       "   0.6171875,\n",
       "   0.71875,\n",
       "   0.7109375,\n",
       "   0.7265625,\n",
       "   0.8203125,\n",
       "   0.8984375,\n",
       "   0.96875,\n",
       "   0.96875,\n",
       "   0.9765625,\n",
       "   0.984375,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   0.984375,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.28125,\n",
       "   0.359375,\n",
       "   0.53125,\n",
       "   0.546875,\n",
       "   0.5390625,\n",
       "   0.4921875,\n",
       "   0.53125,\n",
       "   0.4765625,\n",
       "   0.5078125,\n",
       "   0.5234375,\n",
       "   0.5234375,\n",
       "   0.515625,\n",
       "   0.4921875,\n",
       "   0.5234375,\n",
       "   0.4609375,\n",
       "   0.5390625,\n",
       "   0.5234375,\n",
       "   0.546875,\n",
       "   0.5,\n",
       "   0.4140625,\n",
       "   0.4453125,\n",
       "   0.484375,\n",
       "   0.5078125,\n",
       "   0.4921875,\n",
       "   0.4453125,\n",
       "   0.40625,\n",
       "   0.5390625,\n",
       "   0.5546875,\n",
       "   0.6796875,\n",
       "   0.796875,\n",
       "   0.7109375,\n",
       "   0.640625,\n",
       "   0.6953125,\n",
       "   0.640625,\n",
       "   0.65625,\n",
       "   0.7109375,\n",
       "   0.875,\n",
       "   0.921875,\n",
       "   0.9140625,\n",
       "   0.9296875,\n",
       "   0.90625,\n",
       "   0.921875,\n",
       "   0.890625,\n",
       "   0.9296875,\n",
       "   0.96875,\n",
       "   0.953125,\n",
       "   0.953125,\n",
       "   0.9453125,\n",
       "   0.953125,\n",
       "   0.9375,\n",
       "   0.953125,\n",
       "   0.9375,\n",
       "   0.9765625,\n",
       "   1.0,\n",
       "   0.9296875,\n",
       "   0.9765625,\n",
       "   0.953125,\n",
       "   0.921875,\n",
       "   0.953125,\n",
       "   0.9375,\n",
       "   0.9375,\n",
       "   0.9609375,\n",
       "   0.9375,\n",
       "   0.96875,\n",
       "   0.9453125,\n",
       "   0.9609375,\n",
       "   0.96875,\n",
       "   0.96875,\n",
       "   0.96875,\n",
       "   0.96875,\n",
       "   0.9609375,\n",
       "   0.9609375,\n",
       "   0.984375,\n",
       "   0.96875,\n",
       "   0.96875,\n",
       "   0.96875,\n",
       "   0.9765625,\n",
       "   0.96875,\n",
       "   0.9765625,\n",
       "   0.9453125,\n",
       "   0.9765625,\n",
       "   0.875],\n",
       "  'active_voters-train': [[0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [4],\n",
       "   [3, 4, 6, 7],\n",
       "   [0, 4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [1, 4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [0, 6],\n",
       "   [0],\n",
       "   [0, 4],\n",
       "   [0],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4, 7],\n",
       "   [0, 4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [0, 2, 5, 6],\n",
       "   [2, 7],\n",
       "   [0, 3, 4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [2],\n",
       "   [4],\n",
       "   [2, 4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [2],\n",
       "   [0, 1, 2, 5],\n",
       "   [2],\n",
       "   [0, 2],\n",
       "   [2],\n",
       "   [2, 6],\n",
       "   [0, 2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [1, 2],\n",
       "   [2],\n",
       "   [2, 6],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2, 4],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2, 4],\n",
       "   [1, 2, 3, 6],\n",
       "   [2, 4],\n",
       "   [2, 3],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2, 5],\n",
       "   [2, 7],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [0, 1, 3, 4, 5, 6, 7],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [2],\n",
       "   [0, 1, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 3, 4, 5, 6, 7],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3, 4],\n",
       "   [3],\n",
       "   [3, 4],\n",
       "   [3],\n",
       "   [3],\n",
       "   [1, 3],\n",
       "   [4, 6],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4, 5, 7],\n",
       "   [0, 4],\n",
       "   [4],\n",
       "   [0, 4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [4],\n",
       "   [0],\n",
       "   [0, 7],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0, 1, 2, 7],\n",
       "   [0],\n",
       "   [0],\n",
       "   [1, 2, 7],\n",
       "   [1, 2, 7],\n",
       "   [1, 2, 7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [0, 7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [7],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0, 1, 2, 3, 4, 5],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [0],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1],\n",
       "   [1]],\n",
       "  'batch_test_acc': [0.0,\n",
       "   0.71875,\n",
       "   0.625,\n",
       "   0.6640625,\n",
       "   0.71875,\n",
       "   0.6484375,\n",
       "   0.59375,\n",
       "   0.6796875,\n",
       "   0.625,\n",
       "   0.6015625,\n",
       "   0.640625,\n",
       "   0.71875,\n",
       "   0.703125,\n",
       "   0.6796875,\n",
       "   0.6328125,\n",
       "   0.5390625,\n",
       "   0.6567164063453674,\n",
       "   0.0,\n",
       "   0.0078125,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0078125,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0078125,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.015625,\n",
       "   0.008196720853447914,\n",
       "   0.765625,\n",
       "   0.78125,\n",
       "   0.8203125,\n",
       "   0.828125,\n",
       "   0.7734375,\n",
       "   0.8125,\n",
       "   0.765625,\n",
       "   0.8125,\n",
       "   0.75,\n",
       "   0.8203125,\n",
       "   0.8515625,\n",
       "   0.828125,\n",
       "   0.8203125,\n",
       "   0.7890625,\n",
       "   0.7195122241973877,\n",
       "   0.9375,\n",
       "   0.96875,\n",
       "   0.9375,\n",
       "   0.953125,\n",
       "   0.9765625,\n",
       "   0.9609375,\n",
       "   0.9609375,\n",
       "   0.96875,\n",
       "   0.9765625,\n",
       "   0.9375,\n",
       "   0.9765625,\n",
       "   0.984375,\n",
       "   0.96875,\n",
       "   0.9765625,\n",
       "   0.9609375,\n",
       "   0.9545454382896423,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.015625,\n",
       "   0.0,\n",
       "   0.0078125,\n",
       "   0.0,\n",
       "   0.0078125,\n",
       "   0.0078125,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'active_voters-test': [[1],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   [0, 1, 2, 3, 4, 5, 6, 7]],\n",
       "  'experience_test_acc': [0.6144575827261981,\n",
       "   0.0029537013033404946,\n",
       "   0.7958841482798259,\n",
       "   0.9624911211431026,\n",
       "   0.00244140625]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.batch_metric_values[\"max_diversity-f1_score-num_gurus-1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Results\n",
    "\n",
    "(leftover copied code from other file, not adapted for the above code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "full-ensemble\n",
      "random_better-accuracy_score-num_gurus-1\n",
      "random_better-accuracy_score-num_gurus-3\n",
      "random_better-accuracy_score-num_gurus-5\n",
      "random_better-accuracy_score-num_gurus-7\n",
      "random_better-accuracy_score-num_gurus-9\n",
      "random_better-accuracy_score-num_gurus-11\n",
      "probabilistic_better-accuracy_score-num_gurus-1\n",
      "probabilistic_better-accuracy_score-num_gurus-3\n",
      "probabilistic_better-accuracy_score-num_gurus-5\n",
      "probabilistic_better-accuracy_score-num_gurus-7\n",
      "probabilistic_better-accuracy_score-num_gurus-9\n",
      "probabilistic_better-accuracy_score-num_gurus-11\n",
      "probabilistic_weighted-accuracy_score-num_gurus-1\n",
      "probabilistic_weighted-accuracy_score-num_gurus-3\n",
      "probabilistic_weighted-accuracy_score-num_gurus-5\n",
      "probabilistic_weighted-accuracy_score-num_gurus-7\n",
      "probabilistic_weighted-accuracy_score-num_gurus-9\n",
      "probabilistic_weighted-accuracy_score-num_gurus-11\n",
      "max_diversity-accuracy_score-num_gurus-1\n",
      "max_diversity-accuracy_score-num_gurus-3\n",
      "max_diversity-accuracy_score-num_gurus-5\n",
      "max_diversity-accuracy_score-num_gurus-7\n",
      "max_diversity-accuracy_score-num_gurus-9\n",
      "max_diversity-accuracy_score-num_gurus-11\n",
      "single_Net\n"
     ]
    }
   ],
   "source": [
    "print(len(exp.ensembles))\n",
    "for ens in exp.ensembles:\n",
    "    print(ens.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_diversity-accuracy_score-num_gurus-5\n"
     ]
    }
   ],
   "source": [
    "print(exp.ensembles[-5].name)\n",
    "batch_accs = []\n",
    "for voter in exp.ensembles[-5].voters:\n",
    "    batch_accs.append(voter.batch_accuracies)\n",
    "# exp.ensembles[-5].voters[0].batch_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_active_streaks(voter_id, trial_num):\n",
    "    \"\"\"\n",
    "    Find active streaks for a specified voter.\n",
    "\n",
    "    :param voter_id: ID of the voter for which to find active streaks.\n",
    "    :param batch_metric_values: Dictionary containing the batch metric values.\n",
    "    :param metric_key: Key to access the relevant metric in batch_metric_values.\n",
    "    :return: List of active streaks for the specified voter.\n",
    "    \"\"\"\n",
    "    active_batches = []\n",
    "    active_streak = [None, None]\n",
    "    voter_active = False\n",
    "\n",
    "    for i, av in enumerate(\n",
    "        exp.batch_metric_values[\"max_diversity-f1_score-num_gurus-1\"][trial_num][\n",
    "            \"active_voters-train\"\n",
    "        ]\n",
    "    ):\n",
    "        # print(av)\n",
    "        if voter_id in av:\n",
    "            if not voter_active:\n",
    "                # Start a new streak\n",
    "                active_streak[0] = i\n",
    "                voter_active = True\n",
    "                # print(\"streak started\")\n",
    "            active_streak[1] = i\n",
    "        else:\n",
    "            if voter_active:\n",
    "                # End the current streak\n",
    "                active_batches.append(active_streak.copy())\n",
    "                active_streak = [None, None]\n",
    "                voter_active = False\n",
    "                # print(\"streak done\")\n",
    "\n",
    "    # Handle case where the streak continues till the end of the list\n",
    "    if voter_active:\n",
    "        active_batches.append(active_streak.copy())\n",
    "\n",
    "    return active_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at activity on last trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'max_diversity-f1_score-num_gurus-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m voter_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_voters):\n\u001b[0;32m----> 2\u001b[0m     active_streaks \u001b[38;5;241m=\u001b[39m \u001b[43mfind_active_streaks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoter_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(active_streaks)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# print(f\"Active Streaks for Voter {voter_id}: {active_streaks}\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m, in \u001b[0;36mfind_active_streaks\u001b[0;34m(voter_id, trial_num)\u001b[0m\n\u001b[1;32m     11\u001b[0m active_streak \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     12\u001b[0m voter_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, av \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_metric_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_diversity-f1_score-num_gurus-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[trial_num][\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_voters-train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m     ]\n\u001b[1;32m     18\u001b[0m ):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# print(av)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m voter_id \u001b[38;5;129;01min\u001b[39;00m av:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m voter_active:\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;66;03m# Start a new streak\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'max_diversity-f1_score-num_gurus-1'"
     ]
    }
   ],
   "source": [
    "for voter_id in range(n_voters):\n",
    "    active_streaks = find_active_streaks(voter_id, num_trials - 1)\n",
    "    print(active_streaks)\n",
    "    # print(f\"Active Streaks for Voter {voter_id}: {active_streaks}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))  # Create a new figure for each voter\n",
    "    plt.plot(batch_accs[voter_id])\n",
    "    # plt.axvline(x=len_train, color=\"k\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # Shade the active batches for this voter\n",
    "    for streak in active_streaks:\n",
    "        if streak[0] is not None and streak[1] is not None:\n",
    "            plt.axvspan(streak[0], streak[1], alpha=0.3, color=\"red\")\n",
    "\n",
    "    # Plot a green vertical line at all train splits\n",
    "    # for split in train_splits[:-1]:\n",
    "    #     plt.axvline(x=split, color=\"g\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "    plt.title(f\"Voter {voter_id} Activity\")\n",
    "    plt.xlabel(\"Batches\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()  # Display the plot for each voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
